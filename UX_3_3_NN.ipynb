{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UX_3_3_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "c8tQMXXN_8my"
      },
      "outputs": [],
      "source": [
        "from datetime import date, datetime\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import random, numpy\n",
        "from numpy.random import seed\n",
        "\n",
        "SEED = 12345"
      ],
      "metadata": {
        "id": "ndg3B4_bLG4m"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Moving Average**"
      ],
      "metadata": {
        "id": "FAGStRGxQRQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SMA(data,n):\n",
        "    \n",
        "    #додаємо NaN на початку\n",
        "\tsma_list=[np.nan for k in range(n-1)]\n",
        "    \n",
        "\tfor i in range(len(data)-n+1):\n",
        "\t\tsum_n = 0\n",
        "\t\tfor j in range(n):\n",
        "\t\t\tsum_n = sum_n + data[i+j]\n",
        "\t\tsma=sum_n/n\n",
        "\t\tsma_list.append(round(sma, 2))\n",
        "        \n",
        "\treturn sma_list"
      ],
      "metadata": {
        "id": "EkdtzE6UQLYO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Weighted Moving Average**"
      ],
      "metadata": {
        "id": "5etv44l1QazH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LWMA(data,n):\n",
        "    \n",
        "\tlma_list=[np.nan for k in range(n-1)]\n",
        "\n",
        "\tfor i in range(len(data)-n+1):\n",
        "\t\tsum_n, sum_j = 0, 0\n",
        "\t\tfor j in range(n):\n",
        "\t\t\tsum_n = sum_n + (j+1)*data[i+j]\n",
        "\t\t\tsum_j = sum_j + (j+1)\n",
        "\t\tlma=sum_n/sum_j\n",
        "\t\tlma_list.append(lma)\n",
        "\n",
        "\treturn lma_list"
      ],
      "metadata": {
        "id": "j6U7YwTyQe5E"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EMA(data, n, a=0):\n",
        "\tema_list=[data[0]]\n",
        "\tif a==0:\n",
        "\t\ta=2/(n+1)\n",
        "\n",
        "\tfor i in range (1,len(data)):\n",
        "\t\tema = 0\n",
        "\t\tema = (1-a)*ema_list[i-1]+a*data[i]\n",
        "\t\tema_list.append(ema)\n",
        "\n",
        "\treturn ema_list"
      ],
      "metadata": {
        "id": "5c442wnTQi50"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SO**"
      ],
      "metadata": {
        "id": "c_8JRJwkQlBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SO(data_close, data_high, data_low, n):\n",
        "\tK, D = [np.nan for k in range(n-1)], [np.nan for k in range(n-1)]\n",
        "\thighest_high, lowest_low = [np.nan for k in range(n-1)], [np.nan for k in range(n-1)]\n",
        "\n",
        "\tfor i in range(len(data_close)-n+1):\n",
        "\t\tlist_n_high, list_n_low = [], []\n",
        "\t\tfor j in range(0, n):\n",
        "\t\t\tlist_n_high.append(data_high[i+j])\n",
        "\t\t\tlist_n_low.append(data_low[i+j])\n",
        "\t\thighest_high.append(max(list_n_high))\n",
        "\t\tlowest_low.append(min(list_n_low))\n",
        "\n",
        "\tfor i in range(n-1, len(highest_high)):\n",
        "\t\tK.append(100*(data_close[i]-lowest_low[i])/(highest_high[i]-lowest_low[i]))\n",
        "\tD = SMA(K, n)\n",
        "\n",
        "\treturn K, D"
      ],
      "metadata": {
        "id": "HaI1nXycQnKV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CCI**"
      ],
      "metadata": {
        "id": "-pFB551sQ5BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CCI(data_close, data_high, data_low, n):\n",
        "\tp_typical = []\n",
        "\n",
        "\tfor i in range(len(data_close)):\n",
        "\t\tp_typical.append((data_close[i]+data_low[i]+data_high[i])/3)\n",
        "\tsma = SMA(p_typical,n)\n",
        "\n",
        "\tMAD = [np.nan for k in range(n-1)]\n",
        "\tfor j in range(n-1, len(data_close)):\n",
        "\t\tmad = 0\n",
        "\t\tfor s in range(n):\n",
        "\t\t\tmad = mad +  abs(p_typical[j-s]-sma[j])\n",
        "\t\tMAD.append(mad/n)\n",
        "\n",
        "\tCCI = [np.nan for n in range(n-1)]\n",
        "\tfor t in range(n-1, len(data_close)):\n",
        "\t\tcci = (p_typical[t]-sma[t])/(0.015*MAD[t])\n",
        "\t\tCCI.append(cci)\n",
        "\n",
        "\treturn CCI"
      ],
      "metadata": {
        "id": "or1TLwu5Q-9t"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disparsity Index**"
      ],
      "metadata": {
        "id": "UeCoKKAEREis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DI(data, n, MA_type):\n",
        "    if MA_type == \"EMA\":\n",
        "        MA = EMA(data, n)\n",
        "    elif MA_type == \"LWMA\":\n",
        "        MA = LWMA(data, n)\n",
        "    else:\n",
        "        MA = SMA(data, n)\n",
        "    \n",
        "    di_list = []\n",
        "    for i in range(len(MA)):\n",
        "        if (np.isnan(MA[i])):\n",
        "            di_list.append(np.nan)\n",
        "        else:\n",
        "            di_list.append((data[i]-MA[i])/(100*MA[i]))\n",
        "        \n",
        "    return di_list"
      ],
      "metadata": {
        "id": "f7u6F_4iQ_nv"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elder-Ray Index**"
      ],
      "metadata": {
        "id": "Qxx4w--KRHqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ERI(data_close, data_high, data_low, n):\n",
        "    MA = EMA(data_close, n)\n",
        "    \n",
        "    BuP, BeP = [], []\n",
        "    for i in range(len(data_close)):\n",
        "        BuP.append(data_high[i] - MA[i])\n",
        "        BeP.append(data_low[i] - MA[i])\n",
        "    return BuP, BeP"
      ],
      "metadata": {
        "id": "WER9MGV8RLW1"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy with moving averages**\n",
        "\n",
        "Сигнали - перетин ціни і плинного середнього\n",
        "\n",
        "P - list of Close prices\n",
        "\n",
        "n1 - к-ть періодів для середнього\n",
        "\n",
        "MA_type - тип середнього (\"SMA\", \"EMA\", \"LWMA\")"
      ],
      "metadata": {
        "id": "--dvS2dkRXt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy_MA_1(P, n1, MA_type, n2=26, n3=9):\n",
        "\tMA= []\n",
        "\tif MA_type == \"SMA\":\n",
        "\t\tMA = SMA(P, n1)\n",
        "\telif MA_type == \"EMA\":\n",
        "\t\tMA = EMA(P, n1)\n",
        "\telif MA_type == \"LWMA\":\n",
        "\t\tMA = LWMA(P, n1)\n",
        "\n",
        "\tif MA_type != \"EMA\":\n",
        "\t\ts=[np.nan for k in range(n1)]\n",
        "\t\tfor i in range(n1, len(MA)):\n",
        "\t\t\tif (P[i-1]<MA[i-1]) and (P[i]>MA[i]):\n",
        "\t\t\t\ts.append(1)\n",
        "\t\t\telif (P[i-1]>MA[i-1]) and (P[i]<MA[i]):\n",
        "\t\t\t\ts.append(-1)\n",
        "\t\t\telse:\n",
        "\t\t\t\ts.append(0)\n",
        "\telif MA_type == \"EMA\":\n",
        "\t\ts=[np.nan]\n",
        "\t\tfor i in range(1,len(MA)):\n",
        "\t\t\tif (P[i-1]<MA[i-1]) and (P[i]>MA[i]):\n",
        "\t\t\t\ts.append(1)\n",
        "\t\t\telif (P[i-1]>MA[i-1]) and (P[i]<MA[i]):\n",
        "\t\t\t\ts.append(-1)\n",
        "\t\t\telse:\n",
        "\t\t\t\ts.append(0)\n",
        "\treturn s"
      ],
      "metadata": {
        "id": "Nu2LbJeERaLN"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy SO**"
      ],
      "metadata": {
        "id": "YucvKZibRdGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy_SO(P_close, P_high, P_low, n):\n",
        "\tK, D = SO(P_close, P_high, P_low, n)\n",
        "\ts=[np.nan for k in range(n)]\n",
        "\tfor i in range(n, len(P_close)):\n",
        "\t\tif (K[i]>D[i]) and (K[i-1]<D[i-1]):\n",
        "\t\t\ts.append(-1)\n",
        "\t\telif (K[i]<D[i]) and (K[i-1]>D[i-1]):\n",
        "\t\t\ts.append(1)\n",
        "\t\telse:\n",
        "\t\t\ts.append(0)\n",
        "\treturn s"
      ],
      "metadata": {
        "id": "5M6hGv1TRfAJ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy CCI**"
      ],
      "metadata": {
        "id": "K63-kEMrRmXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy_CCI(data_close, data_high, data_low, n):\n",
        "\tcci = CCI(data_close, data_high, data_low, n)\n",
        "\ts=[]\n",
        "\tfor i in range(len(data_close)):\n",
        "\t\tif ((cci[i]>0) and (cci[i-1]<0)):\n",
        "\t\t\ts.append(1)\n",
        "\t\telif ((cci[i]<0) and (cci[i-1]>0)):\n",
        "\t\t\ts.append(-1)\n",
        "\t\telse:\n",
        "\t\t\ts.append(0)\n",
        "\treturn s"
      ],
      "metadata": {
        "id": "xzzLOQ6WRoh0"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy DI**"
      ],
      "metadata": {
        "id": "Zuwa8SyjRuFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy_DI(P_close, n):\n",
        "    DI_ = DI(P_close, n, MA_type=\"SMA\")\n",
        "    \n",
        "    s=[np.nan]\n",
        "    for i in range(1,len(DI_)):\n",
        "        if np.isnan(DI_[i]):\n",
        "            s.append(np.nan)\n",
        "        elif ((DI_[i]>0)&(DI_[i-1]<0)):\n",
        "            s.append(1)\n",
        "        elif ((DI_[i]<0)&(DI_[i-1]>0)):\n",
        "            s.append(-1)\n",
        "        else:\n",
        "            s.append(0)\n",
        "            \n",
        "    return s"
      ],
      "metadata": {
        "id": "agMkpNZnRu92"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy ERI**"
      ],
      "metadata": {
        "id": "JfNwESPnRwha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy_ERI(P_close, P_high, P_low, n=13):\n",
        "    BuP_ = ERI(P_close, P_high, P_low, n)[0]\n",
        "    BeP_ = ERI(P_close, P_high, P_low, n)[1]\n",
        "    \n",
        "    s=[np.nan]\n",
        "    for i in range(1, len(BuP_)):\n",
        "        if ((BeP_[i]>0)&(BeP_[i-1]<0)):\n",
        "            s.append(1)\n",
        "        elif ((BuP_[i]<0)&(BuP_[i-1]>0)):\n",
        "\n",
        "            s.append(-1)\n",
        "        else:\n",
        "            s.append(0)\n",
        "            \n",
        "    return s"
      ],
      "metadata": {
        "id": "1UBPEhCTRyed"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategy MAE**"
      ],
      "metadata": {
        "id": "Vu8QKb3jUfrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy_MAE(P, upper, lower, n1, MA_type, MAE_type=\"LL\"):\n",
        "\tif n1 >= 0:\n",
        "\t\tUL, LL, MA = [], [], []\n",
        "\t\tif MA_type == \"SMA\":\n",
        "\t\t\tMA = SMA(P, n1)\n",
        "\t\telif MA_type == \"EMA\":\n",
        "\t\t\tMA = EMA(P, n1)\n",
        "\t\telif MA_type == \"LWMA\":\n",
        "\t\t\tMA = LWMA(P, n1)\n",
        "\n",
        "\t\tfor i in range(len(P)):\n",
        "\t\t\tUL.append((1+upper)*MA[i])\n",
        "\t\t\tLL.append((1-lower)*MA[i])\n",
        "\t\tif MA_type != \"EMA\":\n",
        "\t\t\ts=[np.nan for k in range(n1)]\n",
        "\t\t\tif MAE_type == \"UL\":\n",
        "\t\t\t\tfor i in range(n1, len(MA)):\n",
        "\t\t\t\t\tif (P[i-1]<UL[i-1]) and (P[i]>UL[i]):\n",
        "\t\t\t\t\t\ts.append(1)\n",
        "\t\t\t\t\telif (P[i-1]>UL[i-1]) and (P[i]<UL[i]):\n",
        "\t\t\t\t\t\ts.append(-1)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\ts.append(0)\n",
        "\t\t\telif MAE_type == \"LL\":\n",
        "\t\t\t\tfor i in range(n1, len(MA)):\n",
        "\t\t\t\t\tif (P[i-1]<LL[i-1]) and (P[i]>LL[i]):\n",
        "\t\t\t\t\t\ts.append(1)\n",
        "\t\t\t\t\telif (P[i-1]>LL[i-1]) and (P[i]<LL[i]):\n",
        "\t\t\t\t\t\ts.append(-1)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\ts.append(0)\n",
        "\t\telif MA_type == \"EMA\":\n",
        "\t\t\ts=[np.nan]\n",
        "\t\t\tif MAE_type == \"UL\":\n",
        "\t\t\t\tfor i in range(1, len(MA)):\n",
        "\t\t\t\t\tif (P[i-1]<UL[i-1]) and (P[i]>UL[i]):\n",
        "\t\t\t\t\t\ts.append(1)\n",
        "\t\t\t\t\telif (P[i-1]>UL[i-1]) and (P[i]<UL[i]):\n",
        "\t\t\t\t\t\ts.append(-1)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\ts.append(0)\n",
        "\t\t\telif MAE_type == \"LL\":\n",
        "\t\t\t\tfor i in range(1, len(MA)):\n",
        "\t\t\t\t\tif (P[i-1]<LL[i-1]) and (P[i]>LL[i]):\n",
        "\t\t\t\t\t\ts.append(1)\n",
        "\t\t\t\t\telif (P[i-1]>LL[i-1]) and (P[i]<LL[i]):\n",
        "\t\t\t\t\t\ts.append(-1)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\ts.append(0)\n",
        "\t\treturn s\n",
        "\telse:\n",
        "\t\treturn [\"nan\", \"nan\"]"
      ],
      "metadata": {
        "id": "_d23hydZUf8L"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def signal_convertation(signals):\n",
        "    non_zero_element = 0\n",
        "    converted_signals = []\n",
        "    #елементи на початку ряду можуть бути нулями, ми їх не змінюємо до появи першого сигналу\n",
        "    \n",
        "    for i in range(len(signals)):\n",
        "        if np.isnan(signals[i]):\n",
        "            converted_signals.append(np.nan)\n",
        "        else:\n",
        "            if signals[i] != 0:\n",
        "                non_zero_element = signals[i]\n",
        "                converted_signals.append(signals[i])\n",
        "            else:\n",
        "                converted_signals.append(non_zero_element)\n",
        "                \n",
        "    return converted_signals"
      ],
      "metadata": {
        "id": "CtWg8RPNTn4O"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trading_results(price, signal):\n",
        "    results=[\"n/a\" for i in range(len(price))]\n",
        "    open_short, close_short, open_long, close_long = 0, 0, 0, 0\n",
        "    \n",
        "    \n",
        "    for i in range(1,len(signal)):\n",
        "        \n",
        "        if signal[i] == 0 and signal[i-1] == 1:\n",
        "            open_short = i\n",
        "            close_long = i\n",
        "            #рахуємо прибутковість довгої позиції\n",
        "            #result = (price[close_long] - price[open_long])/price[open_long]\n",
        "            result = (price[close_long] - price[open_long])/price[open_long] - 0.4/100\n",
        "            results[i] = result\n",
        "            \n",
        "        if signal[i] == 1 and signal[i-1] == 0:\n",
        "            close_short = i\n",
        "            open_long = i\n",
        "            #рахуємо прибутковість короткої позиції\n",
        "            #result = -(price[close_short] - price[open_short])/price[open_short]\n",
        "            result = -(price[close_short] - price[open_short])/price[open_short] - 0.4/100\n",
        "            results[i] = result\n",
        "            \n",
        "    return(results)"
      ],
      "metadata": {
        "id": "NiDTQwOyYsvO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
        "df = pd.read_excel('UX-dailyhistory.xlsx', header = None, skiprows = 1, names = columns)"
      ],
      "metadata": {
        "id": "ibHbJxUC8oVx"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.index = df[\"Date\"]\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df.drop(['Date', 'Volume'], axis='columns', inplace=True)\n",
        "df = df.sort_index()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Xum0MvW095CP",
        "outputId": "3d7b3d87-744d-4baa-e077-13bc01bf7b07"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open    High     Low   Close\n",
              "Date                                      \n",
              "2009-03-26  500.00  500.00  500.00  500.00\n",
              "2009-03-27  557.04  567.24  508.31  509.86\n",
              "2009-03-30  509.35  509.87  502.22  509.87\n",
              "2009-03-31  509.70  511.46  509.70  511.46\n",
              "2009-04-01  508.05  521.66  508.05  521.66"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d798b0b-7119-419f-87a0-e8f59d032c2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-03-26</th>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-27</th>\n",
              "      <td>557.04</td>\n",
              "      <td>567.24</td>\n",
              "      <td>508.31</td>\n",
              "      <td>509.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-30</th>\n",
              "      <td>509.35</td>\n",
              "      <td>509.87</td>\n",
              "      <td>502.22</td>\n",
              "      <td>509.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-31</th>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-04-01</th>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d798b0b-7119-419f-87a0-e8f59d032c2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d798b0b-7119-419f-87a0-e8f59d032c2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d798b0b-7119-419f-87a0-e8f59d032c2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qIjgtxyd7E7W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import missingno as msno"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(df, color = (138/225,43/225,225/225))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "AL_v3cI9AqF7",
        "outputId": "dd81a831-2774-4c6e-d252-6f667b739b52"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f245ebf9b50>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x720 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "xMHYLtSeA23e",
        "outputId": "2f2a4cf3-b653-4e13-fdad-e4613dc8fa44"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close\n",
              "Date                                          \n",
              "2009-03-26   500.00   500.00   500.00   500.00\n",
              "2009-03-27   557.04   567.24   508.31   509.86\n",
              "2009-03-30   509.35   509.87   502.22   509.87\n",
              "2009-03-31   509.70   511.46   509.70   511.46\n",
              "2009-04-01   508.05   521.66   508.05   521.66\n",
              "...             ...      ...      ...      ...\n",
              "2022-02-18  1785.48  1796.03  1765.74  1774.84\n",
              "2022-02-21  1774.84  1803.77  1766.02  1766.02\n",
              "2022-02-22  1766.02  1787.89  1718.72  1759.73\n",
              "2022-02-23  1759.73  1792.64  1718.50  1718.50\n",
              "2022-02-25  1718.50  1718.50  1718.50  1718.50\n",
              "\n",
              "[3187 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cf5ace1-6b8c-48e8-8a1c-6e89fb9dc8b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-03-26</th>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-27</th>\n",
              "      <td>557.04</td>\n",
              "      <td>567.24</td>\n",
              "      <td>508.31</td>\n",
              "      <td>509.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-30</th>\n",
              "      <td>509.35</td>\n",
              "      <td>509.87</td>\n",
              "      <td>502.22</td>\n",
              "      <td>509.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-31</th>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-04-01</th>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1796.03</td>\n",
              "      <td>1765.74</td>\n",
              "      <td>1774.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1803.77</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1766.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1787.89</td>\n",
              "      <td>1718.72</td>\n",
              "      <td>1759.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1792.64</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-25</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3187 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cf5ace1-6b8c-48e8-8a1c-6e89fb9dc8b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cf5ace1-6b8c-48e8-8a1c-6e89fb9dc8b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cf5ace1-6b8c-48e8-8a1c-6e89fb9dc8b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#якщо ціна наступного дня зросла - ставимо 1\n",
        "to_predict = []\n",
        "for i in range(0,len(df.Close)-1):\n",
        "    if df.Close[i+1] > df.Close[i]:\n",
        "        to_predict.append(1)\n",
        "    else:\n",
        "        to_predict.append(0)\n",
        "\n",
        "to_predict.append(np.nan)"
      ],
      "metadata": {
        "id": "5t_og0lVA_UJ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"DI\"] = signal_convertation(strategy_DI(P_close=df.Close, n=12))\n",
        "df[\"ERI\"] = signal_convertation(strategy_ERI(P_close=df.Close, P_high=df.High, P_low=df.Low, n=13))\n",
        "df[\"SMA_1\"] = signal_convertation(strategy_MA_1(P = df.Close, n1 = 12, MA_type = \"SMA\"))\n",
        "df[\"EMA_1\"] = signal_convertation(strategy_MA_1(P = df.Close, n1 = 7, MA_type = \"EMA\"))\n",
        "df[\"LWMA_1\"] = signal_convertation(strategy_MA_1(P = df.Close, n1 = 15, MA_type = \"LWMA\"))\n",
        "df[\"MAE_1\"] = signal_convertation(strategy_MAE(P=df.Close, upper=0, lower=0.01, n1=34, MA_type=\"SMA\", MAE_type=\"LL\"))\n",
        "df[\"MAE_2\"] = signal_convertation(strategy_MAE(P=df.Close, upper=0, lower=0.01, n1=6, MA_type=\"EMA\", MAE_type=\"LL\"))\n",
        "df[\"MAE_3\"] = signal_convertation(strategy_MAE(P=df.Close, upper=0, lower=0.01, n1=17, MA_type=\"LWMA\", MAE_type=\"LL\"))\n",
        "df[\"MAE_4\"] = signal_convertation(strategy_MAE(P=df.Close, upper=0.015, lower=0, n1=21, MA_type=\"SMA\", MAE_type=\"UL\"))\n",
        "df[\"MAE_5\"] = signal_convertation(strategy_MAE(P=df.Close, upper=0.01, lower=0, n1=13, MA_type=\"EMA\", MAE_type=\"UL\"))\n",
        "df[\"MAE_6\"] = signal_convertation(strategy_MAE(P=df.Close, upper=0.01, lower=0, n1=22, MA_type=\"LWMA\", MAE_type=\"UL\"))\n",
        "#df[\"SO_1\"] = strategy_SO(P_close=df.Close, P_high=df.High, P_low=df.Low, n=47)"
      ],
      "metadata": {
        "id": "xJBsos8EvkdW"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "iduOf-_H1EBM",
        "outputId": "cbaa63bb-38c9-4ebe-d372-49b3340356dc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   DI  ERI  SMA_1  EMA_1  \\\n",
              "Date                                                                     \n",
              "2009-03-26   500.00   500.00   500.00   500.00  NaN  NaN    NaN    NaN   \n",
              "2009-03-27   557.04   567.24   508.31   509.86  NaN  0.0    NaN    0.0   \n",
              "2009-03-30   509.35   509.87   502.22   509.87  NaN  0.0    NaN    0.0   \n",
              "2009-03-31   509.70   511.46   509.70   511.46  NaN  1.0    NaN    0.0   \n",
              "2009-04-01   508.05   521.66   508.05   521.66  NaN  1.0    NaN    0.0   \n",
              "...             ...      ...      ...      ...  ...  ...    ...    ...   \n",
              "2022-02-18  1785.48  1796.03  1765.74  1774.84  1.0  1.0    1.0    1.0   \n",
              "2022-02-21  1774.84  1803.77  1766.02  1766.02  1.0  1.0    1.0    1.0   \n",
              "2022-02-22  1766.02  1787.89  1718.72  1759.73  1.0  1.0    1.0    1.0   \n",
              "2022-02-23  1759.73  1792.64  1718.50  1718.50 -1.0  1.0   -1.0   -1.0   \n",
              "2022-02-25  1718.50  1718.50  1718.50  1718.50 -1.0 -1.0   -1.0   -1.0   \n",
              "\n",
              "            LWMA_1  MAE_1  MAE_2  MAE_3  MAE_4  MAE_5  MAE_6  \n",
              "Date                                                          \n",
              "2009-03-26     NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
              "2009-03-27     NaN    NaN    0.0    NaN    NaN    1.0    NaN  \n",
              "2009-03-30     NaN    NaN    0.0    NaN    NaN    1.0    NaN  \n",
              "2009-03-31     NaN    NaN    0.0    NaN    NaN    1.0    NaN  \n",
              "2009-04-01     NaN    NaN    0.0    NaN    NaN    1.0    NaN  \n",
              "...            ...    ...    ...    ...    ...    ...    ...  \n",
              "2022-02-18     1.0    1.0    1.0    1.0    1.0    1.0    1.0  \n",
              "2022-02-21     1.0    1.0    1.0    1.0    1.0    1.0    1.0  \n",
              "2022-02-22     1.0    1.0    1.0    1.0    1.0    1.0    1.0  \n",
              "2022-02-23    -1.0    1.0   -1.0    1.0   -1.0   -1.0   -1.0  \n",
              "2022-02-25    -1.0    1.0   -1.0    1.0   -1.0   -1.0   -1.0  \n",
              "\n",
              "[3187 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4e11837-ea51-4f45-a8a7-6a60bc247eb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>MAE_2</th>\n",
              "      <th>MAE_3</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-03-26</th>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-27</th>\n",
              "      <td>557.04</td>\n",
              "      <td>567.24</td>\n",
              "      <td>508.31</td>\n",
              "      <td>509.86</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-30</th>\n",
              "      <td>509.35</td>\n",
              "      <td>509.87</td>\n",
              "      <td>502.22</td>\n",
              "      <td>509.87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-31</th>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-04-01</th>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1796.03</td>\n",
              "      <td>1765.74</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1803.77</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1787.89</td>\n",
              "      <td>1718.72</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1792.64</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-25</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3187 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4e11837-ea51-4f45-a8a7-6a60bc247eb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4e11837-ea51-4f45-a8a7-6a60bc247eb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4e11837-ea51-4f45-a8a7-6a60bc247eb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#прибираэмо нулы на початку при розрахунку методів ТА - для кожного методу окремо (один раз)\n",
        "df = df.replace(0, np.nan)"
      ],
      "metadata": {
        "id": "HIQZq4z6vp78"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Percent change 1\"] = 100*df[\"Close\"].pct_change(periods=1)\n",
        "df[\"Percent change 5\"] = 100*df[\"Close\"].pct_change(periods=5)\n",
        "df[\"Percent change 30\"] = 100*df[\"Close\"].pct_change(periods=30)\n",
        "df[\"Percent change Open\"] = 100*df[\"Open\"].pct_change(periods=1)\n",
        "df[\"Percent change High\"] = 100*df[\"High\"].pct_change(periods=1)\n",
        "df[\"Percent change Low\"] = 100*df[\"Low\"].pct_change(periods=1)"
      ],
      "metadata": {
        "id": "8zBhla5mvlAs"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Y\"] = to_predict\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "lnsK1gKOBPGU",
        "outputId": "e01ca4fc-19c9-44c8-9465-3b300b683a24"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   DI  ERI  SMA_1  EMA_1  \\\n",
              "Date                                                                     \n",
              "2022-02-18  1785.48  1796.03  1765.74  1774.84  1.0  1.0    1.0    1.0   \n",
              "2022-02-21  1774.84  1803.77  1766.02  1766.02  1.0  1.0    1.0    1.0   \n",
              "2022-02-22  1766.02  1787.89  1718.72  1759.73  1.0  1.0    1.0    1.0   \n",
              "2022-02-23  1759.73  1792.64  1718.50  1718.50 -1.0  1.0   -1.0   -1.0   \n",
              "2022-02-25  1718.50  1718.50  1718.50  1718.50 -1.0 -1.0   -1.0   -1.0   \n",
              "\n",
              "            LWMA_1  MAE_1  ...  MAE_4  MAE_5  MAE_6  Percent change 1  \\\n",
              "Date                       ...                                          \n",
              "2022-02-18     1.0    1.0  ...    1.0    1.0    1.0         -0.595918   \n",
              "2022-02-21     1.0    1.0  ...    1.0    1.0    1.0         -0.496946   \n",
              "2022-02-22     1.0    1.0  ...    1.0    1.0    1.0         -0.356168   \n",
              "2022-02-23    -1.0    1.0  ...   -1.0   -1.0   -1.0         -2.342973   \n",
              "2022-02-25    -1.0    1.0  ...   -1.0   -1.0   -1.0          0.000000   \n",
              "\n",
              "            Percent change 5  Percent change 30  Percent change Open  \\\n",
              "Date                                                                   \n",
              "2022-02-18          3.565906           2.278569             3.967159   \n",
              "2022-02-21          4.124854           1.770299            -0.595918   \n",
              "2022-02-22          2.926244           0.735597            -0.496946   \n",
              "2022-02-23          0.066964          -0.354283            -0.356168   \n",
              "2022-02-25         -3.751372          -2.764025            -2.342973   \n",
              "\n",
              "            Percent change High  Percent change Low    Y  \n",
              "Date                                                      \n",
              "2022-02-18             0.590878            3.149864  0.0  \n",
              "2022-02-21             0.430950            0.015857  0.0  \n",
              "2022-02-22            -0.880378           -2.678339  0.0  \n",
              "2022-02-23             0.265676           -0.012800  0.0  \n",
              "2022-02-25            -4.135800            0.000000  NaN  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c747305-f220-4409-b428-5f3eabf4a8e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1796.03</td>\n",
              "      <td>1765.74</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.595918</td>\n",
              "      <td>3.565906</td>\n",
              "      <td>2.278569</td>\n",
              "      <td>3.967159</td>\n",
              "      <td>0.590878</td>\n",
              "      <td>3.149864</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1803.77</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.496946</td>\n",
              "      <td>4.124854</td>\n",
              "      <td>1.770299</td>\n",
              "      <td>-0.595918</td>\n",
              "      <td>0.430950</td>\n",
              "      <td>0.015857</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1787.89</td>\n",
              "      <td>1718.72</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.356168</td>\n",
              "      <td>2.926244</td>\n",
              "      <td>0.735597</td>\n",
              "      <td>-0.496946</td>\n",
              "      <td>-0.880378</td>\n",
              "      <td>-2.678339</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1792.64</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.342973</td>\n",
              "      <td>0.066964</td>\n",
              "      <td>-0.354283</td>\n",
              "      <td>-0.356168</td>\n",
              "      <td>0.265676</td>\n",
              "      <td>-0.012800</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-25</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.751372</td>\n",
              "      <td>-2.764025</td>\n",
              "      <td>-2.342973</td>\n",
              "      <td>-4.135800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c747305-f220-4409-b428-5f3eabf4a8e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c747305-f220-4409-b428-5f3eabf4a8e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c747305-f220-4409-b428-5f3eabf4a8e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "_mQPsmrp1ik7",
        "outputId": "37903ce0-7fa5-4310-b141-50657170dcf5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open    High     Low   Close  DI  ERI  SMA_1  EMA_1  LWMA_1  \\\n",
              "Date                                                                        \n",
              "2009-03-26  500.00  500.00  500.00  500.00 NaN  NaN    NaN    NaN     NaN   \n",
              "2009-03-27  557.04  567.24  508.31  509.86 NaN  NaN    NaN    NaN     NaN   \n",
              "2009-03-30  509.35  509.87  502.22  509.87 NaN  NaN    NaN    NaN     NaN   \n",
              "2009-03-31  509.70  511.46  509.70  511.46 NaN  1.0    NaN    NaN     NaN   \n",
              "2009-04-01  508.05  521.66  508.05  521.66 NaN  1.0    NaN    NaN     NaN   \n",
              "\n",
              "            MAE_1  ...  MAE_4  MAE_5  MAE_6  Percent change 1  \\\n",
              "Date               ...                                          \n",
              "2009-03-26    NaN  ...    NaN    NaN    NaN               NaN   \n",
              "2009-03-27    NaN  ...    NaN    1.0    NaN          1.972000   \n",
              "2009-03-30    NaN  ...    NaN    1.0    NaN          0.001961   \n",
              "2009-03-31    NaN  ...    NaN    1.0    NaN          0.311844   \n",
              "2009-04-01    NaN  ...    NaN    1.0    NaN          1.994291   \n",
              "\n",
              "            Percent change 5  Percent change 30  Percent change Open  \\\n",
              "Date                                                                   \n",
              "2009-03-26               NaN                NaN                  NaN   \n",
              "2009-03-27               NaN                NaN            11.408000   \n",
              "2009-03-30               NaN                NaN            -8.561324   \n",
              "2009-03-31               NaN                NaN             0.068715   \n",
              "2009-04-01               NaN                NaN            -0.323720   \n",
              "\n",
              "            Percent change High  Percent change Low    Y  \n",
              "Date                                                      \n",
              "2009-03-26                  NaN                 NaN  1.0  \n",
              "2009-03-27            13.448000            1.662000  1.0  \n",
              "2009-03-30           -10.113885           -1.198088  1.0  \n",
              "2009-03-31             0.311844            1.489387  1.0  \n",
              "2009-04-01             1.994291           -0.323720  1.0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4d61bfa-6046-4ab8-9d7d-5ddaba6552c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-03-26</th>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-27</th>\n",
              "      <td>557.04</td>\n",
              "      <td>567.24</td>\n",
              "      <td>508.31</td>\n",
              "      <td>509.86</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.972000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.408000</td>\n",
              "      <td>13.448000</td>\n",
              "      <td>1.662000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-30</th>\n",
              "      <td>509.35</td>\n",
              "      <td>509.87</td>\n",
              "      <td>502.22</td>\n",
              "      <td>509.87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-8.561324</td>\n",
              "      <td>-10.113885</td>\n",
              "      <td>-1.198088</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-31</th>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.311844</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.068715</td>\n",
              "      <td>0.311844</td>\n",
              "      <td>1.489387</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-04-01</th>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.994291</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.323720</td>\n",
              "      <td>1.994291</td>\n",
              "      <td>-0.323720</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4d61bfa-6046-4ab8-9d7d-5ddaba6552c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4d61bfa-6046-4ab8-9d7d-5ddaba6552c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4d61bfa-6046-4ab8-9d7d-5ddaba6552c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.copy()\n",
        "X_train, X_valid = train_test_split(X, train_size=0.8, random_state=42, shuffle=False)"
      ],
      "metadata": {
        "id": "bjHjVnE31wfj"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "JyoXJM9b5w1f",
        "outputId": "2405e8a9-6757-49b1-adf3-4716b65ab31d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   DI  ERI  SMA_1  EMA_1  \\\n",
              "Date                                                                     \n",
              "2009-03-26   500.00   500.00   500.00   500.00  NaN  NaN    NaN    NaN   \n",
              "2009-03-27   557.04   567.24   508.31   509.86  NaN  NaN    NaN    NaN   \n",
              "2009-03-30   509.35   509.87   502.22   509.87  NaN  NaN    NaN    NaN   \n",
              "2009-03-31   509.70   511.46   509.70   511.46  NaN  1.0    NaN    NaN   \n",
              "2009-04-01   508.05   521.66   508.05   521.66  NaN  1.0    NaN    NaN   \n",
              "...             ...      ...      ...      ...  ...  ...    ...    ...   \n",
              "2019-07-22  1593.63  1593.63  1587.99  1587.99 -1.0 -1.0   -1.0   -1.0   \n",
              "2019-07-23  1587.99  1604.56  1587.99  1597.37 -1.0 -1.0   -1.0    1.0   \n",
              "2019-07-24  1597.37  1598.31  1587.52  1587.52 -1.0 -1.0   -1.0   -1.0   \n",
              "2019-07-25  1587.52  1587.52  1587.52  1587.52 -1.0 -1.0   -1.0   -1.0   \n",
              "2019-07-26  1587.52  1587.52  1587.52  1587.52 -1.0 -1.0   -1.0   -1.0   \n",
              "\n",
              "            LWMA_1  MAE_1  ...  MAE_4  MAE_5  MAE_6  Percent change 1  \\\n",
              "Date                       ...                                          \n",
              "2009-03-26     NaN    NaN  ...    NaN    NaN    NaN               NaN   \n",
              "2009-03-27     NaN    NaN  ...    NaN    1.0    NaN          1.972000   \n",
              "2009-03-30     NaN    NaN  ...    NaN    1.0    NaN          0.001961   \n",
              "2009-03-31     NaN    NaN  ...    NaN    1.0    NaN          0.311844   \n",
              "2009-04-01     NaN    NaN  ...    NaN    1.0    NaN          1.994291   \n",
              "...            ...    ...  ...    ...    ...    ...               ...   \n",
              "2019-07-22    -1.0   -1.0  ...   -1.0   -1.0   -1.0         -0.353909   \n",
              "2019-07-23    -1.0   -1.0  ...   -1.0   -1.0   -1.0          0.590684   \n",
              "2019-07-24    -1.0   -1.0  ...   -1.0   -1.0   -1.0         -0.616639   \n",
              "2019-07-25    -1.0   -1.0  ...   -1.0   -1.0   -1.0          0.000000   \n",
              "2019-07-26    -1.0   -1.0  ...   -1.0   -1.0   -1.0          0.000000   \n",
              "\n",
              "            Percent change 5  Percent change 30  Percent change Open  \\\n",
              "Date                                                                   \n",
              "2009-03-26               NaN                NaN                  NaN   \n",
              "2009-03-27               NaN                NaN            11.408000   \n",
              "2009-03-30               NaN                NaN            -8.561324   \n",
              "2009-03-31               NaN                NaN             0.068715   \n",
              "2009-04-01               NaN                NaN            -0.323720   \n",
              "...                      ...                ...                  ...   \n",
              "2019-07-22         -0.402657          -8.052413            -0.048921   \n",
              "2019-07-23          0.185649          -6.610580            -0.353909   \n",
              "2019-07-24         -0.383401          -5.737053             0.590684   \n",
              "2019-07-25         -0.432135          -3.620778            -0.616639   \n",
              "2019-07-26         -0.383401          -3.620778             0.000000   \n",
              "\n",
              "            Percent change High  Percent change Low    Y  \n",
              "Date                                                      \n",
              "2009-03-26                  NaN                 NaN  1.0  \n",
              "2009-03-27            13.448000            1.662000  1.0  \n",
              "2009-03-30           -10.113885           -1.198088  1.0  \n",
              "2009-03-31             0.311844            1.489387  1.0  \n",
              "2009-04-01             1.994291           -0.323720  1.0  \n",
              "...                         ...                 ...  ...  \n",
              "2019-07-22            -0.244751            0.783808  1.0  \n",
              "2019-07-23             0.685856            0.000000  0.0  \n",
              "2019-07-24            -0.389515           -0.029597  0.0  \n",
              "2019-07-25            -0.675088            0.000000  0.0  \n",
              "2019-07-26             0.000000            0.000000  1.0  \n",
              "\n",
              "[2549 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b729903-1c56-4630-9fc6-abe44f949091\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-03-26</th>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-27</th>\n",
              "      <td>557.04</td>\n",
              "      <td>567.24</td>\n",
              "      <td>508.31</td>\n",
              "      <td>509.86</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.972000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.408000</td>\n",
              "      <td>13.448000</td>\n",
              "      <td>1.662000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-30</th>\n",
              "      <td>509.35</td>\n",
              "      <td>509.87</td>\n",
              "      <td>502.22</td>\n",
              "      <td>509.87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-8.561324</td>\n",
              "      <td>-10.113885</td>\n",
              "      <td>-1.198088</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-31</th>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>509.70</td>\n",
              "      <td>511.46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.311844</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.068715</td>\n",
              "      <td>0.311844</td>\n",
              "      <td>1.489387</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-04-01</th>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>508.05</td>\n",
              "      <td>521.66</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.994291</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.323720</td>\n",
              "      <td>1.994291</td>\n",
              "      <td>-0.323720</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-22</th>\n",
              "      <td>1593.63</td>\n",
              "      <td>1593.63</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.353909</td>\n",
              "      <td>-0.402657</td>\n",
              "      <td>-8.052413</td>\n",
              "      <td>-0.048921</td>\n",
              "      <td>-0.244751</td>\n",
              "      <td>0.783808</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-23</th>\n",
              "      <td>1587.99</td>\n",
              "      <td>1604.56</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1597.37</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.590684</td>\n",
              "      <td>0.185649</td>\n",
              "      <td>-6.610580</td>\n",
              "      <td>-0.353909</td>\n",
              "      <td>0.685856</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-24</th>\n",
              "      <td>1597.37</td>\n",
              "      <td>1598.31</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.616639</td>\n",
              "      <td>-0.383401</td>\n",
              "      <td>-5.737053</td>\n",
              "      <td>0.590684</td>\n",
              "      <td>-0.389515</td>\n",
              "      <td>-0.029597</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-25</th>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.432135</td>\n",
              "      <td>-3.620778</td>\n",
              "      <td>-0.616639</td>\n",
              "      <td>-0.675088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-26</th>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.383401</td>\n",
              "      <td>-3.620778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2549 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b729903-1c56-4630-9fc6-abe44f949091')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b729903-1c56-4630-9fc6-abe44f949091 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b729903-1c56-4630-9fc6-abe44f949091');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "PLznzOyp5w-q",
        "outputId": "b6ea68b8-aaf9-48a8-b019-1570dce83fcd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   DI  ERI  SMA_1  EMA_1  \\\n",
              "Date                                                                     \n",
              "2019-07-29  1587.52  1614.96  1587.52  1614.96  1.0 -1.0    1.0    1.0   \n",
              "2019-07-30  1614.96  1614.96  1603.24  1603.24  1.0  1.0    1.0    1.0   \n",
              "2019-07-31  1603.24  1610.91  1601.91  1601.91  1.0  1.0    1.0    1.0   \n",
              "2019-08-01  1601.91  1601.91  1601.91  1601.91  1.0  1.0    1.0    1.0   \n",
              "2019-08-02  1601.91  1601.91  1583.93  1583.93 -1.0  1.0   -1.0   -1.0   \n",
              "...             ...      ...      ...      ...  ...  ...    ...    ...   \n",
              "2022-02-18  1785.48  1796.03  1765.74  1774.84  1.0  1.0    1.0    1.0   \n",
              "2022-02-21  1774.84  1803.77  1766.02  1766.02  1.0  1.0    1.0    1.0   \n",
              "2022-02-22  1766.02  1787.89  1718.72  1759.73  1.0  1.0    1.0    1.0   \n",
              "2022-02-23  1759.73  1792.64  1718.50  1718.50 -1.0  1.0   -1.0   -1.0   \n",
              "2022-02-25  1718.50  1718.50  1718.50  1718.50 -1.0 -1.0   -1.0   -1.0   \n",
              "\n",
              "            LWMA_1  MAE_1  ...  MAE_4  MAE_5  MAE_6  Percent change 1  \\\n",
              "Date                       ...                                          \n",
              "2019-07-29     1.0    1.0  ...   -1.0   -1.0    1.0          1.728482   \n",
              "2019-07-30     1.0    1.0  ...   -1.0   -1.0   -1.0         -0.725715   \n",
              "2019-07-31     1.0    1.0  ...   -1.0   -1.0   -1.0         -0.082957   \n",
              "2019-08-01     1.0    1.0  ...   -1.0   -1.0   -1.0          0.000000   \n",
              "2019-08-02    -1.0   -1.0  ...   -1.0   -1.0   -1.0         -1.122410   \n",
              "...            ...    ...  ...    ...    ...    ...               ...   \n",
              "2022-02-18     1.0    1.0  ...    1.0    1.0    1.0         -0.595918   \n",
              "2022-02-21     1.0    1.0  ...    1.0    1.0    1.0         -0.496946   \n",
              "2022-02-22     1.0    1.0  ...    1.0    1.0    1.0         -0.356168   \n",
              "2022-02-23    -1.0    1.0  ...   -1.0   -1.0   -1.0         -2.342973   \n",
              "2022-02-25    -1.0    1.0  ...   -1.0   -1.0   -1.0          0.000000   \n",
              "\n",
              "            Percent change 5  Percent change 30  Percent change Open  \\\n",
              "Date                                                                   \n",
              "2019-07-29          1.698373          -1.954880             0.000000   \n",
              "2019-07-30          0.367479          -2.666408             1.728482   \n",
              "2019-07-31          0.906445          -2.515746            -0.725715   \n",
              "2019-08-01          0.906445          -0.488269            -0.082957   \n",
              "2019-08-02         -0.226139          -1.605198             0.000000   \n",
              "...                      ...                ...                  ...   \n",
              "2022-02-18          3.565906           2.278569             3.967159   \n",
              "2022-02-21          4.124854           1.770299            -0.595918   \n",
              "2022-02-22          2.926244           0.735597            -0.496946   \n",
              "2022-02-23          0.066964          -0.354283            -0.356168   \n",
              "2022-02-25         -3.751372          -2.764025            -2.342973   \n",
              "\n",
              "            Percent change High  Percent change Low    Y  \n",
              "Date                                                      \n",
              "2019-07-29             1.728482            0.000000  0.0  \n",
              "2019-07-30             0.000000            0.990224  0.0  \n",
              "2019-07-31            -0.250780           -0.082957  0.0  \n",
              "2019-08-01            -0.558690            0.000000  0.0  \n",
              "2019-08-02             0.000000           -1.122410  1.0  \n",
              "...                         ...                 ...  ...  \n",
              "2022-02-18             0.590878            3.149864  0.0  \n",
              "2022-02-21             0.430950            0.015857  0.0  \n",
              "2022-02-22            -0.880378           -2.678339  0.0  \n",
              "2022-02-23             0.265676           -0.012800  0.0  \n",
              "2022-02-25            -4.135800            0.000000  NaN  \n",
              "\n",
              "[638 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcf1533e-8758-4c7b-b838-c497c25325db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>1587.52</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.728482</td>\n",
              "      <td>1.698373</td>\n",
              "      <td>-1.954880</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.728482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-30</th>\n",
              "      <td>1614.96</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.725715</td>\n",
              "      <td>0.367479</td>\n",
              "      <td>-2.666408</td>\n",
              "      <td>1.728482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.990224</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-31</th>\n",
              "      <td>1603.24</td>\n",
              "      <td>1610.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.082957</td>\n",
              "      <td>0.906445</td>\n",
              "      <td>-2.515746</td>\n",
              "      <td>-0.725715</td>\n",
              "      <td>-0.250780</td>\n",
              "      <td>-0.082957</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906445</td>\n",
              "      <td>-0.488269</td>\n",
              "      <td>-0.082957</td>\n",
              "      <td>-0.558690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-02</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1583.93</td>\n",
              "      <td>1583.93</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.122410</td>\n",
              "      <td>-0.226139</td>\n",
              "      <td>-1.605198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.122410</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1796.03</td>\n",
              "      <td>1765.74</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.595918</td>\n",
              "      <td>3.565906</td>\n",
              "      <td>2.278569</td>\n",
              "      <td>3.967159</td>\n",
              "      <td>0.590878</td>\n",
              "      <td>3.149864</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1803.77</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.496946</td>\n",
              "      <td>4.124854</td>\n",
              "      <td>1.770299</td>\n",
              "      <td>-0.595918</td>\n",
              "      <td>0.430950</td>\n",
              "      <td>0.015857</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1787.89</td>\n",
              "      <td>1718.72</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.356168</td>\n",
              "      <td>2.926244</td>\n",
              "      <td>0.735597</td>\n",
              "      <td>-0.496946</td>\n",
              "      <td>-0.880378</td>\n",
              "      <td>-2.678339</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1792.64</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.342973</td>\n",
              "      <td>0.066964</td>\n",
              "      <td>-0.354283</td>\n",
              "      <td>-0.356168</td>\n",
              "      <td>0.265676</td>\n",
              "      <td>-0.012800</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-25</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.751372</td>\n",
              "      <td>-2.764025</td>\n",
              "      <td>-2.342973</td>\n",
              "      <td>-4.135800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>638 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcf1533e-8758-4c7b-b838-c497c25325db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcf1533e-8758-4c7b-b838-c497c25325db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcf1533e-8758-4c7b-b838-c497c25325db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.dropna()\n",
        "X_valid = X_valid.dropna()\n",
        "y_train = X_train.pop('Y')\n",
        "y_valid = X_valid.pop('Y')"
      ],
      "metadata": {
        "id": "MlUCMmkf15AB"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "wA8_ljMeFLgl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "outputId": "07a70571-b1fe-4059-99c1-f3de0865e9f6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   DI  ERI  SMA_1  EMA_1  \\\n",
              "Date                                                                     \n",
              "2009-06-17  1059.69  1059.69  1024.47  1025.18 -1.0 -1.0   -1.0   -1.0   \n",
              "2009-06-18  1026.92  1031.08   994.05  1008.52 -1.0 -1.0   -1.0   -1.0   \n",
              "2009-06-19  1009.33  1030.27  1009.33  1025.47 -1.0 -1.0   -1.0   -1.0   \n",
              "2009-06-22  1025.47  1025.47   977.64   977.64 -1.0 -1.0   -1.0   -1.0   \n",
              "2009-06-23   975.62   975.62   938.97   956.65 -1.0 -1.0   -1.0   -1.0   \n",
              "...             ...      ...      ...      ...  ...  ...    ...    ...   \n",
              "2019-07-22  1593.63  1593.63  1587.99  1587.99 -1.0 -1.0   -1.0   -1.0   \n",
              "2019-07-23  1587.99  1604.56  1587.99  1597.37 -1.0 -1.0   -1.0    1.0   \n",
              "2019-07-24  1597.37  1598.31  1587.52  1587.52 -1.0 -1.0   -1.0   -1.0   \n",
              "2019-07-25  1587.52  1587.52  1587.52  1587.52 -1.0 -1.0   -1.0   -1.0   \n",
              "2019-07-26  1587.52  1587.52  1587.52  1587.52 -1.0 -1.0   -1.0   -1.0   \n",
              "\n",
              "            LWMA_1  MAE_1  ...  MAE_3  MAE_4  MAE_5  MAE_6  Percent change 1  \\\n",
              "Date                       ...                                                 \n",
              "2009-06-17    -1.0   -1.0  ...   -1.0   -1.0   -1.0   -1.0         -3.064515   \n",
              "2009-06-18    -1.0   -1.0  ...   -1.0   -1.0   -1.0   -1.0         -1.625080   \n",
              "2009-06-19    -1.0   -1.0  ...   -1.0   -1.0   -1.0   -1.0          1.680681   \n",
              "2009-06-22    -1.0   -1.0  ...   -1.0   -1.0   -1.0   -1.0         -4.664203   \n",
              "2009-06-23    -1.0   -1.0  ...   -1.0   -1.0   -1.0   -1.0         -2.147007   \n",
              "...            ...    ...  ...    ...    ...    ...    ...               ...   \n",
              "2019-07-22    -1.0   -1.0  ...    1.0   -1.0   -1.0   -1.0         -0.353909   \n",
              "2019-07-23    -1.0   -1.0  ...    1.0   -1.0   -1.0   -1.0          0.590684   \n",
              "2019-07-24    -1.0   -1.0  ...    1.0   -1.0   -1.0   -1.0         -0.616639   \n",
              "2019-07-25    -1.0   -1.0  ...    1.0   -1.0   -1.0   -1.0          0.000000   \n",
              "2019-07-26    -1.0   -1.0  ...    1.0   -1.0   -1.0   -1.0          0.000000   \n",
              "\n",
              "            Percent change 5  Percent change 30  Percent change Open  \\\n",
              "Date                                                                   \n",
              "2009-06-17         -8.154453          28.439700             2.044373   \n",
              "2009-06-18         -9.233926          18.782168            -3.092414   \n",
              "2009-06-19         -7.501150          15.480856            -1.712889   \n",
              "2009-06-22         -5.964507           1.730471             1.599081   \n",
              "2009-06-23         -9.544341          -4.961305            -4.861186   \n",
              "...                      ...                ...                  ...   \n",
              "2019-07-22         -0.402657          -8.052413            -0.048921   \n",
              "2019-07-23          0.185649          -6.610580            -0.353909   \n",
              "2019-07-24         -0.383401          -5.737053             0.590684   \n",
              "2019-07-25         -0.432135          -3.620778            -0.616639   \n",
              "2019-07-26         -0.383401          -3.620778             0.000000   \n",
              "\n",
              "            Percent change High  Percent change Low  \n",
              "Date                                                 \n",
              "2009-06-17            -0.927441            0.669182  \n",
              "2009-06-18            -2.699846           -2.969340  \n",
              "2009-06-19            -0.078558            1.537146  \n",
              "2009-06-22            -0.465897           -3.139707  \n",
              "2009-06-23            -4.861186           -3.955444  \n",
              "...                         ...                 ...  \n",
              "2019-07-22            -0.244751            0.783808  \n",
              "2019-07-23             0.685856            0.000000  \n",
              "2019-07-24            -0.389515           -0.029597  \n",
              "2019-07-25            -0.675088            0.000000  \n",
              "2019-07-26             0.000000            0.000000  \n",
              "\n",
              "[2495 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff279d6c-2318-4360-ad15-d81eb2cd36d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_3</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-06-17</th>\n",
              "      <td>1059.69</td>\n",
              "      <td>1059.69</td>\n",
              "      <td>1024.47</td>\n",
              "      <td>1025.18</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.064515</td>\n",
              "      <td>-8.154453</td>\n",
              "      <td>28.439700</td>\n",
              "      <td>2.044373</td>\n",
              "      <td>-0.927441</td>\n",
              "      <td>0.669182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-18</th>\n",
              "      <td>1026.92</td>\n",
              "      <td>1031.08</td>\n",
              "      <td>994.05</td>\n",
              "      <td>1008.52</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.625080</td>\n",
              "      <td>-9.233926</td>\n",
              "      <td>18.782168</td>\n",
              "      <td>-3.092414</td>\n",
              "      <td>-2.699846</td>\n",
              "      <td>-2.969340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-19</th>\n",
              "      <td>1009.33</td>\n",
              "      <td>1030.27</td>\n",
              "      <td>1009.33</td>\n",
              "      <td>1025.47</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.680681</td>\n",
              "      <td>-7.501150</td>\n",
              "      <td>15.480856</td>\n",
              "      <td>-1.712889</td>\n",
              "      <td>-0.078558</td>\n",
              "      <td>1.537146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-22</th>\n",
              "      <td>1025.47</td>\n",
              "      <td>1025.47</td>\n",
              "      <td>977.64</td>\n",
              "      <td>977.64</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-4.664203</td>\n",
              "      <td>-5.964507</td>\n",
              "      <td>1.730471</td>\n",
              "      <td>1.599081</td>\n",
              "      <td>-0.465897</td>\n",
              "      <td>-3.139707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-23</th>\n",
              "      <td>975.62</td>\n",
              "      <td>975.62</td>\n",
              "      <td>938.97</td>\n",
              "      <td>956.65</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.147007</td>\n",
              "      <td>-9.544341</td>\n",
              "      <td>-4.961305</td>\n",
              "      <td>-4.861186</td>\n",
              "      <td>-4.861186</td>\n",
              "      <td>-3.955444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-22</th>\n",
              "      <td>1593.63</td>\n",
              "      <td>1593.63</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.353909</td>\n",
              "      <td>-0.402657</td>\n",
              "      <td>-8.052413</td>\n",
              "      <td>-0.048921</td>\n",
              "      <td>-0.244751</td>\n",
              "      <td>0.783808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-23</th>\n",
              "      <td>1587.99</td>\n",
              "      <td>1604.56</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1597.37</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.590684</td>\n",
              "      <td>0.185649</td>\n",
              "      <td>-6.610580</td>\n",
              "      <td>-0.353909</td>\n",
              "      <td>0.685856</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-24</th>\n",
              "      <td>1597.37</td>\n",
              "      <td>1598.31</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.616639</td>\n",
              "      <td>-0.383401</td>\n",
              "      <td>-5.737053</td>\n",
              "      <td>0.590684</td>\n",
              "      <td>-0.389515</td>\n",
              "      <td>-0.029597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-25</th>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.432135</td>\n",
              "      <td>-3.620778</td>\n",
              "      <td>-0.616639</td>\n",
              "      <td>-0.675088</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-26</th>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.383401</td>\n",
              "      <td>-3.620778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2495 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff279d6c-2318-4360-ad15-d81eb2cd36d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff279d6c-2318-4360-ad15-d81eb2cd36d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff279d6c-2318-4360-ad15-d81eb2cd36d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "P-JY6Eku2Jbt",
        "outputId": "658c7af4-2816-4dd9-d707-d5f547a4168a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close   DI  ERI  SMA_1  EMA_1  \\\n",
              "Date                                                                     \n",
              "2019-07-29  1587.52  1614.96  1587.52  1614.96  1.0 -1.0    1.0    1.0   \n",
              "2019-07-30  1614.96  1614.96  1603.24  1603.24  1.0  1.0    1.0    1.0   \n",
              "2019-07-31  1603.24  1610.91  1601.91  1601.91  1.0  1.0    1.0    1.0   \n",
              "2019-08-01  1601.91  1601.91  1601.91  1601.91  1.0  1.0    1.0    1.0   \n",
              "2019-08-02  1601.91  1601.91  1583.93  1583.93 -1.0  1.0   -1.0   -1.0   \n",
              "...             ...      ...      ...      ...  ...  ...    ...    ...   \n",
              "2022-02-17  1717.35  1785.48  1711.82  1785.48  1.0 -1.0    1.0    1.0   \n",
              "2022-02-18  1785.48  1796.03  1765.74  1774.84  1.0  1.0    1.0    1.0   \n",
              "2022-02-21  1774.84  1803.77  1766.02  1766.02  1.0  1.0    1.0    1.0   \n",
              "2022-02-22  1766.02  1787.89  1718.72  1759.73  1.0  1.0    1.0    1.0   \n",
              "2022-02-23  1759.73  1792.64  1718.50  1718.50 -1.0  1.0   -1.0   -1.0   \n",
              "\n",
              "            LWMA_1  MAE_1  ...  MAE_3  MAE_4  MAE_5  MAE_6  Percent change 1  \\\n",
              "Date                       ...                                                 \n",
              "2019-07-29     1.0    1.0  ...    1.0   -1.0   -1.0    1.0          1.728482   \n",
              "2019-07-30     1.0    1.0  ...    1.0   -1.0   -1.0   -1.0         -0.725715   \n",
              "2019-07-31     1.0    1.0  ...    1.0   -1.0   -1.0   -1.0         -0.082957   \n",
              "2019-08-01     1.0    1.0  ...    1.0   -1.0   -1.0   -1.0          0.000000   \n",
              "2019-08-02    -1.0   -1.0  ...    1.0   -1.0   -1.0   -1.0         -1.122410   \n",
              "...            ...    ...  ...    ...    ...    ...    ...               ...   \n",
              "2022-02-17     1.0    1.0  ...    1.0    1.0    1.0    1.0          3.967159   \n",
              "2022-02-18     1.0    1.0  ...    1.0    1.0    1.0    1.0         -0.595918   \n",
              "2022-02-21     1.0    1.0  ...    1.0    1.0    1.0    1.0         -0.496946   \n",
              "2022-02-22     1.0    1.0  ...    1.0    1.0    1.0    1.0         -0.356168   \n",
              "2022-02-23    -1.0    1.0  ...    1.0   -1.0   -1.0   -1.0         -2.342973   \n",
              "\n",
              "            Percent change 5  Percent change 30  Percent change Open  \\\n",
              "Date                                                                   \n",
              "2019-07-29          1.698373          -1.954880             0.000000   \n",
              "2019-07-30          0.367479          -2.666408             1.728482   \n",
              "2019-07-31          0.906445          -2.515746            -0.725715   \n",
              "2019-08-01          0.906445          -0.488269            -0.082957   \n",
              "2019-08-02         -0.226139          -1.605198             0.000000   \n",
              "...                      ...                ...                  ...   \n",
              "2022-02-17          5.402725           3.710502             0.447447   \n",
              "2022-02-18          3.565906           2.278569             3.967159   \n",
              "2022-02-21          4.124854           1.770299            -0.595918   \n",
              "2022-02-22          2.926244           0.735597            -0.496946   \n",
              "2022-02-23          0.066964          -0.354283            -0.356168   \n",
              "\n",
              "            Percent change High  Percent change Low  \n",
              "Date                                                 \n",
              "2019-07-29             1.728482            0.000000  \n",
              "2019-07-30             0.000000            0.990224  \n",
              "2019-07-31            -0.250780           -0.082957  \n",
              "2019-08-01            -0.558690            0.000000  \n",
              "2019-08-02             0.000000           -1.122410  \n",
              "...                         ...                 ...  \n",
              "2022-02-17             3.614807            1.761394  \n",
              "2022-02-18             0.590878            3.149864  \n",
              "2022-02-21             0.430950            0.015857  \n",
              "2022-02-22            -0.880378           -2.678339  \n",
              "2022-02-23             0.265676           -0.012800  \n",
              "\n",
              "[637 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-920ef7fd-a05e-4b78-b9fd-26b14f36120e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_3</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>1587.52</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.728482</td>\n",
              "      <td>1.698373</td>\n",
              "      <td>-1.954880</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.728482</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-30</th>\n",
              "      <td>1614.96</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.725715</td>\n",
              "      <td>0.367479</td>\n",
              "      <td>-2.666408</td>\n",
              "      <td>1.728482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.990224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-31</th>\n",
              "      <td>1603.24</td>\n",
              "      <td>1610.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.082957</td>\n",
              "      <td>0.906445</td>\n",
              "      <td>-2.515746</td>\n",
              "      <td>-0.725715</td>\n",
              "      <td>-0.250780</td>\n",
              "      <td>-0.082957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906445</td>\n",
              "      <td>-0.488269</td>\n",
              "      <td>-0.082957</td>\n",
              "      <td>-0.558690</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-02</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>1583.93</td>\n",
              "      <td>1583.93</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.122410</td>\n",
              "      <td>-0.226139</td>\n",
              "      <td>-1.605198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.122410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-17</th>\n",
              "      <td>1717.35</td>\n",
              "      <td>1785.48</td>\n",
              "      <td>1711.82</td>\n",
              "      <td>1785.48</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.967159</td>\n",
              "      <td>5.402725</td>\n",
              "      <td>3.710502</td>\n",
              "      <td>0.447447</td>\n",
              "      <td>3.614807</td>\n",
              "      <td>1.761394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1796.03</td>\n",
              "      <td>1765.74</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.595918</td>\n",
              "      <td>3.565906</td>\n",
              "      <td>2.278569</td>\n",
              "      <td>3.967159</td>\n",
              "      <td>0.590878</td>\n",
              "      <td>3.149864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1803.77</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.496946</td>\n",
              "      <td>4.124854</td>\n",
              "      <td>1.770299</td>\n",
              "      <td>-0.595918</td>\n",
              "      <td>0.430950</td>\n",
              "      <td>0.015857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1787.89</td>\n",
              "      <td>1718.72</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.356168</td>\n",
              "      <td>2.926244</td>\n",
              "      <td>0.735597</td>\n",
              "      <td>-0.496946</td>\n",
              "      <td>-0.880378</td>\n",
              "      <td>-2.678339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1792.64</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>1718.50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.342973</td>\n",
              "      <td>0.066964</td>\n",
              "      <td>-0.354283</td>\n",
              "      <td>-0.356168</td>\n",
              "      <td>0.265676</td>\n",
              "      <td>-0.012800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-920ef7fd-a05e-4b78-b9fd-26b14f36120e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-920ef7fd-a05e-4b78-b9fd-26b14f36120e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-920ef7fd-a05e-4b78-b9fd-26b14f36120e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIv1X86f2Jka",
        "outputId": "0d32a27b-023b-4b14-8327-af93dc94f52e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2009-06-17    0.0\n",
              "2009-06-18    1.0\n",
              "2009-06-19    0.0\n",
              "2009-06-22    0.0\n",
              "2009-06-23    1.0\n",
              "             ... \n",
              "2019-07-22    1.0\n",
              "2019-07-23    0.0\n",
              "2019-07-24    0.0\n",
              "2019-07-25    0.0\n",
              "2019-07-26    1.0\n",
              "Name: Y, Length: 2495, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kJ0ALYR2JsM",
        "outputId": "2fed4073-a28f-4b90-8065-b4da94f16d18"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2019-07-29    0.0\n",
              "2019-07-30    0.0\n",
              "2019-07-31    0.0\n",
              "2019-08-01    0.0\n",
              "2019-08-02    1.0\n",
              "             ... \n",
              "2022-02-17    0.0\n",
              "2022-02-18    0.0\n",
              "2022-02-21    0.0\n",
              "2022-02-22    0.0\n",
              "2022-02-23    0.0\n",
              "Name: Y, Length: 637, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Normalizer:\n",
        "    def fit(self, X: np.array) -> None:\n",
        "        self.mu = X.mean(axis=0)\n",
        "        self.sigma = X.std(axis=0)\n",
        "        \n",
        "    def transform(self, X: np.array) -> np.array:\n",
        "        return (X - self.mu[np.newaxis, :]) / self.sigma[np.newaxis, :]"
      ],
      "metadata": {
        "id": "jt6Yf2cJPNeU"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_train)\n",
        "X_train_transformed = normalizer.transform(X_train)\n",
        "X_test_transformed = normalizer.transform(X_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BfNQw39PeRt",
        "outputId": "ccd5b244-27fa-4fb3-a498-874dbf32083d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_transformed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "JMt6iQIYPiy8",
        "outputId": "f1ecce1a-a696-4387-e540-89d87387c8b7"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Open      High       Low     Close        DI       ERI  \\\n",
              "Date                                                                     \n",
              "2009-06-17 -0.497473 -0.518744 -0.542088 -0.564172 -1.072567 -1.086495   \n",
              "2009-06-18 -0.560485 -0.573347 -0.601106 -0.596222 -1.072567 -1.086495   \n",
              "2009-06-19 -0.594308 -0.574893 -0.571461 -0.563614 -1.072567 -1.086495   \n",
              "2009-06-22 -0.563273 -0.584054 -0.632943 -0.655628 -1.072567 -1.086495   \n",
              "2009-06-23 -0.659128 -0.679194 -0.707967 -0.696008 -1.072567 -1.086495   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2019-07-22  0.529216  0.500291  0.551198  0.518546 -1.072567 -1.086495   \n",
              "2019-07-23  0.518371  0.521151  0.551198  0.536591 -1.072567 -1.086495   \n",
              "2019-07-24  0.536408  0.509223  0.550286  0.517642 -1.072567 -1.086495   \n",
              "2019-07-25  0.517468  0.488630  0.550286  0.517642 -1.072567 -1.086495   \n",
              "2019-07-26  0.517468  0.488630  0.550286  0.517642 -1.072567 -1.086495   \n",
              "\n",
              "               SMA_1     EMA_1    LWMA_1     MAE_1  ...     MAE_3     MAE_4  \\\n",
              "Date                                                ...                       \n",
              "2009-06-17 -1.072567 -1.079505 -1.056292 -1.304783  ... -1.548619 -0.765445   \n",
              "2009-06-18 -1.072567 -1.079505 -1.056292 -1.304783  ... -1.548619 -0.765445   \n",
              "2009-06-19 -1.072567 -1.079505 -1.056292 -1.304783  ... -1.548619 -0.765445   \n",
              "2009-06-22 -1.072567 -1.079505 -1.056292 -1.304783  ... -1.548619 -0.765445   \n",
              "2009-06-23 -1.072567 -1.079505 -1.056292 -1.304783  ... -1.548619 -0.765445   \n",
              "...              ...       ...       ...       ...  ...       ...       ...   \n",
              "2019-07-22 -1.072567 -1.079505 -1.056292 -1.304783  ...  0.645478 -0.765445   \n",
              "2019-07-23 -1.072567  0.925979 -1.056292 -1.304783  ...  0.645478 -0.765445   \n",
              "2019-07-24 -1.072567 -1.079505 -1.056292 -1.304783  ...  0.645478 -0.765445   \n",
              "2019-07-25 -1.072567 -1.079505 -1.056292 -1.304783  ...  0.645478 -0.765445   \n",
              "2019-07-26 -1.072567 -1.079505 -1.056292 -1.304783  ...  0.645478 -0.765445   \n",
              "\n",
              "               MAE_5     MAE_6  Percent change 1  Percent change 5  \\\n",
              "Date                                                                 \n",
              "2009-06-17 -0.747113 -0.786658         -1.717798         -1.908294   \n",
              "2009-06-18 -0.747113 -0.786658         -0.919394         -2.155682   \n",
              "2009-06-19 -0.747113 -0.786658          0.914198         -1.758574   \n",
              "2009-06-22 -0.747113 -0.786658         -2.605090         -1.406414   \n",
              "2009-06-23 -0.747113 -0.786658         -1.208888         -2.226821   \n",
              "...              ...       ...               ...               ...   \n",
              "2019-07-22 -0.747113 -0.786658         -0.214319         -0.131778   \n",
              "2019-07-23 -0.747113 -0.786658          0.309614          0.003046   \n",
              "2019-07-24 -0.747113 -0.786658         -0.360046         -0.127365   \n",
              "2019-07-25 -0.747113 -0.786658         -0.018018         -0.138534   \n",
              "2019-07-26 -0.747113 -0.786658         -0.018018         -0.127365   \n",
              "\n",
              "            Percent change 30  Percent change Open  Percent change High  \\\n",
              "Date                                                                      \n",
              "2009-06-17           2.346694             1.118445            -0.568257   \n",
              "2009-06-18           1.515164            -1.738106            -1.620261   \n",
              "2009-06-19           1.230916            -0.970957            -0.064406   \n",
              "2009-06-22           0.046985             0.870819            -0.294309   \n",
              "2009-06-23          -0.529187            -2.721715            -2.903115   \n",
              "...                       ...                  ...                  ...   \n",
              "2019-07-22          -0.795337            -0.045629            -0.163049   \n",
              "2019-07-23          -0.671193            -0.215232             0.389309   \n",
              "2019-07-24          -0.595981             0.310053            -0.248973   \n",
              "2019-07-25          -0.413766            -0.361335            -0.418474   \n",
              "2019-07-26          -0.413766            -0.018425            -0.017778   \n",
              "\n",
              "            Percent change Low  \n",
              "Date                            \n",
              "2009-06-17            0.341857  \n",
              "2009-06-18           -1.619822  \n",
              "2009-06-19            0.809813  \n",
              "2009-06-22           -1.711673  \n",
              "2009-06-23           -2.151471  \n",
              "...                        ...  \n",
              "2019-07-22            0.403657  \n",
              "2019-07-23           -0.018927  \n",
              "2019-07-24           -0.034884  \n",
              "2019-07-25           -0.018927  \n",
              "2019-07-26           -0.018927  \n",
              "\n",
              "[2495 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f87c9239-a3d2-4289-bf7e-d2bcab63c570\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_3</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-06-17</th>\n",
              "      <td>-0.497473</td>\n",
              "      <td>-0.518744</td>\n",
              "      <td>-0.542088</td>\n",
              "      <td>-0.564172</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.548619</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-1.717798</td>\n",
              "      <td>-1.908294</td>\n",
              "      <td>2.346694</td>\n",
              "      <td>1.118445</td>\n",
              "      <td>-0.568257</td>\n",
              "      <td>0.341857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-18</th>\n",
              "      <td>-0.560485</td>\n",
              "      <td>-0.573347</td>\n",
              "      <td>-0.601106</td>\n",
              "      <td>-0.596222</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.548619</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.919394</td>\n",
              "      <td>-2.155682</td>\n",
              "      <td>1.515164</td>\n",
              "      <td>-1.738106</td>\n",
              "      <td>-1.620261</td>\n",
              "      <td>-1.619822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-19</th>\n",
              "      <td>-0.594308</td>\n",
              "      <td>-0.574893</td>\n",
              "      <td>-0.571461</td>\n",
              "      <td>-0.563614</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.548619</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>0.914198</td>\n",
              "      <td>-1.758574</td>\n",
              "      <td>1.230916</td>\n",
              "      <td>-0.970957</td>\n",
              "      <td>-0.064406</td>\n",
              "      <td>0.809813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-22</th>\n",
              "      <td>-0.563273</td>\n",
              "      <td>-0.584054</td>\n",
              "      <td>-0.632943</td>\n",
              "      <td>-0.655628</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.548619</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-2.605090</td>\n",
              "      <td>-1.406414</td>\n",
              "      <td>0.046985</td>\n",
              "      <td>0.870819</td>\n",
              "      <td>-0.294309</td>\n",
              "      <td>-1.711673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-23</th>\n",
              "      <td>-0.659128</td>\n",
              "      <td>-0.679194</td>\n",
              "      <td>-0.707967</td>\n",
              "      <td>-0.696008</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.548619</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-1.208888</td>\n",
              "      <td>-2.226821</td>\n",
              "      <td>-0.529187</td>\n",
              "      <td>-2.721715</td>\n",
              "      <td>-2.903115</td>\n",
              "      <td>-2.151471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-22</th>\n",
              "      <td>0.529216</td>\n",
              "      <td>0.500291</td>\n",
              "      <td>0.551198</td>\n",
              "      <td>0.518546</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.214319</td>\n",
              "      <td>-0.131778</td>\n",
              "      <td>-0.795337</td>\n",
              "      <td>-0.045629</td>\n",
              "      <td>-0.163049</td>\n",
              "      <td>0.403657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-23</th>\n",
              "      <td>0.518371</td>\n",
              "      <td>0.521151</td>\n",
              "      <td>0.551198</td>\n",
              "      <td>0.536591</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>0.309614</td>\n",
              "      <td>0.003046</td>\n",
              "      <td>-0.671193</td>\n",
              "      <td>-0.215232</td>\n",
              "      <td>0.389309</td>\n",
              "      <td>-0.018927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-24</th>\n",
              "      <td>0.536408</td>\n",
              "      <td>0.509223</td>\n",
              "      <td>0.550286</td>\n",
              "      <td>0.517642</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.360046</td>\n",
              "      <td>-0.127365</td>\n",
              "      <td>-0.595981</td>\n",
              "      <td>0.310053</td>\n",
              "      <td>-0.248973</td>\n",
              "      <td>-0.034884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-25</th>\n",
              "      <td>0.517468</td>\n",
              "      <td>0.488630</td>\n",
              "      <td>0.550286</td>\n",
              "      <td>0.517642</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.018018</td>\n",
              "      <td>-0.138534</td>\n",
              "      <td>-0.413766</td>\n",
              "      <td>-0.361335</td>\n",
              "      <td>-0.418474</td>\n",
              "      <td>-0.018927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-26</th>\n",
              "      <td>0.517468</td>\n",
              "      <td>0.488630</td>\n",
              "      <td>0.550286</td>\n",
              "      <td>0.517642</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.018018</td>\n",
              "      <td>-0.127365</td>\n",
              "      <td>-0.413766</td>\n",
              "      <td>-0.018425</td>\n",
              "      <td>-0.017778</td>\n",
              "      <td>-0.018927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2495 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f87c9239-a3d2-4289-bf7e-d2bcab63c570')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f87c9239-a3d2-4289-bf7e-d2bcab63c570 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f87c9239-a3d2-4289-bf7e-d2bcab63c570');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_transformed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "WbQFBSx2PjPF",
        "outputId": "79954860-48b4-484d-ee60-2d91bd89f3fc"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Open      High       Low     Close        DI       ERI  \\\n",
              "Date                                                                     \n",
              "2019-07-29  0.517468  0.541000  0.550286  0.570430  0.931969 -1.086495   \n",
              "2019-07-30  0.570231  0.541000  0.580785  0.547884  0.931969  0.920022   \n",
              "2019-07-31  0.547695  0.533270  0.578204  0.545325  0.931969  0.920022   \n",
              "2019-08-01  0.545138  0.516094  0.578204  0.545325  0.931969  0.920022   \n",
              "2019-08-02  0.545138  0.516094  0.543321  0.510736 -1.072567  0.920022   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-02-17  0.767112  0.866441  0.791441  0.898472  0.931969 -1.086495   \n",
              "2022-02-18  0.898116  0.886576  0.896051  0.878003  0.931969  0.920022   \n",
              "2022-02-21  0.877657  0.901347  0.896594  0.861035  0.931969  0.920022   \n",
              "2022-02-22  0.860697  0.871040  0.804828  0.848934  0.931969  0.920022   \n",
              "2022-02-23  0.848603  0.880106  0.804401  0.769617 -1.072567  0.920022   \n",
              "\n",
              "               SMA_1     EMA_1    LWMA_1     MAE_1  ...     MAE_3     MAE_4  \\\n",
              "Date                                                ...                       \n",
              "2019-07-29  0.931969  0.925979  0.946328  0.766104  ...  0.645478 -0.765445   \n",
              "2019-07-30  0.931969  0.925979  0.946328  0.766104  ...  0.645478 -0.765445   \n",
              "2019-07-31  0.931969  0.925979  0.946328  0.766104  ...  0.645478 -0.765445   \n",
              "2019-08-01  0.931969  0.925979  0.946328  0.766104  ...  0.645478 -0.765445   \n",
              "2019-08-02 -1.072567 -1.079505 -1.056292 -1.304783  ...  0.645478 -0.765445   \n",
              "...              ...       ...       ...       ...  ...       ...       ...   \n",
              "2022-02-17  0.931969  0.925979  0.946328  0.766104  ...  0.645478  1.305906   \n",
              "2022-02-18  0.931969  0.925979  0.946328  0.766104  ...  0.645478  1.305906   \n",
              "2022-02-21  0.931969  0.925979  0.946328  0.766104  ...  0.645478  1.305906   \n",
              "2022-02-22  0.931969  0.925979  0.946328  0.766104  ...  0.645478  1.305906   \n",
              "2022-02-23 -1.072567 -1.079505 -1.056292  0.766104  ...  0.645478 -0.765445   \n",
              "\n",
              "               MAE_5     MAE_6  Percent change 1  Percent change 5  \\\n",
              "Date                                                                 \n",
              "2019-07-29 -0.747113  1.270691          0.940712          0.349725   \n",
              "2019-07-30 -0.747113 -0.786658         -0.420546          0.044717   \n",
              "2019-07-31 -0.747113 -0.786658         -0.064031          0.168235   \n",
              "2019-08-01 -0.747113 -0.786658         -0.018018          0.168235   \n",
              "2019-08-02 -0.747113 -0.786658         -0.640580         -0.091325   \n",
              "...              ...       ...               ...               ...   \n",
              "2022-02-17  1.337950  1.270691          2.182428          1.198669   \n",
              "2022-02-18  1.337950  1.270691         -0.348553          0.777716   \n",
              "2022-02-21  1.337950  1.270691         -0.293657          0.905813   \n",
              "2022-02-22  1.337950  1.270691         -0.215572          0.631122   \n",
              "2022-02-23 -0.747113 -0.786658         -1.317584         -0.024153   \n",
              "\n",
              "            Percent change 30  Percent change Open  Percent change High  \\\n",
              "Date                                                                      \n",
              "2019-07-29          -0.270329            -0.018425             1.008155   \n",
              "2019-07-30          -0.331593             0.942779            -0.017778   \n",
              "2019-07-31          -0.318621            -0.421992            -0.166628   \n",
              "2019-08-01          -0.144052            -0.064557            -0.349386   \n",
              "2019-08-02          -0.240221            -0.018425            -0.017778   \n",
              "...                       ...                  ...                  ...   \n",
              "2022-02-17           0.217469             0.230399             2.127776   \n",
              "2022-02-18           0.094177             2.187700             0.332935   \n",
              "2022-02-21           0.050415            -0.349813             0.238011   \n",
              "2022-02-22          -0.038675            -0.294775            -0.540323   \n",
              "2022-02-23          -0.132515            -0.216489             0.139913   \n",
              "\n",
              "            Percent change Low  \n",
              "Date                            \n",
              "2019-07-29           -0.018927  \n",
              "2019-07-30            0.514944  \n",
              "2019-07-31           -0.063652  \n",
              "2019-08-01           -0.018927  \n",
              "2019-08-02           -0.624065  \n",
              "...                        ...  \n",
              "2022-02-17            0.930714  \n",
              "2022-02-18            1.679296  \n",
              "2022-02-21           -0.010377  \n",
              "2022-02-22           -1.462931  \n",
              "2022-02-23           -0.025828  \n",
              "\n",
              "[637 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e020e9a2-9951-44be-80df-b953bef8e821\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>DI</th>\n",
              "      <th>ERI</th>\n",
              "      <th>SMA_1</th>\n",
              "      <th>EMA_1</th>\n",
              "      <th>LWMA_1</th>\n",
              "      <th>MAE_1</th>\n",
              "      <th>...</th>\n",
              "      <th>MAE_3</th>\n",
              "      <th>MAE_4</th>\n",
              "      <th>MAE_5</th>\n",
              "      <th>MAE_6</th>\n",
              "      <th>Percent change 1</th>\n",
              "      <th>Percent change 5</th>\n",
              "      <th>Percent change 30</th>\n",
              "      <th>Percent change Open</th>\n",
              "      <th>Percent change High</th>\n",
              "      <th>Percent change Low</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>0.517468</td>\n",
              "      <td>0.541000</td>\n",
              "      <td>0.550286</td>\n",
              "      <td>0.570430</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>1.270691</td>\n",
              "      <td>0.940712</td>\n",
              "      <td>0.349725</td>\n",
              "      <td>-0.270329</td>\n",
              "      <td>-0.018425</td>\n",
              "      <td>1.008155</td>\n",
              "      <td>-0.018927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-30</th>\n",
              "      <td>0.570231</td>\n",
              "      <td>0.541000</td>\n",
              "      <td>0.580785</td>\n",
              "      <td>0.547884</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.420546</td>\n",
              "      <td>0.044717</td>\n",
              "      <td>-0.331593</td>\n",
              "      <td>0.942779</td>\n",
              "      <td>-0.017778</td>\n",
              "      <td>0.514944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-31</th>\n",
              "      <td>0.547695</td>\n",
              "      <td>0.533270</td>\n",
              "      <td>0.578204</td>\n",
              "      <td>0.545325</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.064031</td>\n",
              "      <td>0.168235</td>\n",
              "      <td>-0.318621</td>\n",
              "      <td>-0.421992</td>\n",
              "      <td>-0.166628</td>\n",
              "      <td>-0.063652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>0.545138</td>\n",
              "      <td>0.516094</td>\n",
              "      <td>0.578204</td>\n",
              "      <td>0.545325</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.018018</td>\n",
              "      <td>0.168235</td>\n",
              "      <td>-0.144052</td>\n",
              "      <td>-0.064557</td>\n",
              "      <td>-0.349386</td>\n",
              "      <td>-0.018927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-02</th>\n",
              "      <td>0.545138</td>\n",
              "      <td>0.516094</td>\n",
              "      <td>0.543321</td>\n",
              "      <td>0.510736</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>-1.304783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-0.640580</td>\n",
              "      <td>-0.091325</td>\n",
              "      <td>-0.240221</td>\n",
              "      <td>-0.018425</td>\n",
              "      <td>-0.017778</td>\n",
              "      <td>-0.624065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-17</th>\n",
              "      <td>0.767112</td>\n",
              "      <td>0.866441</td>\n",
              "      <td>0.791441</td>\n",
              "      <td>0.898472</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>-1.086495</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>1.305906</td>\n",
              "      <td>1.337950</td>\n",
              "      <td>1.270691</td>\n",
              "      <td>2.182428</td>\n",
              "      <td>1.198669</td>\n",
              "      <td>0.217469</td>\n",
              "      <td>0.230399</td>\n",
              "      <td>2.127776</td>\n",
              "      <td>0.930714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>0.898116</td>\n",
              "      <td>0.886576</td>\n",
              "      <td>0.896051</td>\n",
              "      <td>0.878003</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>1.305906</td>\n",
              "      <td>1.337950</td>\n",
              "      <td>1.270691</td>\n",
              "      <td>-0.348553</td>\n",
              "      <td>0.777716</td>\n",
              "      <td>0.094177</td>\n",
              "      <td>2.187700</td>\n",
              "      <td>0.332935</td>\n",
              "      <td>1.679296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>0.877657</td>\n",
              "      <td>0.901347</td>\n",
              "      <td>0.896594</td>\n",
              "      <td>0.861035</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>1.305906</td>\n",
              "      <td>1.337950</td>\n",
              "      <td>1.270691</td>\n",
              "      <td>-0.293657</td>\n",
              "      <td>0.905813</td>\n",
              "      <td>0.050415</td>\n",
              "      <td>-0.349813</td>\n",
              "      <td>0.238011</td>\n",
              "      <td>-0.010377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>0.860697</td>\n",
              "      <td>0.871040</td>\n",
              "      <td>0.804828</td>\n",
              "      <td>0.848934</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>0.931969</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>1.305906</td>\n",
              "      <td>1.337950</td>\n",
              "      <td>1.270691</td>\n",
              "      <td>-0.215572</td>\n",
              "      <td>0.631122</td>\n",
              "      <td>-0.038675</td>\n",
              "      <td>-0.294775</td>\n",
              "      <td>-0.540323</td>\n",
              "      <td>-1.462931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>0.848603</td>\n",
              "      <td>0.880106</td>\n",
              "      <td>0.804401</td>\n",
              "      <td>0.769617</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>0.920022</td>\n",
              "      <td>-1.072567</td>\n",
              "      <td>-1.079505</td>\n",
              "      <td>-1.056292</td>\n",
              "      <td>0.766104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645478</td>\n",
              "      <td>-0.765445</td>\n",
              "      <td>-0.747113</td>\n",
              "      <td>-0.786658</td>\n",
              "      <td>-1.317584</td>\n",
              "      <td>-0.024153</td>\n",
              "      <td>-0.132515</td>\n",
              "      <td>-0.216489</td>\n",
              "      <td>0.139913</td>\n",
              "      <td>-0.025828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e020e9a2-9951-44be-80df-b953bef8e821')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e020e9a2-9951-44be-80df-b953bef8e821 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e020e9a2-9951-44be-80df-b953bef8e821');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network(nodes_first, nodes_second, batch, dropout_include, SEED, X_train, y_train, X_valid, y_valid, count, rate_=None):\n",
        "  from tensorflow.python.framework import ops\n",
        "  ops.reset_default_graph()\n",
        "\n",
        "  seed(SEED)\n",
        "  tensorflow.random.set_seed(SEED)\n",
        "  random.seed(SEED)\n",
        "  numpy.random.seed(SEED)\n",
        "\n",
        "  if dropout_include==False:\n",
        "      model = keras.Sequential([\n",
        "          layers.Dense(nodes_first, activation='relu'),\n",
        "          layers.Dense(nodes_second, activation='relu'),  \n",
        "          layers.Dense(1, activation='sigmoid')\n",
        "      ])\n",
        "  else:\n",
        "      model = keras.Sequential([\n",
        "          layers.Dense(nodes_first, activation='relu'),\n",
        "          layers.Dropout(rate=rate_),\n",
        "          layers.Dense(nodes_second, activation='relu'),\n",
        "          layers.Dropout(rate=rate_),    \n",
        "          layers.Dense(1, activation='sigmoid')\n",
        "      ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['binary_accuracy'])\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(\n",
        "      patience=3,\n",
        "      min_delta=0.001,\n",
        "      restore_best_weights=False,\n",
        "  )\n",
        "\n",
        "  history = model.fit(\n",
        "      X_train, y_train,\n",
        "      validation_data=(X_valid, y_valid),\n",
        "      batch_size=batch,\n",
        "      epochs=20,\n",
        "      verbose=0,\n",
        "      callbacks=[early_stopping]\n",
        "  )\n",
        "\n",
        "  print(\"model \"+str(count) + \":\"+\n",
        "        \" nodes_first= \"+str(nodes_first)+\n",
        "        \", nodes_second=\" + str(nodes_second) +\n",
        "        \", batch=\" + str(batch) +\n",
        "        \", dropout_include=\" + str(dropout_include) +\n",
        "        \", rate=\" + str(rate_) +\n",
        "        \". Binary accuracy: \" + str(history.history['binary_accuracy'][-1]))\n",
        "  \n",
        "  return (history.history['binary_accuracy'][-1])"
      ],
      "metadata": {
        "id": "4tjXtZmSLsBd"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "accuracy_list = []\n",
        "for dropout_include in [True, False]:\n",
        "  for batch in [32, 64, 128, 256, 512, 1024]:\n",
        "    for nodes_first in [2, 4, 8, 12, 16, 24, 32]:\n",
        "      for nodes_second in [2, 4, 8, 12, 16, 24, 32]:\n",
        "        if dropout_include == True:\n",
        "          for rate__ in [0.1, 0.2, 0.3, 0.4]:\n",
        "            acc = neural_network(nodes_first, nodes_second, batch, dropout_include, SEED, X_train_transformed, y_train, X_test_transformed, y_valid, i, rate_=rate__)\n",
        "            i=i+1\n",
        "            accuracy_list.append(acc)\n",
        "        else:\n",
        "          acc = neural_network(nodes_first, nodes_second, batch, dropout_include, SEED, X_train_transformed, y_train, X_test_transformed, y_valid, i)\n",
        "          i=i+1\n",
        "          accuracy_list.append(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iie95NzbLsr1",
        "outputId": "de80df17-97b7-44ca-be2f-d18adb565dbb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 0: nodes_first= 2, nodes_second=2, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5422845482826233\n",
            "model 1: nodes_first= 2, nodes_second=2, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5194388628005981\n",
            "model 2: nodes_first= 2, nodes_second=2, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5206412672996521\n",
            "model 3: nodes_first= 2, nodes_second=2, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5194388628005981\n",
            "model 4: nodes_first= 2, nodes_second=4, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.4985972046852112\n",
            "model 5: nodes_first= 2, nodes_second=4, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.4989979863166809\n",
            "model 6: nodes_first= 2, nodes_second=4, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5050100088119507\n",
            "model 7: nodes_first= 2, nodes_second=4, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.510220468044281\n",
            "model 8: nodes_first= 2, nodes_second=8, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5326653122901917\n",
            "model 9: nodes_first= 2, nodes_second=8, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.524248480796814\n",
            "model 10: nodes_first= 2, nodes_second=8, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.52304607629776\n",
            "model 11: nodes_first= 2, nodes_second=8, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 12: nodes_first= 2, nodes_second=12, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5318637490272522\n",
            "model 13: nodes_first= 2, nodes_second=12, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5174348950386047\n",
            "model 14: nodes_first= 2, nodes_second=12, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5234469175338745\n",
            "model 15: nodes_first= 2, nodes_second=12, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5238476991653442\n",
            "model 16: nodes_first= 2, nodes_second=16, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.524248480796814\n",
            "model 17: nodes_first= 2, nodes_second=16, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5006012320518494\n",
            "model 18: nodes_first= 2, nodes_second=16, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.4949899911880493\n",
            "model 19: nodes_first= 2, nodes_second=16, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.496593177318573\n",
            "model 20: nodes_first= 2, nodes_second=24, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5186372995376587\n",
            "model 21: nodes_first= 2, nodes_second=24, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.504609227180481\n",
            "model 22: nodes_first= 2, nodes_second=24, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5106212496757507\n",
            "model 23: nodes_first= 2, nodes_second=24, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5054108500480652\n",
            "model 24: nodes_first= 2, nodes_second=32, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.531062126159668\n",
            "model 25: nodes_first= 2, nodes_second=32, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5210421085357666\n",
            "model 26: nodes_first= 2, nodes_second=32, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5226452946662903\n",
            "model 27: nodes_first= 2, nodes_second=32, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5162324905395508\n",
            "model 28: nodes_first= 4, nodes_second=2, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.536673367023468\n",
            "model 29: nodes_first= 4, nodes_second=2, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5346693396568298\n",
            "model 30: nodes_first= 4, nodes_second=2, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5070140361785889\n",
            "model 31: nodes_first= 4, nodes_second=2, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5030060410499573\n",
            "model 32: nodes_first= 4, nodes_second=4, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5262525081634521\n",
            "model 33: nodes_first= 4, nodes_second=4, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5150300860404968\n",
            "model 34: nodes_first= 4, nodes_second=4, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5178356766700745\n",
            "model 35: nodes_first= 4, nodes_second=4, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.524248480796814\n",
            "model 36: nodes_first= 4, nodes_second=8, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5222445130348206\n",
            "model 37: nodes_first= 4, nodes_second=8, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5226452946662903\n",
            "model 38: nodes_first= 4, nodes_second=8, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5078156590461731\n",
            "model 39: nodes_first= 4, nodes_second=8, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5074148178100586\n",
            "model 40: nodes_first= 4, nodes_second=12, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5394789576530457\n",
            "model 41: nodes_first= 4, nodes_second=12, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5458917617797852\n",
            "model 42: nodes_first= 4, nodes_second=12, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5190380811691284\n",
            "model 43: nodes_first= 4, nodes_second=12, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.511422872543335\n",
            "model 44: nodes_first= 4, nodes_second=16, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5262525081634521\n",
            "model 45: nodes_first= 4, nodes_second=16, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5174348950386047\n",
            "model 46: nodes_first= 4, nodes_second=16, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.504609227180481\n",
            "model 47: nodes_first= 4, nodes_second=16, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5054108500480652\n",
            "model 48: nodes_first= 4, nodes_second=24, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5250501036643982\n",
            "model 49: nodes_first= 4, nodes_second=24, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5158316493034363\n",
            "model 50: nodes_first= 4, nodes_second=24, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.503406822681427\n",
            "model 51: nodes_first= 4, nodes_second=24, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.511422872543335\n",
            "model 52: nodes_first= 4, nodes_second=32, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5322645306587219\n",
            "model 53: nodes_first= 4, nodes_second=32, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5302605032920837\n",
            "model 54: nodes_first= 4, nodes_second=32, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5294589400291443\n",
            "model 55: nodes_first= 4, nodes_second=32, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5094188451766968\n",
            "model 56: nodes_first= 8, nodes_second=2, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5150300860404968\n",
            "model 57: nodes_first= 8, nodes_second=2, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5122244358062744\n",
            "model 58: nodes_first= 8, nodes_second=2, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5222445130348206\n",
            "model 59: nodes_first= 8, nodes_second=2, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5198397040367126\n",
            "model 60: nodes_first= 8, nodes_second=4, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5426853895187378\n",
            "model 61: nodes_first= 8, nodes_second=4, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5258517265319824\n",
            "model 62: nodes_first= 8, nodes_second=4, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5198397040367126\n",
            "model 63: nodes_first= 8, nodes_second=4, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5202404856681824\n",
            "model 64: nodes_first= 8, nodes_second=8, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5258517265319824\n",
            "model 65: nodes_first= 8, nodes_second=8, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5246493220329285\n",
            "model 66: nodes_first= 8, nodes_second=8, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5238476991653442\n",
            "model 67: nodes_first= 8, nodes_second=8, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5158316493034363\n",
            "model 68: nodes_first= 8, nodes_second=12, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5438877940177917\n",
            "model 69: nodes_first= 8, nodes_second=12, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5194388628005981\n",
            "model 70: nodes_first= 8, nodes_second=12, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5094188451766968\n",
            "model 71: nodes_first= 8, nodes_second=12, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.49819639325141907\n",
            "model 72: nodes_first= 8, nodes_second=16, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5326653122901917\n",
            "model 73: nodes_first= 8, nodes_second=16, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5278556942939758\n",
            "model 74: nodes_first= 8, nodes_second=16, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5198397040367126\n",
            "model 75: nodes_first= 8, nodes_second=16, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5326653122901917\n",
            "model 76: nodes_first= 8, nodes_second=24, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.550701379776001\n",
            "model 77: nodes_first= 8, nodes_second=24, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5334669351577759\n",
            "model 78: nodes_first= 8, nodes_second=24, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5190380811691284\n",
            "model 79: nodes_first= 8, nodes_second=24, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5258517265319824\n",
            "model 80: nodes_first= 8, nodes_second=32, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5390781760215759\n",
            "model 81: nodes_first= 8, nodes_second=32, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5306613445281982\n",
            "model 82: nodes_first= 8, nodes_second=32, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5226452946662903\n",
            "model 83: nodes_first= 8, nodes_second=32, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5138276815414429\n",
            "model 84: nodes_first= 12, nodes_second=2, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.521843671798706\n",
            "model 85: nodes_first= 12, nodes_second=2, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 86: nodes_first= 12, nodes_second=2, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5014027953147888\n",
            "model 87: nodes_first= 12, nodes_second=2, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5010020136833191\n",
            "model 88: nodes_first= 12, nodes_second=4, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5478957891464233\n",
            "model 89: nodes_first= 12, nodes_second=4, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5326653122901917\n",
            "model 90: nodes_first= 12, nodes_second=4, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5210421085357666\n",
            "model 91: nodes_first= 12, nodes_second=4, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5098196268081665\n",
            "model 92: nodes_first= 12, nodes_second=8, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5438877940177917\n",
            "model 93: nodes_first= 12, nodes_second=8, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5346693396568298\n",
            "model 94: nodes_first= 12, nodes_second=8, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5286573171615601\n",
            "model 95: nodes_first= 12, nodes_second=8, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5042084455490112\n",
            "model 96: nodes_first= 12, nodes_second=12, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5234469175338745\n",
            "model 97: nodes_first= 12, nodes_second=12, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5074148178100586\n",
            "model 98: nodes_first= 12, nodes_second=12, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.503406822681427\n",
            "model 99: nodes_first= 12, nodes_second=12, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 100: nodes_first= 12, nodes_second=16, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5486974120140076\n",
            "model 101: nodes_first= 12, nodes_second=16, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5370741486549377\n",
            "model 102: nodes_first= 12, nodes_second=16, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5258517265319824\n",
            "model 103: nodes_first= 12, nodes_second=16, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5238476991653442\n",
            "model 104: nodes_first= 12, nodes_second=24, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5418837666511536\n",
            "model 105: nodes_first= 12, nodes_second=24, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5410821437835693\n",
            "model 106: nodes_first= 12, nodes_second=24, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5350701212882996\n",
            "model 107: nodes_first= 12, nodes_second=24, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5058116316795349\n",
            "model 108: nodes_first= 12, nodes_second=32, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5290580987930298\n",
            "model 109: nodes_first= 12, nodes_second=32, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5342685580253601\n",
            "model 110: nodes_first= 12, nodes_second=32, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5162324905395508\n",
            "model 111: nodes_first= 12, nodes_second=32, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5030060410499573\n",
            "model 112: nodes_first= 16, nodes_second=2, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5146292448043823\n",
            "model 113: nodes_first= 16, nodes_second=2, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.521843671798706\n",
            "model 114: nodes_first= 16, nodes_second=2, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5134268403053284\n",
            "model 115: nodes_first= 16, nodes_second=2, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.509018063545227\n",
            "model 116: nodes_first= 16, nodes_second=4, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5226452946662903\n",
            "model 117: nodes_first= 16, nodes_second=4, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5186372995376587\n",
            "model 118: nodes_first= 16, nodes_second=4, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5206412672996521\n",
            "model 119: nodes_first= 16, nodes_second=4, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5078156590461731\n",
            "model 120: nodes_first= 16, nodes_second=8, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5362725257873535\n",
            "model 121: nodes_first= 16, nodes_second=8, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5362725257873535\n",
            "model 122: nodes_first= 16, nodes_second=8, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5126252770423889\n",
            "model 123: nodes_first= 16, nodes_second=8, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.4921843707561493\n",
            "model 124: nodes_first= 16, nodes_second=12, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5306613445281982\n",
            "model 125: nodes_first= 16, nodes_second=12, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5326653122901917\n",
            "model 126: nodes_first= 16, nodes_second=12, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5178356766700745\n",
            "model 127: nodes_first= 16, nodes_second=12, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.49779558181762695\n",
            "model 128: nodes_first= 16, nodes_second=16, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5346693396568298\n",
            "model 129: nodes_first= 16, nodes_second=16, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5358717441558838\n",
            "model 130: nodes_first= 16, nodes_second=16, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5290580987930298\n",
            "model 131: nodes_first= 16, nodes_second=16, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5170340538024902\n",
            "model 132: nodes_first= 16, nodes_second=24, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5519037842750549\n",
            "model 133: nodes_first= 16, nodes_second=24, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5547094345092773\n",
            "model 134: nodes_first= 16, nodes_second=24, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5342685580253601\n",
            "model 135: nodes_first= 16, nodes_second=24, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5194388628005981\n",
            "model 136: nodes_first= 16, nodes_second=32, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5478957891464233\n",
            "model 137: nodes_first= 16, nodes_second=32, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.524248480796814\n",
            "model 138: nodes_first= 16, nodes_second=32, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5342685580253601\n",
            "model 139: nodes_first= 16, nodes_second=32, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5214428901672363\n",
            "model 140: nodes_first= 24, nodes_second=2, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5302605032920837\n",
            "model 141: nodes_first= 24, nodes_second=2, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5122244358062744\n",
            "model 142: nodes_first= 24, nodes_second=2, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5030060410499573\n",
            "model 143: nodes_first= 24, nodes_second=2, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5074148178100586\n",
            "model 144: nodes_first= 24, nodes_second=4, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5330661535263062\n",
            "model 145: nodes_first= 24, nodes_second=4, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5286573171615601\n",
            "model 146: nodes_first= 24, nodes_second=4, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5182364583015442\n",
            "model 147: nodes_first= 24, nodes_second=4, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5170340538024902\n",
            "model 148: nodes_first= 24, nodes_second=8, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.549498975276947\n",
            "model 149: nodes_first= 24, nodes_second=8, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5470941662788391\n",
            "model 150: nodes_first= 24, nodes_second=8, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5306613445281982\n",
            "model 151: nodes_first= 24, nodes_second=8, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5142284631729126\n",
            "model 152: nodes_first= 24, nodes_second=12, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5318637490272522\n",
            "model 153: nodes_first= 24, nodes_second=12, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.537875771522522\n",
            "model 154: nodes_first= 24, nodes_second=12, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5426853895187378\n",
            "model 155: nodes_first= 24, nodes_second=12, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5302605032920837\n",
            "model 156: nodes_first= 24, nodes_second=16, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5539078116416931\n",
            "model 157: nodes_first= 24, nodes_second=16, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5390781760215759\n",
            "model 158: nodes_first= 24, nodes_second=16, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5354709625244141\n",
            "model 159: nodes_first= 24, nodes_second=16, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5442885756492615\n",
            "model 160: nodes_first= 24, nodes_second=24, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5466933846473694\n",
            "model 161: nodes_first= 24, nodes_second=24, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5430861711502075\n",
            "model 162: nodes_first= 24, nodes_second=24, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5535070300102234\n",
            "model 163: nodes_first= 24, nodes_second=24, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5270541310310364\n",
            "model 164: nodes_first= 24, nodes_second=32, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5458917617797852\n",
            "model 165: nodes_first= 24, nodes_second=32, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5350701212882996\n",
            "model 166: nodes_first= 24, nodes_second=32, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5358717441558838\n",
            "model 167: nodes_first= 24, nodes_second=32, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5106212496757507\n",
            "model 168: nodes_first= 32, nodes_second=2, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5234469175338745\n",
            "model 169: nodes_first= 32, nodes_second=2, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.510220468044281\n",
            "model 170: nodes_first= 32, nodes_second=2, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5050100088119507\n",
            "model 171: nodes_first= 32, nodes_second=2, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 172: nodes_first= 32, nodes_second=4, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5266532897949219\n",
            "model 173: nodes_first= 32, nodes_second=4, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5182364583015442\n",
            "model 174: nodes_first= 32, nodes_second=4, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5158316493034363\n",
            "model 175: nodes_first= 32, nodes_second=4, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.4985972046852112\n",
            "model 176: nodes_first= 32, nodes_second=8, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5539078116416931\n",
            "model 177: nodes_first= 32, nodes_second=8, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5282565355300903\n",
            "model 178: nodes_first= 32, nodes_second=8, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5186372995376587\n",
            "model 179: nodes_first= 32, nodes_second=8, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 180: nodes_first= 32, nodes_second=12, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5591182112693787\n",
            "model 181: nodes_first= 32, nodes_second=12, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5438877940177917\n",
            "model 182: nodes_first= 32, nodes_second=12, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5246493220329285\n",
            "model 183: nodes_first= 32, nodes_second=12, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5234469175338745\n",
            "model 184: nodes_first= 32, nodes_second=16, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5430861711502075\n",
            "model 185: nodes_first= 32, nodes_second=16, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5519037842750549\n",
            "model 186: nodes_first= 32, nodes_second=16, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5290580987930298\n",
            "model 187: nodes_first= 32, nodes_second=16, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.536673367023468\n",
            "model 188: nodes_first= 32, nodes_second=24, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5406813621520996\n",
            "model 189: nodes_first= 32, nodes_second=24, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5334669351577759\n",
            "model 190: nodes_first= 32, nodes_second=24, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.537875771522522\n",
            "model 191: nodes_first= 32, nodes_second=24, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5314629077911377\n",
            "model 192: nodes_first= 32, nodes_second=32, batch=32, dropout_include=True, rate=0.1. Binary accuracy: 0.5382765531539917\n",
            "model 193: nodes_first= 32, nodes_second=32, batch=32, dropout_include=True, rate=0.2. Binary accuracy: 0.5454909801483154\n",
            "model 194: nodes_first= 32, nodes_second=32, batch=32, dropout_include=True, rate=0.3. Binary accuracy: 0.5338677167892456\n",
            "model 195: nodes_first= 32, nodes_second=32, batch=32, dropout_include=True, rate=0.4. Binary accuracy: 0.5350701212882996\n",
            "model 196: nodes_first= 2, nodes_second=2, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5286573171615601\n",
            "model 197: nodes_first= 2, nodes_second=2, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5154308676719666\n",
            "model 198: nodes_first= 2, nodes_second=2, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5202404856681824\n",
            "model 199: nodes_first= 2, nodes_second=2, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5158316493034363\n",
            "model 200: nodes_first= 2, nodes_second=4, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.4969939887523651\n",
            "model 201: nodes_first= 2, nodes_second=4, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5010020136833191\n",
            "model 202: nodes_first= 2, nodes_second=4, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5026051998138428\n",
            "model 203: nodes_first= 2, nodes_second=4, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.49338677525520325\n",
            "model 204: nodes_first= 2, nodes_second=8, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5166332721710205\n",
            "model 205: nodes_first= 2, nodes_second=8, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5250501036643982\n",
            "model 206: nodes_first= 2, nodes_second=8, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5026051998138428\n",
            "model 207: nodes_first= 2, nodes_second=8, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.504609227180481\n",
            "model 208: nodes_first= 2, nodes_second=12, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5270541310310364\n",
            "model 209: nodes_first= 2, nodes_second=12, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5214428901672363\n",
            "model 210: nodes_first= 2, nodes_second=12, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5098196268081665\n",
            "model 211: nodes_first= 2, nodes_second=12, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 212: nodes_first= 2, nodes_second=16, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5130260586738586\n",
            "model 213: nodes_first= 2, nodes_second=16, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5158316493034363\n",
            "model 214: nodes_first= 2, nodes_second=16, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5122244358062744\n",
            "model 215: nodes_first= 2, nodes_second=16, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5014027953147888\n",
            "model 216: nodes_first= 2, nodes_second=24, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5346693396568298\n",
            "model 217: nodes_first= 2, nodes_second=24, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5146292448043823\n",
            "model 218: nodes_first= 2, nodes_second=24, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5070140361785889\n",
            "model 219: nodes_first= 2, nodes_second=24, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5026051998138428\n",
            "model 220: nodes_first= 2, nodes_second=32, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5294589400291443\n",
            "model 221: nodes_first= 2, nodes_second=32, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5338677167892456\n",
            "model 222: nodes_first= 2, nodes_second=32, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5170340538024902\n",
            "model 223: nodes_first= 2, nodes_second=32, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5066132545471191\n",
            "model 224: nodes_first= 4, nodes_second=2, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5246493220329285\n",
            "model 225: nodes_first= 4, nodes_second=2, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.503406822681427\n",
            "model 226: nodes_first= 4, nodes_second=2, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5094188451766968\n",
            "model 227: nodes_first= 4, nodes_second=2, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.511422872543335\n",
            "model 228: nodes_first= 4, nodes_second=4, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5322645306587219\n",
            "model 229: nodes_first= 4, nodes_second=4, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5214428901672363\n",
            "model 230: nodes_first= 4, nodes_second=4, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5126252770423889\n",
            "model 231: nodes_first= 4, nodes_second=4, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5130260586738586\n",
            "model 232: nodes_first= 4, nodes_second=8, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5318637490272522\n",
            "model 233: nodes_first= 4, nodes_second=8, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5146292448043823\n",
            "model 234: nodes_first= 4, nodes_second=8, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5094188451766968\n",
            "model 235: nodes_first= 4, nodes_second=8, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5062124133110046\n",
            "model 236: nodes_first= 4, nodes_second=12, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5266532897949219\n",
            "model 237: nodes_first= 4, nodes_second=12, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5322645306587219\n",
            "model 238: nodes_first= 4, nodes_second=12, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.4989979863166809\n",
            "model 239: nodes_first= 4, nodes_second=12, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5010020136833191\n",
            "model 240: nodes_first= 4, nodes_second=16, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5238476991653442\n",
            "model 241: nodes_first= 4, nodes_second=16, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5210421085357666\n",
            "model 242: nodes_first= 4, nodes_second=16, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5122244358062744\n",
            "model 243: nodes_first= 4, nodes_second=16, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5078156590461731\n",
            "model 244: nodes_first= 4, nodes_second=24, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5078156590461731\n",
            "model 245: nodes_first= 4, nodes_second=24, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5006012320518494\n",
            "model 246: nodes_first= 4, nodes_second=24, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5174348950386047\n",
            "model 247: nodes_first= 4, nodes_second=24, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5146292448043823\n",
            "model 248: nodes_first= 4, nodes_second=32, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.52304607629776\n",
            "model 249: nodes_first= 4, nodes_second=32, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5194388628005981\n",
            "model 250: nodes_first= 4, nodes_second=32, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5074148178100586\n",
            "model 251: nodes_first= 4, nodes_second=32, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.4941883683204651\n",
            "model 252: nodes_first= 8, nodes_second=2, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5350701212882996\n",
            "model 253: nodes_first= 8, nodes_second=2, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5186372995376587\n",
            "model 254: nodes_first= 8, nodes_second=2, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5182364583015442\n",
            "model 255: nodes_first= 8, nodes_second=2, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.510220468044281\n",
            "model 256: nodes_first= 8, nodes_second=4, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5478957891464233\n",
            "model 257: nodes_first= 8, nodes_second=4, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5286573171615601\n",
            "model 258: nodes_first= 8, nodes_second=4, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.529859721660614\n",
            "model 259: nodes_first= 8, nodes_second=4, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.502204418182373\n",
            "model 260: nodes_first= 8, nodes_second=8, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5174348950386047\n",
            "model 261: nodes_first= 8, nodes_second=8, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 262: nodes_first= 8, nodes_second=8, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.503406822681427\n",
            "model 263: nodes_first= 8, nodes_second=8, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5058116316795349\n",
            "model 264: nodes_first= 8, nodes_second=12, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5282565355300903\n",
            "model 265: nodes_first= 8, nodes_second=12, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5178356766700745\n",
            "model 266: nodes_first= 8, nodes_second=12, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.510220468044281\n",
            "model 267: nodes_first= 8, nodes_second=12, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5006012320518494\n",
            "model 268: nodes_first= 8, nodes_second=16, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5462926030158997\n",
            "model 269: nodes_first= 8, nodes_second=16, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5374749302864075\n",
            "model 270: nodes_first= 8, nodes_second=16, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.503406822681427\n",
            "model 271: nodes_first= 8, nodes_second=16, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5198397040367126\n",
            "model 272: nodes_first= 8, nodes_second=24, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5430861711502075\n",
            "model 273: nodes_first= 8, nodes_second=24, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5238476991653442\n",
            "model 274: nodes_first= 8, nodes_second=24, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5270541310310364\n",
            "model 275: nodes_first= 8, nodes_second=24, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.531062126159668\n",
            "model 276: nodes_first= 8, nodes_second=32, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5402805805206299\n",
            "model 277: nodes_first= 8, nodes_second=32, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5238476991653442\n",
            "model 278: nodes_first= 8, nodes_second=32, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5246493220329285\n",
            "model 279: nodes_first= 8, nodes_second=32, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.504609227180481\n",
            "model 280: nodes_first= 12, nodes_second=2, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5194388628005981\n",
            "model 281: nodes_first= 12, nodes_second=2, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5206412672996521\n",
            "model 282: nodes_first= 12, nodes_second=2, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.504609227180481\n",
            "model 283: nodes_first= 12, nodes_second=2, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.4989979863166809\n",
            "model 284: nodes_first= 12, nodes_second=4, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5434869527816772\n",
            "model 285: nodes_first= 12, nodes_second=4, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5394789576530457\n",
            "model 286: nodes_first= 12, nodes_second=4, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5086172223091125\n",
            "model 287: nodes_first= 12, nodes_second=4, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5158316493034363\n",
            "model 288: nodes_first= 12, nodes_second=8, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5406813621520996\n",
            "model 289: nodes_first= 12, nodes_second=8, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5146292448043823\n",
            "model 290: nodes_first= 12, nodes_second=8, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.49779558181762695\n",
            "model 291: nodes_first= 12, nodes_second=8, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5118236541748047\n",
            "model 292: nodes_first= 12, nodes_second=12, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5134268403053284\n",
            "model 293: nodes_first= 12, nodes_second=12, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.4973948001861572\n",
            "model 294: nodes_first= 12, nodes_second=12, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.48937875032424927\n",
            "model 295: nodes_first= 12, nodes_second=12, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5130260586738586\n",
            "model 296: nodes_first= 12, nodes_second=16, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5362725257873535\n",
            "model 297: nodes_first= 12, nodes_second=16, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5535070300102234\n",
            "model 298: nodes_first= 12, nodes_second=16, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5362725257873535\n",
            "model 299: nodes_first= 12, nodes_second=16, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5226452946662903\n",
            "model 300: nodes_first= 12, nodes_second=24, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5406813621520996\n",
            "model 301: nodes_first= 12, nodes_second=24, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5202404856681824\n",
            "model 302: nodes_first= 12, nodes_second=24, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5226452946662903\n",
            "model 303: nodes_first= 12, nodes_second=24, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5126252770423889\n",
            "model 304: nodes_first= 12, nodes_second=32, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5478957891464233\n",
            "model 305: nodes_first= 12, nodes_second=32, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5246493220329285\n",
            "model 306: nodes_first= 12, nodes_second=32, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5110220313072205\n",
            "model 307: nodes_first= 12, nodes_second=32, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5078156590461731\n",
            "model 308: nodes_first= 16, nodes_second=2, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5098196268081665\n",
            "model 309: nodes_first= 16, nodes_second=2, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.49539077281951904\n",
            "model 310: nodes_first= 16, nodes_second=2, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5002003908157349\n",
            "model 311: nodes_first= 16, nodes_second=2, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.4973948001861572\n",
            "model 312: nodes_first= 16, nodes_second=4, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5270541310310364\n",
            "model 313: nodes_first= 16, nodes_second=4, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5082164406776428\n",
            "model 314: nodes_first= 16, nodes_second=4, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5206412672996521\n",
            "model 315: nodes_first= 16, nodes_second=4, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.4969939887523651\n",
            "model 316: nodes_first= 16, nodes_second=8, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5302605032920837\n",
            "model 317: nodes_first= 16, nodes_second=8, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5234469175338745\n",
            "model 318: nodes_first= 16, nodes_second=8, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.511422872543335\n",
            "model 319: nodes_first= 16, nodes_second=8, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5206412672996521\n",
            "model 320: nodes_first= 16, nodes_second=12, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5322645306587219\n",
            "model 321: nodes_first= 16, nodes_second=12, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5082164406776428\n",
            "model 322: nodes_first= 16, nodes_second=12, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5106212496757507\n",
            "model 323: nodes_first= 16, nodes_second=12, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.4949899911880493\n",
            "model 324: nodes_first= 16, nodes_second=16, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5302605032920837\n",
            "model 325: nodes_first= 16, nodes_second=16, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5238476991653442\n",
            "model 326: nodes_first= 16, nodes_second=16, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.521843671798706\n",
            "model 327: nodes_first= 16, nodes_second=16, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5194388628005981\n",
            "model 328: nodes_first= 16, nodes_second=24, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.529859721660614\n",
            "model 329: nodes_first= 16, nodes_second=24, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5302605032920837\n",
            "model 330: nodes_first= 16, nodes_second=24, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5178356766700745\n",
            "model 331: nodes_first= 16, nodes_second=24, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5254508852958679\n",
            "model 332: nodes_first= 16, nodes_second=32, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5254508852958679\n",
            "model 333: nodes_first= 16, nodes_second=32, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5194388628005981\n",
            "model 334: nodes_first= 16, nodes_second=32, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5294589400291443\n",
            "model 335: nodes_first= 16, nodes_second=32, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.521843671798706\n",
            "model 336: nodes_first= 24, nodes_second=2, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5202404856681824\n",
            "model 337: nodes_first= 24, nodes_second=2, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5178356766700745\n",
            "model 338: nodes_first= 24, nodes_second=2, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5042084455490112\n",
            "model 339: nodes_first= 24, nodes_second=2, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5074148178100586\n",
            "model 340: nodes_first= 24, nodes_second=4, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5234469175338745\n",
            "model 341: nodes_first= 24, nodes_second=4, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5190380811691284\n",
            "model 342: nodes_first= 24, nodes_second=4, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5146292448043823\n",
            "model 343: nodes_first= 24, nodes_second=4, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5014027953147888\n",
            "model 344: nodes_first= 24, nodes_second=8, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5450901985168457\n",
            "model 345: nodes_first= 24, nodes_second=8, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5306613445281982\n",
            "model 346: nodes_first= 24, nodes_second=8, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5226452946662903\n",
            "model 347: nodes_first= 24, nodes_second=8, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5198397040367126\n",
            "model 348: nodes_first= 24, nodes_second=12, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5350701212882996\n",
            "model 349: nodes_first= 24, nodes_second=12, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5358717441558838\n",
            "model 350: nodes_first= 24, nodes_second=12, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5250501036643982\n",
            "model 351: nodes_first= 24, nodes_second=12, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.536673367023468\n",
            "model 352: nodes_first= 24, nodes_second=16, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5587174296379089\n",
            "model 353: nodes_first= 24, nodes_second=16, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5571142435073853\n",
            "model 354: nodes_first= 24, nodes_second=16, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5182364583015442\n",
            "model 355: nodes_first= 24, nodes_second=16, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5178356766700745\n",
            "model 356: nodes_first= 24, nodes_second=24, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.550701379776001\n",
            "model 357: nodes_first= 24, nodes_second=24, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5358717441558838\n",
            "model 358: nodes_first= 24, nodes_second=24, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5370741486549377\n",
            "model 359: nodes_first= 24, nodes_second=24, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5226452946662903\n",
            "model 360: nodes_first= 24, nodes_second=32, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5450901985168457\n",
            "model 361: nodes_first= 24, nodes_second=32, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5314629077911377\n",
            "model 362: nodes_first= 24, nodes_second=32, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.52304607629776\n",
            "model 363: nodes_first= 24, nodes_second=32, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5258517265319824\n",
            "model 364: nodes_first= 32, nodes_second=2, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5182364583015442\n",
            "model 365: nodes_first= 32, nodes_second=2, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5130260586738586\n",
            "model 366: nodes_first= 32, nodes_second=2, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.511422872543335\n",
            "model 367: nodes_first= 32, nodes_second=2, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 368: nodes_first= 32, nodes_second=4, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5142284631729126\n",
            "model 369: nodes_first= 32, nodes_second=4, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.509018063545227\n",
            "model 370: nodes_first= 32, nodes_second=4, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5126252770423889\n",
            "model 371: nodes_first= 32, nodes_second=4, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.4973948001861572\n",
            "model 372: nodes_first= 32, nodes_second=8, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5434869527816772\n",
            "model 373: nodes_first= 32, nodes_second=8, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5194388628005981\n",
            "model 374: nodes_first= 32, nodes_second=8, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5094188451766968\n",
            "model 375: nodes_first= 32, nodes_second=8, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.509018063545227\n",
            "model 376: nodes_first= 32, nodes_second=12, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5571142435073853\n",
            "model 377: nodes_first= 32, nodes_second=12, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5410821437835693\n",
            "model 378: nodes_first= 32, nodes_second=12, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5286573171615601\n",
            "model 379: nodes_first= 32, nodes_second=12, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5158316493034363\n",
            "model 380: nodes_first= 32, nodes_second=16, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5527054071426392\n",
            "model 381: nodes_first= 32, nodes_second=16, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5426853895187378\n",
            "model 382: nodes_first= 32, nodes_second=16, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5350701212882996\n",
            "model 383: nodes_first= 32, nodes_second=16, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5402805805206299\n",
            "model 384: nodes_first= 32, nodes_second=24, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5382765531539917\n",
            "model 385: nodes_first= 32, nodes_second=24, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.531062126159668\n",
            "model 386: nodes_first= 32, nodes_second=24, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5322645306587219\n",
            "model 387: nodes_first= 32, nodes_second=24, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5418837666511536\n",
            "model 388: nodes_first= 32, nodes_second=32, batch=64, dropout_include=True, rate=0.1. Binary accuracy: 0.5519037842750549\n",
            "model 389: nodes_first= 32, nodes_second=32, batch=64, dropout_include=True, rate=0.2. Binary accuracy: 0.5402805805206299\n",
            "model 390: nodes_first= 32, nodes_second=32, batch=64, dropout_include=True, rate=0.3. Binary accuracy: 0.5318637490272522\n",
            "model 391: nodes_first= 32, nodes_second=32, batch=64, dropout_include=True, rate=0.4. Binary accuracy: 0.5194388628005981\n",
            "model 392: nodes_first= 2, nodes_second=2, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5266532897949219\n",
            "model 393: nodes_first= 2, nodes_second=2, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5142284631729126\n",
            "model 394: nodes_first= 2, nodes_second=2, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.510220468044281\n",
            "model 395: nodes_first= 2, nodes_second=2, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5018036365509033\n",
            "model 396: nodes_first= 2, nodes_second=4, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.4985972046852112\n",
            "model 397: nodes_first= 2, nodes_second=4, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.4897795617580414\n",
            "model 398: nodes_first= 2, nodes_second=4, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.4945891797542572\n",
            "model 399: nodes_first= 2, nodes_second=4, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.4921843707561493\n",
            "model 400: nodes_first= 2, nodes_second=8, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5042084455490112\n",
            "model 401: nodes_first= 2, nodes_second=8, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.503406822681427\n",
            "model 402: nodes_first= 2, nodes_second=8, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.509018063545227\n",
            "model 403: nodes_first= 2, nodes_second=8, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5066132545471191\n",
            "model 404: nodes_first= 2, nodes_second=12, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5254508852958679\n",
            "model 405: nodes_first= 2, nodes_second=12, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 406: nodes_first= 2, nodes_second=12, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5078156590461731\n",
            "model 407: nodes_first= 2, nodes_second=12, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5182364583015442\n",
            "model 408: nodes_first= 2, nodes_second=16, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5162324905395508\n",
            "model 409: nodes_first= 2, nodes_second=16, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.4989979863166809\n",
            "model 410: nodes_first= 2, nodes_second=16, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5030060410499573\n",
            "model 411: nodes_first= 2, nodes_second=16, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5030060410499573\n",
            "model 412: nodes_first= 2, nodes_second=24, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5274549126625061\n",
            "model 413: nodes_first= 2, nodes_second=24, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5266532897949219\n",
            "model 414: nodes_first= 2, nodes_second=24, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5150300860404968\n",
            "model 415: nodes_first= 2, nodes_second=24, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5210421085357666\n",
            "model 416: nodes_first= 2, nodes_second=32, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5274549126625061\n",
            "model 417: nodes_first= 2, nodes_second=32, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5134268403053284\n",
            "model 418: nodes_first= 2, nodes_second=32, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5062124133110046\n",
            "model 419: nodes_first= 2, nodes_second=32, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.49979960918426514\n",
            "model 420: nodes_first= 4, nodes_second=2, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.510220468044281\n",
            "model 421: nodes_first= 4, nodes_second=2, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.504609227180481\n",
            "model 422: nodes_first= 4, nodes_second=2, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5062124133110046\n",
            "model 423: nodes_first= 4, nodes_second=2, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.509018063545227\n",
            "model 424: nodes_first= 4, nodes_second=4, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.521843671798706\n",
            "model 425: nodes_first= 4, nodes_second=4, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 426: nodes_first= 4, nodes_second=4, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.504609227180481\n",
            "model 427: nodes_first= 4, nodes_second=4, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5202404856681824\n",
            "model 428: nodes_first= 4, nodes_second=8, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5198397040367126\n",
            "model 429: nodes_first= 4, nodes_second=8, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.509018063545227\n",
            "model 430: nodes_first= 4, nodes_second=8, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5138276815414429\n",
            "model 431: nodes_first= 4, nodes_second=8, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5018036365509033\n",
            "model 432: nodes_first= 4, nodes_second=12, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5306613445281982\n",
            "model 433: nodes_first= 4, nodes_second=12, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5270541310310364\n",
            "model 434: nodes_first= 4, nodes_second=12, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5210421085357666\n",
            "model 435: nodes_first= 4, nodes_second=12, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.49539077281951904\n",
            "model 436: nodes_first= 4, nodes_second=16, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5174348950386047\n",
            "model 437: nodes_first= 4, nodes_second=16, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.504609227180481\n",
            "model 438: nodes_first= 4, nodes_second=16, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5198397040367126\n",
            "model 439: nodes_first= 4, nodes_second=16, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5198397040367126\n",
            "model 440: nodes_first= 4, nodes_second=24, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5282565355300903\n",
            "model 441: nodes_first= 4, nodes_second=24, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5150300860404968\n",
            "model 442: nodes_first= 4, nodes_second=24, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5138276815414429\n",
            "model 443: nodes_first= 4, nodes_second=24, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5054108500480652\n",
            "model 444: nodes_first= 4, nodes_second=32, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5122244358062744\n",
            "model 445: nodes_first= 4, nodes_second=32, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 446: nodes_first= 4, nodes_second=32, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5238476991653442\n",
            "model 447: nodes_first= 4, nodes_second=32, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5070140361785889\n",
            "model 448: nodes_first= 8, nodes_second=2, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5370741486549377\n",
            "model 449: nodes_first= 8, nodes_second=2, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5258517265319824\n",
            "model 450: nodes_first= 8, nodes_second=2, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5282565355300903\n",
            "model 451: nodes_first= 8, nodes_second=2, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5058116316795349\n",
            "model 452: nodes_first= 8, nodes_second=4, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5358717441558838\n",
            "model 453: nodes_first= 8, nodes_second=4, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 454: nodes_first= 8, nodes_second=4, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5186372995376587\n",
            "model 455: nodes_first= 8, nodes_second=4, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.511422872543335\n",
            "model 456: nodes_first= 8, nodes_second=8, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5010020136833191\n",
            "model 457: nodes_first= 8, nodes_second=8, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.4973948001861572\n",
            "model 458: nodes_first= 8, nodes_second=8, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.4969939887523651\n",
            "model 459: nodes_first= 8, nodes_second=8, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.48737475275993347\n",
            "model 460: nodes_first= 8, nodes_second=12, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.524248480796814\n",
            "model 461: nodes_first= 8, nodes_second=12, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.4949899911880493\n",
            "model 462: nodes_first= 8, nodes_second=12, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5086172223091125\n",
            "model 463: nodes_first= 8, nodes_second=12, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 464: nodes_first= 8, nodes_second=16, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5402805805206299\n",
            "model 465: nodes_first= 8, nodes_second=16, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5294589400291443\n",
            "model 466: nodes_first= 8, nodes_second=16, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5258517265319824\n",
            "model 467: nodes_first= 8, nodes_second=16, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5222445130348206\n",
            "model 468: nodes_first= 8, nodes_second=24, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5374749302864075\n",
            "model 469: nodes_first= 8, nodes_second=24, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.524248480796814\n",
            "model 470: nodes_first= 8, nodes_second=24, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5146292448043823\n",
            "model 471: nodes_first= 8, nodes_second=24, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5210421085357666\n",
            "model 472: nodes_first= 8, nodes_second=32, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.524248480796814\n",
            "model 473: nodes_first= 8, nodes_second=32, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5150300860404968\n",
            "model 474: nodes_first= 8, nodes_second=32, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.504609227180481\n",
            "model 475: nodes_first= 8, nodes_second=32, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5194388628005981\n",
            "model 476: nodes_first= 12, nodes_second=2, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5142284631729126\n",
            "model 477: nodes_first= 12, nodes_second=2, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 478: nodes_first= 12, nodes_second=2, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5166332721710205\n",
            "model 479: nodes_first= 12, nodes_second=2, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.509018063545227\n",
            "model 480: nodes_first= 12, nodes_second=4, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.52304607629776\n",
            "model 481: nodes_first= 12, nodes_second=4, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5474950075149536\n",
            "model 482: nodes_first= 12, nodes_second=4, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5202404856681824\n",
            "model 483: nodes_first= 12, nodes_second=4, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5042084455490112\n",
            "model 484: nodes_first= 12, nodes_second=8, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5414829850196838\n",
            "model 485: nodes_first= 12, nodes_second=8, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5214428901672363\n",
            "model 486: nodes_first= 12, nodes_second=8, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5038076043128967\n",
            "model 487: nodes_first= 12, nodes_second=8, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.52304607629776\n",
            "model 488: nodes_first= 12, nodes_second=12, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.509018063545227\n",
            "model 489: nodes_first= 12, nodes_second=12, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5018036365509033\n",
            "model 490: nodes_first= 12, nodes_second=12, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.4941883683204651\n",
            "model 491: nodes_first= 12, nodes_second=12, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.4969939887523651\n",
            "model 492: nodes_first= 12, nodes_second=16, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5318637490272522\n",
            "model 493: nodes_first= 12, nodes_second=16, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5330661535263062\n",
            "model 494: nodes_first= 12, nodes_second=16, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5210421085357666\n",
            "model 495: nodes_first= 12, nodes_second=16, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5238476991653442\n",
            "model 496: nodes_first= 12, nodes_second=24, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5234469175338745\n",
            "model 497: nodes_first= 12, nodes_second=24, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5330661535263062\n",
            "model 498: nodes_first= 12, nodes_second=24, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5182364583015442\n",
            "model 499: nodes_first= 12, nodes_second=24, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5042084455490112\n",
            "model 500: nodes_first= 12, nodes_second=32, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5318637490272522\n",
            "model 501: nodes_first= 12, nodes_second=32, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5070140361785889\n",
            "model 502: nodes_first= 12, nodes_second=32, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.4989979863166809\n",
            "model 503: nodes_first= 12, nodes_second=32, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.4969939887523651\n",
            "model 504: nodes_first= 16, nodes_second=2, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5082164406776428\n",
            "model 505: nodes_first= 16, nodes_second=2, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.502204418182373\n",
            "model 506: nodes_first= 16, nodes_second=2, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5178356766700745\n",
            "model 507: nodes_first= 16, nodes_second=2, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.49779558181762695\n",
            "model 508: nodes_first= 16, nodes_second=4, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5166332721710205\n",
            "model 509: nodes_first= 16, nodes_second=4, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5058116316795349\n",
            "model 510: nodes_first= 16, nodes_second=4, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5070140361785889\n",
            "model 511: nodes_first= 16, nodes_second=4, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.4905811548233032\n",
            "model 512: nodes_first= 16, nodes_second=8, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5214428901672363\n",
            "model 513: nodes_first= 16, nodes_second=8, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5038076043128967\n",
            "model 514: nodes_first= 16, nodes_second=8, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5122244358062744\n",
            "model 515: nodes_first= 16, nodes_second=8, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.48056110739707947\n",
            "model 516: nodes_first= 16, nodes_second=12, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5274549126625061\n",
            "model 517: nodes_first= 16, nodes_second=12, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.4989979863166809\n",
            "model 518: nodes_first= 16, nodes_second=12, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.4813627302646637\n",
            "model 519: nodes_first= 16, nodes_second=12, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.48657315969467163\n",
            "model 520: nodes_first= 16, nodes_second=16, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5246493220329285\n",
            "model 521: nodes_first= 16, nodes_second=16, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 522: nodes_first= 16, nodes_second=16, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5070140361785889\n",
            "model 523: nodes_first= 16, nodes_second=16, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5158316493034363\n",
            "model 524: nodes_first= 16, nodes_second=24, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5386773347854614\n",
            "model 525: nodes_first= 16, nodes_second=24, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5206412672996521\n",
            "model 526: nodes_first= 16, nodes_second=24, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5486974120140076\n",
            "model 527: nodes_first= 16, nodes_second=24, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5270541310310364\n",
            "model 528: nodes_first= 16, nodes_second=32, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5350701212882996\n",
            "model 529: nodes_first= 16, nodes_second=32, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5206412672996521\n",
            "model 530: nodes_first= 16, nodes_second=32, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5154308676719666\n",
            "model 531: nodes_first= 16, nodes_second=32, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5182364583015442\n",
            "model 532: nodes_first= 24, nodes_second=2, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5166332721710205\n",
            "model 533: nodes_first= 24, nodes_second=2, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5194388628005981\n",
            "model 534: nodes_first= 24, nodes_second=2, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5138276815414429\n",
            "model 535: nodes_first= 24, nodes_second=2, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5194388628005981\n",
            "model 536: nodes_first= 24, nodes_second=4, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5182364583015442\n",
            "model 537: nodes_first= 24, nodes_second=4, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5094188451766968\n",
            "model 538: nodes_first= 24, nodes_second=4, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5134268403053284\n",
            "model 539: nodes_first= 24, nodes_second=4, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.4861723482608795\n",
            "model 540: nodes_first= 24, nodes_second=8, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5474950075149536\n",
            "model 541: nodes_first= 24, nodes_second=8, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5394789576530457\n",
            "model 542: nodes_first= 24, nodes_second=8, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5238476991653442\n",
            "model 543: nodes_first= 24, nodes_second=8, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5138276815414429\n",
            "model 544: nodes_first= 24, nodes_second=12, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5478957891464233\n",
            "model 545: nodes_first= 24, nodes_second=12, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5174348950386047\n",
            "model 546: nodes_first= 24, nodes_second=12, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5334669351577759\n",
            "model 547: nodes_first= 24, nodes_second=12, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5154308676719666\n",
            "model 548: nodes_first= 24, nodes_second=16, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5551102161407471\n",
            "model 549: nodes_first= 24, nodes_second=16, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5458917617797852\n",
            "model 550: nodes_first= 24, nodes_second=16, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5414829850196838\n",
            "model 551: nodes_first= 24, nodes_second=16, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5146292448043823\n",
            "model 552: nodes_first= 24, nodes_second=24, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5519037842750549\n",
            "model 553: nodes_first= 24, nodes_second=24, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5438877940177917\n",
            "model 554: nodes_first= 24, nodes_second=24, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5170340538024902\n",
            "model 555: nodes_first= 24, nodes_second=24, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5206412672996521\n",
            "model 556: nodes_first= 24, nodes_second=32, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5286573171615601\n",
            "model 557: nodes_first= 24, nodes_second=32, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5294589400291443\n",
            "model 558: nodes_first= 24, nodes_second=32, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5214428901672363\n",
            "model 559: nodes_first= 24, nodes_second=32, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.524248480796814\n",
            "model 560: nodes_first= 32, nodes_second=2, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5122244358062744\n",
            "model 561: nodes_first= 32, nodes_second=2, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5170340538024902\n",
            "model 562: nodes_first= 32, nodes_second=2, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.511422872543335\n",
            "model 563: nodes_first= 32, nodes_second=2, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5134268403053284\n",
            "model 564: nodes_first= 32, nodes_second=4, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5174348950386047\n",
            "model 565: nodes_first= 32, nodes_second=4, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5066132545471191\n",
            "model 566: nodes_first= 32, nodes_second=4, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.49819639325141907\n",
            "model 567: nodes_first= 32, nodes_second=4, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.48657315969467163\n",
            "model 568: nodes_first= 32, nodes_second=8, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5278556942939758\n",
            "model 569: nodes_first= 32, nodes_second=8, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5198397040367126\n",
            "model 570: nodes_first= 32, nodes_second=8, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.503406822681427\n",
            "model 571: nodes_first= 32, nodes_second=8, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5066132545471191\n",
            "model 572: nodes_first= 32, nodes_second=12, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5511022210121155\n",
            "model 573: nodes_first= 32, nodes_second=12, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.531062126159668\n",
            "model 574: nodes_first= 32, nodes_second=12, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5258517265319824\n",
            "model 575: nodes_first= 32, nodes_second=12, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5306613445281982\n",
            "model 576: nodes_first= 32, nodes_second=16, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5350701212882996\n",
            "model 577: nodes_first= 32, nodes_second=16, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5539078116416931\n",
            "model 578: nodes_first= 32, nodes_second=16, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5374749302864075\n",
            "model 579: nodes_first= 32, nodes_second=16, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5162324905395508\n",
            "model 580: nodes_first= 32, nodes_second=24, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5567134022712708\n",
            "model 581: nodes_first= 32, nodes_second=24, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5426853895187378\n",
            "model 582: nodes_first= 32, nodes_second=24, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.521843671798706\n",
            "model 583: nodes_first= 32, nodes_second=24, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5174348950386047\n",
            "model 584: nodes_first= 32, nodes_second=32, batch=128, dropout_include=True, rate=0.1. Binary accuracy: 0.5535070300102234\n",
            "model 585: nodes_first= 32, nodes_second=32, batch=128, dropout_include=True, rate=0.2. Binary accuracy: 0.5318637490272522\n",
            "model 586: nodes_first= 32, nodes_second=32, batch=128, dropout_include=True, rate=0.3. Binary accuracy: 0.5286573171615601\n",
            "model 587: nodes_first= 32, nodes_second=32, batch=128, dropout_include=True, rate=0.4. Binary accuracy: 0.5206412672996521\n",
            "model 588: nodes_first= 2, nodes_second=2, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5186372995376587\n",
            "model 589: nodes_first= 2, nodes_second=2, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5294589400291443\n",
            "model 590: nodes_first= 2, nodes_second=2, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5126252770423889\n",
            "model 591: nodes_first= 2, nodes_second=2, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5030060410499573\n",
            "model 592: nodes_first= 2, nodes_second=4, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.4837675392627716\n",
            "model 593: nodes_first= 2, nodes_second=4, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.49579158425331116\n",
            "model 594: nodes_first= 2, nodes_second=4, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4901803731918335\n",
            "model 595: nodes_first= 2, nodes_second=4, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.4969939887523651\n",
            "model 596: nodes_first= 2, nodes_second=8, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.49138277769088745\n",
            "model 597: nodes_first= 2, nodes_second=8, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.48737475275993347\n",
            "model 598: nodes_first= 2, nodes_second=8, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.48897796869277954\n",
            "model 599: nodes_first= 2, nodes_second=8, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49098196625709534\n",
            "model 600: nodes_first= 2, nodes_second=12, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5066132545471191\n",
            "model 601: nodes_first= 2, nodes_second=12, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5078156590461731\n",
            "model 602: nodes_first= 2, nodes_second=12, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5054108500480652\n",
            "model 603: nodes_first= 2, nodes_second=12, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.504609227180481\n",
            "model 604: nodes_first= 2, nodes_second=16, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5086172223091125\n",
            "model 605: nodes_first= 2, nodes_second=16, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5054108500480652\n",
            "model 606: nodes_first= 2, nodes_second=16, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4921843707561493\n",
            "model 607: nodes_first= 2, nodes_second=16, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49338677525520325\n",
            "model 608: nodes_first= 2, nodes_second=24, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5270541310310364\n",
            "model 609: nodes_first= 2, nodes_second=24, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5126252770423889\n",
            "model 610: nodes_first= 2, nodes_second=24, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5174348950386047\n",
            "model 611: nodes_first= 2, nodes_second=24, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5166332721710205\n",
            "model 612: nodes_first= 2, nodes_second=32, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5142284631729126\n",
            "model 613: nodes_first= 2, nodes_second=32, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5010020136833191\n",
            "model 614: nodes_first= 2, nodes_second=32, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5078156590461731\n",
            "model 615: nodes_first= 2, nodes_second=32, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5154308676719666\n",
            "model 616: nodes_first= 4, nodes_second=2, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5078156590461731\n",
            "model 617: nodes_first= 4, nodes_second=2, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5094188451766968\n",
            "model 618: nodes_first= 4, nodes_second=2, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5030060410499573\n",
            "model 619: nodes_first= 4, nodes_second=2, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5178356766700745\n",
            "model 620: nodes_first= 4, nodes_second=4, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5182364583015442\n",
            "model 621: nodes_first= 4, nodes_second=4, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 622: nodes_first= 4, nodes_second=4, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.49539077281951904\n",
            "model 623: nodes_first= 4, nodes_second=4, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5142284631729126\n",
            "model 624: nodes_first= 4, nodes_second=8, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5234469175338745\n",
            "model 625: nodes_first= 4, nodes_second=8, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5222445130348206\n",
            "model 626: nodes_first= 4, nodes_second=8, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5278556942939758\n",
            "model 627: nodes_first= 4, nodes_second=8, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49298596382141113\n",
            "model 628: nodes_first= 4, nodes_second=12, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5078156590461731\n",
            "model 629: nodes_first= 4, nodes_second=12, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 630: nodes_first= 4, nodes_second=12, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4925851821899414\n",
            "model 631: nodes_first= 4, nodes_second=12, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5066132545471191\n",
            "model 632: nodes_first= 4, nodes_second=16, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5202404856681824\n",
            "model 633: nodes_first= 4, nodes_second=16, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5238476991653442\n",
            "model 634: nodes_first= 4, nodes_second=16, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5146292448043823\n",
            "model 635: nodes_first= 4, nodes_second=16, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49338677525520325\n",
            "model 636: nodes_first= 4, nodes_second=24, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5098196268081665\n",
            "model 637: nodes_first= 4, nodes_second=24, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5018036365509033\n",
            "model 638: nodes_first= 4, nodes_second=24, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5018036365509033\n",
            "model 639: nodes_first= 4, nodes_second=24, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.4941883683204651\n",
            "model 640: nodes_first= 4, nodes_second=32, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5118236541748047\n",
            "model 641: nodes_first= 4, nodes_second=32, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5014027953147888\n",
            "model 642: nodes_first= 4, nodes_second=32, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4905811548233032\n",
            "model 643: nodes_first= 4, nodes_second=32, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5002003908157349\n",
            "model 644: nodes_first= 8, nodes_second=2, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5358717441558838\n",
            "model 645: nodes_first= 8, nodes_second=2, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 646: nodes_first= 8, nodes_second=2, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.504609227180481\n",
            "model 647: nodes_first= 8, nodes_second=2, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5082164406776428\n",
            "model 648: nodes_first= 8, nodes_second=4, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5042084455490112\n",
            "model 649: nodes_first= 8, nodes_second=4, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.49619239568710327\n",
            "model 650: nodes_first= 8, nodes_second=4, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5122244358062744\n",
            "model 651: nodes_first= 8, nodes_second=4, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5174348950386047\n",
            "model 652: nodes_first= 8, nodes_second=8, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5030060410499573\n",
            "model 653: nodes_first= 8, nodes_second=8, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5194388628005981\n",
            "model 654: nodes_first= 8, nodes_second=8, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.509018063545227\n",
            "model 655: nodes_first= 8, nodes_second=8, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49979960918426514\n",
            "model 656: nodes_first= 8, nodes_second=12, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5450901985168457\n",
            "model 657: nodes_first= 8, nodes_second=12, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.4941883683204651\n",
            "model 658: nodes_first= 8, nodes_second=12, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5118236541748047\n",
            "model 659: nodes_first= 8, nodes_second=12, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49979960918426514\n",
            "model 660: nodes_first= 8, nodes_second=16, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5370741486549377\n",
            "model 661: nodes_first= 8, nodes_second=16, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5278556942939758\n",
            "model 662: nodes_first= 8, nodes_second=16, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5234469175338745\n",
            "model 663: nodes_first= 8, nodes_second=16, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5382765531539917\n",
            "model 664: nodes_first= 8, nodes_second=24, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5306613445281982\n",
            "model 665: nodes_first= 8, nodes_second=24, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.52304607629776\n",
            "model 666: nodes_first= 8, nodes_second=24, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5222445130348206\n",
            "model 667: nodes_first= 8, nodes_second=24, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5270541310310364\n",
            "model 668: nodes_first= 8, nodes_second=32, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5222445130348206\n",
            "model 669: nodes_first= 8, nodes_second=32, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5150300860404968\n",
            "model 670: nodes_first= 8, nodes_second=32, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.521843671798706\n",
            "model 671: nodes_first= 8, nodes_second=32, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5290580987930298\n",
            "model 672: nodes_first= 12, nodes_second=2, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5162324905395508\n",
            "model 673: nodes_first= 12, nodes_second=2, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 674: nodes_first= 12, nodes_second=2, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4921843707561493\n",
            "model 675: nodes_first= 12, nodes_second=2, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5018036365509033\n",
            "model 676: nodes_first= 12, nodes_second=4, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5198397040367126\n",
            "model 677: nodes_first= 12, nodes_second=4, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.504609227180481\n",
            "model 678: nodes_first= 12, nodes_second=4, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5026051998138428\n",
            "model 679: nodes_first= 12, nodes_second=4, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5042084455490112\n",
            "model 680: nodes_first= 12, nodes_second=8, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5062124133110046\n",
            "model 681: nodes_first= 12, nodes_second=8, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5066132545471191\n",
            "model 682: nodes_first= 12, nodes_second=8, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4941883683204651\n",
            "model 683: nodes_first= 12, nodes_second=8, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.4917835593223572\n",
            "model 684: nodes_first= 12, nodes_second=12, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5082164406776428\n",
            "model 685: nodes_first= 12, nodes_second=12, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.4841683506965637\n",
            "model 686: nodes_first= 12, nodes_second=12, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4905811548233032\n",
            "model 687: nodes_first= 12, nodes_second=12, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5054108500480652\n",
            "model 688: nodes_first= 12, nodes_second=16, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5390781760215759\n",
            "model 689: nodes_first= 12, nodes_second=16, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5190380811691284\n",
            "model 690: nodes_first= 12, nodes_second=16, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5250501036643982\n",
            "model 691: nodes_first= 12, nodes_second=16, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.521843671798706\n",
            "model 692: nodes_first= 12, nodes_second=24, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5278556942939758\n",
            "model 693: nodes_first= 12, nodes_second=24, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5086172223091125\n",
            "model 694: nodes_first= 12, nodes_second=24, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.509018063545227\n",
            "model 695: nodes_first= 12, nodes_second=24, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5066132545471191\n",
            "model 696: nodes_first= 12, nodes_second=32, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5246493220329285\n",
            "model 697: nodes_first= 12, nodes_second=32, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 698: nodes_first= 12, nodes_second=32, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.49619239568710327\n",
            "model 699: nodes_first= 12, nodes_second=32, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5098196268081665\n",
            "model 700: nodes_first= 16, nodes_second=2, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5186372995376587\n",
            "model 701: nodes_first= 16, nodes_second=2, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5126252770423889\n",
            "model 702: nodes_first= 16, nodes_second=2, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.509018063545227\n",
            "model 703: nodes_first= 16, nodes_second=2, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5118236541748047\n",
            "model 704: nodes_first= 16, nodes_second=4, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5054108500480652\n",
            "model 705: nodes_first= 16, nodes_second=4, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.496593177318573\n",
            "model 706: nodes_first= 16, nodes_second=4, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.49338677525520325\n",
            "model 707: nodes_first= 16, nodes_second=4, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.4853707551956177\n",
            "model 708: nodes_first= 16, nodes_second=8, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5278556942939758\n",
            "model 709: nodes_first= 16, nodes_second=8, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5146292448043823\n",
            "model 710: nodes_first= 16, nodes_second=8, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4949899911880493\n",
            "model 711: nodes_first= 16, nodes_second=8, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5062124133110046\n",
            "model 712: nodes_first= 16, nodes_second=12, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5170340538024902\n",
            "model 713: nodes_first= 16, nodes_second=12, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5190380811691284\n",
            "model 714: nodes_first= 16, nodes_second=12, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5234469175338745\n",
            "model 715: nodes_first= 16, nodes_second=12, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5110220313072205\n",
            "model 716: nodes_first= 16, nodes_second=16, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5162324905395508\n",
            "model 717: nodes_first= 16, nodes_second=16, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.503406822681427\n",
            "model 718: nodes_first= 16, nodes_second=16, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5118236541748047\n",
            "model 719: nodes_first= 16, nodes_second=16, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.510220468044281\n",
            "model 720: nodes_first= 16, nodes_second=24, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5418837666511536\n",
            "model 721: nodes_first= 16, nodes_second=24, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5358717441558838\n",
            "model 722: nodes_first= 16, nodes_second=24, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5306613445281982\n",
            "model 723: nodes_first= 16, nodes_second=24, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5346693396568298\n",
            "model 724: nodes_first= 16, nodes_second=32, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5454909801483154\n",
            "model 725: nodes_first= 16, nodes_second=32, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.49619239568710327\n",
            "model 726: nodes_first= 16, nodes_second=32, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.49338677525520325\n",
            "model 727: nodes_first= 16, nodes_second=32, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49298596382141113\n",
            "model 728: nodes_first= 24, nodes_second=2, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5238476991653442\n",
            "model 729: nodes_first= 24, nodes_second=2, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5142284631729126\n",
            "model 730: nodes_first= 24, nodes_second=2, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5118236541748047\n",
            "model 731: nodes_first= 24, nodes_second=2, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5122244358062744\n",
            "model 732: nodes_first= 24, nodes_second=4, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5190380811691284\n",
            "model 733: nodes_first= 24, nodes_second=4, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5182364583015442\n",
            "model 734: nodes_first= 24, nodes_second=4, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5174348950386047\n",
            "model 735: nodes_first= 24, nodes_second=4, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.503406822681427\n",
            "model 736: nodes_first= 24, nodes_second=8, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5458917617797852\n",
            "model 737: nodes_first= 24, nodes_second=8, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5294589400291443\n",
            "model 738: nodes_first= 24, nodes_second=8, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5002003908157349\n",
            "model 739: nodes_first= 24, nodes_second=8, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.4925851821899414\n",
            "model 740: nodes_first= 24, nodes_second=12, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5318637490272522\n",
            "model 741: nodes_first= 24, nodes_second=12, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5258517265319824\n",
            "model 742: nodes_first= 24, nodes_second=12, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.521843671798706\n",
            "model 743: nodes_first= 24, nodes_second=12, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5258517265319824\n",
            "model 744: nodes_first= 24, nodes_second=16, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5422845482826233\n",
            "model 745: nodes_first= 24, nodes_second=16, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5334669351577759\n",
            "model 746: nodes_first= 24, nodes_second=16, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5318637490272522\n",
            "model 747: nodes_first= 24, nodes_second=16, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5198397040367126\n",
            "model 748: nodes_first= 24, nodes_second=24, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5358717441558838\n",
            "model 749: nodes_first= 24, nodes_second=24, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5334669351577759\n",
            "model 750: nodes_first= 24, nodes_second=24, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.52304607629776\n",
            "model 751: nodes_first= 24, nodes_second=24, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.537875771522522\n",
            "model 752: nodes_first= 24, nodes_second=32, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5290580987930298\n",
            "model 753: nodes_first= 24, nodes_second=32, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5210421085357666\n",
            "model 754: nodes_first= 24, nodes_second=32, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5110220313072205\n",
            "model 755: nodes_first= 24, nodes_second=32, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5074148178100586\n",
            "model 756: nodes_first= 32, nodes_second=2, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5198397040367126\n",
            "model 757: nodes_first= 32, nodes_second=2, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5170340538024902\n",
            "model 758: nodes_first= 32, nodes_second=2, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5142284631729126\n",
            "model 759: nodes_first= 32, nodes_second=2, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5106212496757507\n",
            "model 760: nodes_first= 32, nodes_second=4, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5070140361785889\n",
            "model 761: nodes_first= 32, nodes_second=4, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.4985972046852112\n",
            "model 762: nodes_first= 32, nodes_second=4, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.49138277769088745\n",
            "model 763: nodes_first= 32, nodes_second=4, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.49298596382141113\n",
            "model 764: nodes_first= 32, nodes_second=8, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5170340538024902\n",
            "model 765: nodes_first= 32, nodes_second=8, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 766: nodes_first= 32, nodes_second=8, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.4901803731918335\n",
            "model 767: nodes_first= 32, nodes_second=8, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5006012320518494\n",
            "model 768: nodes_first= 32, nodes_second=12, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5603206157684326\n",
            "model 769: nodes_first= 32, nodes_second=12, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5503005981445312\n",
            "model 770: nodes_first= 32, nodes_second=12, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5294589400291443\n",
            "model 771: nodes_first= 32, nodes_second=12, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5330661535263062\n",
            "model 772: nodes_first= 32, nodes_second=16, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5374749302864075\n",
            "model 773: nodes_first= 32, nodes_second=16, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5226452946662903\n",
            "model 774: nodes_first= 32, nodes_second=16, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5210421085357666\n",
            "model 775: nodes_first= 32, nodes_second=16, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.524248480796814\n",
            "model 776: nodes_first= 32, nodes_second=24, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5258517265319824\n",
            "model 777: nodes_first= 32, nodes_second=24, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5286573171615601\n",
            "model 778: nodes_first= 32, nodes_second=24, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.504609227180481\n",
            "model 779: nodes_first= 32, nodes_second=24, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5050100088119507\n",
            "model 780: nodes_first= 32, nodes_second=32, batch=256, dropout_include=True, rate=0.1. Binary accuracy: 0.5591182112693787\n",
            "model 781: nodes_first= 32, nodes_second=32, batch=256, dropout_include=True, rate=0.2. Binary accuracy: 0.5430861711502075\n",
            "model 782: nodes_first= 32, nodes_second=32, batch=256, dropout_include=True, rate=0.3. Binary accuracy: 0.5322645306587219\n",
            "model 783: nodes_first= 32, nodes_second=32, batch=256, dropout_include=True, rate=0.4. Binary accuracy: 0.5226452946662903\n",
            "model 784: nodes_first= 2, nodes_second=2, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.496593177318573\n",
            "model 785: nodes_first= 2, nodes_second=2, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5006012320518494\n",
            "model 786: nodes_first= 2, nodes_second=2, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5006012320518494\n",
            "model 787: nodes_first= 2, nodes_second=2, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.48256513476371765\n",
            "model 788: nodes_first= 2, nodes_second=4, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.4877755641937256\n",
            "model 789: nodes_first= 2, nodes_second=4, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.4793587028980255\n",
            "model 790: nodes_first= 2, nodes_second=4, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.48496994376182556\n",
            "model 791: nodes_first= 2, nodes_second=4, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.4861723482608795\n",
            "model 792: nodes_first= 2, nodes_second=8, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.4945891797542572\n",
            "model 793: nodes_first= 2, nodes_second=8, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.49098196625709534\n",
            "model 794: nodes_first= 2, nodes_second=8, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.49298596382141113\n",
            "model 795: nodes_first= 2, nodes_second=8, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.48216432332992554\n",
            "model 796: nodes_first= 2, nodes_second=12, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5094188451766968\n",
            "model 797: nodes_first= 2, nodes_second=12, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5070140361785889\n",
            "model 798: nodes_first= 2, nodes_second=12, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.4973948001861572\n",
            "model 799: nodes_first= 2, nodes_second=12, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.496593177318573\n",
            "model 800: nodes_first= 2, nodes_second=16, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.4949899911880493\n",
            "model 801: nodes_first= 2, nodes_second=16, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5014027953147888\n",
            "model 802: nodes_first= 2, nodes_second=16, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.47815629839897156\n",
            "model 803: nodes_first= 2, nodes_second=16, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.4973948001861572\n",
            "model 804: nodes_first= 2, nodes_second=24, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5158316493034363\n",
            "model 805: nodes_first= 2, nodes_second=24, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5202404856681824\n",
            "model 806: nodes_first= 2, nodes_second=24, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5098196268081665\n",
            "model 807: nodes_first= 2, nodes_second=24, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.509018063545227\n",
            "model 808: nodes_first= 2, nodes_second=32, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.524248480796814\n",
            "model 809: nodes_first= 2, nodes_second=32, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.509018063545227\n",
            "model 810: nodes_first= 2, nodes_second=32, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5014027953147888\n",
            "model 811: nodes_first= 2, nodes_second=32, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.4973948001861572\n",
            "model 812: nodes_first= 4, nodes_second=2, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5026051998138428\n",
            "model 813: nodes_first= 4, nodes_second=2, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5030060410499573\n",
            "model 814: nodes_first= 4, nodes_second=2, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5006012320518494\n",
            "model 815: nodes_first= 4, nodes_second=2, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.504609227180481\n",
            "model 816: nodes_first= 4, nodes_second=4, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5222445130348206\n",
            "model 817: nodes_first= 4, nodes_second=4, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 818: nodes_first= 4, nodes_second=4, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5118236541748047\n",
            "model 819: nodes_first= 4, nodes_second=4, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5062124133110046\n",
            "model 820: nodes_first= 4, nodes_second=8, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5198397040367126\n",
            "model 821: nodes_first= 4, nodes_second=8, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5186372995376587\n",
            "model 822: nodes_first= 4, nodes_second=8, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5142284631729126\n",
            "model 823: nodes_first= 4, nodes_second=8, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5130260586738586\n",
            "model 824: nodes_first= 4, nodes_second=12, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5262525081634521\n",
            "model 825: nodes_first= 4, nodes_second=12, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5122244358062744\n",
            "model 826: nodes_first= 4, nodes_second=12, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5170340538024902\n",
            "model 827: nodes_first= 4, nodes_second=12, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5066132545471191\n",
            "model 828: nodes_first= 4, nodes_second=16, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5082164406776428\n",
            "model 829: nodes_first= 4, nodes_second=16, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.49098196625709534\n",
            "model 830: nodes_first= 4, nodes_second=16, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5062124133110046\n",
            "model 831: nodes_first= 4, nodes_second=16, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5118236541748047\n",
            "model 832: nodes_first= 4, nodes_second=24, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.49979960918426514\n",
            "model 833: nodes_first= 4, nodes_second=24, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5054108500480652\n",
            "model 834: nodes_first= 4, nodes_second=24, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.49579158425331116\n",
            "model 835: nodes_first= 4, nodes_second=24, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.496593177318573\n",
            "model 836: nodes_first= 4, nodes_second=32, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.4985972046852112\n",
            "model 837: nodes_first= 4, nodes_second=32, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5074148178100586\n",
            "model 838: nodes_first= 4, nodes_second=32, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5014027953147888\n",
            "model 839: nodes_first= 4, nodes_second=32, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5006012320518494\n",
            "model 840: nodes_first= 8, nodes_second=2, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5314629077911377\n",
            "model 841: nodes_first= 8, nodes_second=2, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5130260586738586\n",
            "model 842: nodes_first= 8, nodes_second=2, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5138276815414429\n",
            "model 843: nodes_first= 8, nodes_second=2, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5074148178100586\n",
            "model 844: nodes_first= 8, nodes_second=4, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.49138277769088745\n",
            "model 845: nodes_first= 8, nodes_second=4, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.49138277769088745\n",
            "model 846: nodes_first= 8, nodes_second=4, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.4989979863166809\n",
            "model 847: nodes_first= 8, nodes_second=4, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5054108500480652\n",
            "model 848: nodes_first= 8, nodes_second=8, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.4989979863166809\n",
            "model 849: nodes_first= 8, nodes_second=8, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.49619239568710327\n",
            "model 850: nodes_first= 8, nodes_second=8, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.4897795617580414\n",
            "model 851: nodes_first= 8, nodes_second=8, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.49579158425331116\n",
            "model 852: nodes_first= 8, nodes_second=12, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5178356766700745\n",
            "model 853: nodes_first= 8, nodes_second=12, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5182364583015442\n",
            "model 854: nodes_first= 8, nodes_second=12, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5154308676719666\n",
            "model 855: nodes_first= 8, nodes_second=12, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5030060410499573\n",
            "model 856: nodes_first= 8, nodes_second=16, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5418837666511536\n",
            "model 857: nodes_first= 8, nodes_second=16, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5262525081634521\n",
            "model 858: nodes_first= 8, nodes_second=16, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5282565355300903\n",
            "model 859: nodes_first= 8, nodes_second=16, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5186372995376587\n",
            "model 860: nodes_first= 8, nodes_second=24, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5338677167892456\n",
            "model 861: nodes_first= 8, nodes_second=24, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5058116316795349\n",
            "model 862: nodes_first= 8, nodes_second=24, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5110220313072205\n",
            "model 863: nodes_first= 8, nodes_second=24, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5126252770423889\n",
            "model 864: nodes_first= 8, nodes_second=32, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5130260586738586\n",
            "model 865: nodes_first= 8, nodes_second=32, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5006012320518494\n",
            "model 866: nodes_first= 8, nodes_second=32, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5178356766700745\n",
            "model 867: nodes_first= 8, nodes_second=32, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.49338677525520325\n",
            "model 868: nodes_first= 12, nodes_second=2, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.509018063545227\n",
            "model 869: nodes_first= 12, nodes_second=2, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5042084455490112\n",
            "model 870: nodes_first= 12, nodes_second=2, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5150300860404968\n",
            "model 871: nodes_first= 12, nodes_second=2, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5130260586738586\n",
            "model 872: nodes_first= 12, nodes_second=4, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5214428901672363\n",
            "model 873: nodes_first= 12, nodes_second=4, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5110220313072205\n",
            "model 874: nodes_first= 12, nodes_second=4, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5238476991653442\n",
            "model 875: nodes_first= 12, nodes_second=4, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5122244358062744\n",
            "model 876: nodes_first= 12, nodes_second=8, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.49619239568710327\n",
            "model 877: nodes_first= 12, nodes_second=8, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5042084455490112\n",
            "model 878: nodes_first= 12, nodes_second=8, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5130260586738586\n",
            "model 879: nodes_first= 12, nodes_second=8, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5198397040367126\n",
            "model 880: nodes_first= 12, nodes_second=12, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.4949899911880493\n",
            "model 881: nodes_first= 12, nodes_second=12, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.4941883683204651\n",
            "model 882: nodes_first= 12, nodes_second=12, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.49779558181762695\n",
            "model 883: nodes_first= 12, nodes_second=12, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.4881763458251953\n",
            "model 884: nodes_first= 12, nodes_second=16, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5482965707778931\n",
            "model 885: nodes_first= 12, nodes_second=16, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5346693396568298\n",
            "model 886: nodes_first= 12, nodes_second=16, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5302605032920837\n",
            "model 887: nodes_first= 12, nodes_second=16, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5122244358062744\n",
            "model 888: nodes_first= 12, nodes_second=24, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5170340538024902\n",
            "model 889: nodes_first= 12, nodes_second=24, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5206412672996521\n",
            "model 890: nodes_first= 12, nodes_second=24, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5166332721710205\n",
            "model 891: nodes_first= 12, nodes_second=24, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5070140361785889\n",
            "model 892: nodes_first= 12, nodes_second=32, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5138276815414429\n",
            "model 893: nodes_first= 12, nodes_second=32, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.49779558181762695\n",
            "model 894: nodes_first= 12, nodes_second=32, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.4897795617580414\n",
            "model 895: nodes_first= 12, nodes_second=32, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.4901803731918335\n",
            "model 896: nodes_first= 16, nodes_second=2, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5222445130348206\n",
            "model 897: nodes_first= 16, nodes_second=2, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5138276815414429\n",
            "model 898: nodes_first= 16, nodes_second=2, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5170340538024902\n",
            "model 899: nodes_first= 16, nodes_second=2, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5178356766700745\n",
            "model 900: nodes_first= 16, nodes_second=4, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5018036365509033\n",
            "model 901: nodes_first= 16, nodes_second=4, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.4941883683204651\n",
            "model 902: nodes_first= 16, nodes_second=4, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5006012320518494\n",
            "model 903: nodes_first= 16, nodes_second=4, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5062124133110046\n",
            "model 904: nodes_first= 16, nodes_second=8, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5038076043128967\n",
            "model 905: nodes_first= 16, nodes_second=8, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.49779558181762695\n",
            "model 906: nodes_first= 16, nodes_second=8, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.4941883683204651\n",
            "model 907: nodes_first= 16, nodes_second=8, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5238476991653442\n",
            "model 908: nodes_first= 16, nodes_second=12, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5050100088119507\n",
            "model 909: nodes_first= 16, nodes_second=12, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5070140361785889\n",
            "model 910: nodes_first= 16, nodes_second=12, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5118236541748047\n",
            "model 911: nodes_first= 16, nodes_second=12, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5110220313072205\n",
            "model 912: nodes_first= 16, nodes_second=16, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5122244358062744\n",
            "model 913: nodes_first= 16, nodes_second=16, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5118236541748047\n",
            "model 914: nodes_first= 16, nodes_second=16, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5018036365509033\n",
            "model 915: nodes_first= 16, nodes_second=16, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5106212496757507\n",
            "model 916: nodes_first= 16, nodes_second=24, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5362725257873535\n",
            "model 917: nodes_first= 16, nodes_second=24, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5246493220329285\n",
            "model 918: nodes_first= 16, nodes_second=24, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5238476991653442\n",
            "model 919: nodes_first= 16, nodes_second=24, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.52304607629776\n",
            "model 920: nodes_first= 16, nodes_second=32, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5210421085357666\n",
            "model 921: nodes_first= 16, nodes_second=32, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5238476991653442\n",
            "model 922: nodes_first= 16, nodes_second=32, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.4941883683204651\n",
            "model 923: nodes_first= 16, nodes_second=32, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5062124133110046\n",
            "model 924: nodes_first= 24, nodes_second=2, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5182364583015442\n",
            "model 925: nodes_first= 24, nodes_second=2, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.499398797750473\n",
            "model 926: nodes_first= 24, nodes_second=2, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.49819639325141907\n",
            "model 927: nodes_first= 24, nodes_second=2, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5098196268081665\n",
            "model 928: nodes_first= 24, nodes_second=4, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5158316493034363\n",
            "model 929: nodes_first= 24, nodes_second=4, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5150300860404968\n",
            "model 930: nodes_first= 24, nodes_second=4, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5018036365509033\n",
            "model 931: nodes_first= 24, nodes_second=4, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.4921843707561493\n",
            "model 932: nodes_first= 24, nodes_second=8, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5234469175338745\n",
            "model 933: nodes_first= 24, nodes_second=8, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.49378758668899536\n",
            "model 934: nodes_first= 24, nodes_second=8, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5094188451766968\n",
            "model 935: nodes_first= 24, nodes_second=8, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5018036365509033\n",
            "model 936: nodes_first= 24, nodes_second=12, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5374749302864075\n",
            "model 937: nodes_first= 24, nodes_second=12, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5130260586738586\n",
            "model 938: nodes_first= 24, nodes_second=12, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5202404856681824\n",
            "model 939: nodes_first= 24, nodes_second=12, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5186372995376587\n",
            "model 940: nodes_first= 24, nodes_second=16, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5238476991653442\n",
            "model 941: nodes_first= 24, nodes_second=16, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5170340538024902\n",
            "model 942: nodes_first= 24, nodes_second=16, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.510220468044281\n",
            "model 943: nodes_first= 24, nodes_second=16, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5182364583015442\n",
            "model 944: nodes_first= 24, nodes_second=24, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5543085932731628\n",
            "model 945: nodes_first= 24, nodes_second=24, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5302605032920837\n",
            "model 946: nodes_first= 24, nodes_second=24, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5258517265319824\n",
            "model 947: nodes_first= 24, nodes_second=24, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.511422872543335\n",
            "model 948: nodes_first= 24, nodes_second=32, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5162324905395508\n",
            "model 949: nodes_first= 24, nodes_second=32, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5110220313072205\n",
            "model 950: nodes_first= 24, nodes_second=32, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.510220468044281\n",
            "model 951: nodes_first= 24, nodes_second=32, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5154308676719666\n",
            "model 952: nodes_first= 32, nodes_second=2, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5154308676719666\n",
            "model 953: nodes_first= 32, nodes_second=2, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5094188451766968\n",
            "model 954: nodes_first= 32, nodes_second=2, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5170340538024902\n",
            "model 955: nodes_first= 32, nodes_second=2, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5126252770423889\n",
            "model 956: nodes_first= 32, nodes_second=4, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.504609227180481\n",
            "model 957: nodes_first= 32, nodes_second=4, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5002003908157349\n",
            "model 958: nodes_first= 32, nodes_second=4, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.4945891797542572\n",
            "model 959: nodes_first= 32, nodes_second=4, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.4989979863166809\n",
            "model 960: nodes_first= 32, nodes_second=8, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.509018063545227\n",
            "model 961: nodes_first= 32, nodes_second=8, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5130260586738586\n",
            "model 962: nodes_first= 32, nodes_second=8, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5106212496757507\n",
            "model 963: nodes_first= 32, nodes_second=8, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5062124133110046\n",
            "model 964: nodes_first= 32, nodes_second=12, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5434869527816772\n",
            "model 965: nodes_first= 32, nodes_second=12, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.531062126159668\n",
            "model 966: nodes_first= 32, nodes_second=12, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5226452946662903\n",
            "model 967: nodes_first= 32, nodes_second=12, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.509018063545227\n",
            "model 968: nodes_first= 32, nodes_second=16, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5274549126625061\n",
            "model 969: nodes_first= 32, nodes_second=16, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5406813621520996\n",
            "model 970: nodes_first= 32, nodes_second=16, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5166332721710205\n",
            "model 971: nodes_first= 32, nodes_second=16, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5054108500480652\n",
            "model 972: nodes_first= 32, nodes_second=24, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5418837666511536\n",
            "model 973: nodes_first= 32, nodes_second=24, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5274549126625061\n",
            "model 974: nodes_first= 32, nodes_second=24, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5086172223091125\n",
            "model 975: nodes_first= 32, nodes_second=24, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5390781760215759\n",
            "model 976: nodes_first= 32, nodes_second=32, batch=512, dropout_include=True, rate=0.1. Binary accuracy: 0.5527054071426392\n",
            "model 977: nodes_first= 32, nodes_second=32, batch=512, dropout_include=True, rate=0.2. Binary accuracy: 0.5254508852958679\n",
            "model 978: nodes_first= 32, nodes_second=32, batch=512, dropout_include=True, rate=0.3. Binary accuracy: 0.5446893572807312\n",
            "model 979: nodes_first= 32, nodes_second=32, batch=512, dropout_include=True, rate=0.4. Binary accuracy: 0.5282565355300903\n",
            "model 980: nodes_first= 2, nodes_second=2, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.4985972046852112\n",
            "model 981: nodes_first= 2, nodes_second=2, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.4973948001861572\n",
            "model 982: nodes_first= 2, nodes_second=2, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5054108500480652\n",
            "model 983: nodes_first= 2, nodes_second=2, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4949899911880493\n",
            "model 984: nodes_first= 2, nodes_second=4, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.48016032576560974\n",
            "model 985: nodes_first= 2, nodes_second=4, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.4769538938999176\n",
            "model 986: nodes_first= 2, nodes_second=4, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.4797595143318176\n",
            "model 987: nodes_first= 2, nodes_second=4, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.48256513476371765\n",
            "model 988: nodes_first= 2, nodes_second=8, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.49098196625709534\n",
            "model 989: nodes_first= 2, nodes_second=8, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.48016032576560974\n",
            "model 990: nodes_first= 2, nodes_second=8, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.47414830327033997\n",
            "model 991: nodes_first= 2, nodes_second=8, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4837675392627716\n",
            "model 992: nodes_first= 2, nodes_second=12, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.4925851821899414\n",
            "model 993: nodes_first= 2, nodes_second=12, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.49779558181762695\n",
            "model 994: nodes_first= 2, nodes_second=12, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.49579158425331116\n",
            "model 995: nodes_first= 2, nodes_second=12, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4857715368270874\n",
            "model 996: nodes_first= 2, nodes_second=16, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.4877755641937256\n",
            "model 997: nodes_first= 2, nodes_second=16, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.4945891797542572\n",
            "model 998: nodes_first= 2, nodes_second=16, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.4857715368270874\n",
            "model 999: nodes_first= 2, nodes_second=16, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.48697394132614136\n",
            "model 1000: nodes_first= 2, nodes_second=24, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5030060410499573\n",
            "model 1001: nodes_first= 2, nodes_second=24, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5258517265319824\n",
            "model 1002: nodes_first= 2, nodes_second=24, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5134268403053284\n",
            "model 1003: nodes_first= 2, nodes_second=24, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5082164406776428\n",
            "model 1004: nodes_first= 2, nodes_second=32, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5098196268081665\n",
            "model 1005: nodes_first= 2, nodes_second=32, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5226452946662903\n",
            "model 1006: nodes_first= 2, nodes_second=32, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.49539077281951904\n",
            "model 1007: nodes_first= 2, nodes_second=32, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4925851821899414\n",
            "model 1008: nodes_first= 4, nodes_second=2, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5006012320518494\n",
            "model 1009: nodes_first= 4, nodes_second=2, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.49779558181762695\n",
            "model 1010: nodes_first= 4, nodes_second=2, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5002003908157349\n",
            "model 1011: nodes_first= 4, nodes_second=2, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5010020136833191\n",
            "model 1012: nodes_first= 4, nodes_second=4, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5122244358062744\n",
            "model 1013: nodes_first= 4, nodes_second=4, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.509018063545227\n",
            "model 1014: nodes_first= 4, nodes_second=4, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5010020136833191\n",
            "model 1015: nodes_first= 4, nodes_second=4, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5006012320518494\n",
            "model 1016: nodes_first= 4, nodes_second=8, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5154308676719666\n",
            "model 1017: nodes_first= 4, nodes_second=8, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5202404856681824\n",
            "model 1018: nodes_first= 4, nodes_second=8, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5138276815414429\n",
            "model 1019: nodes_first= 4, nodes_second=8, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5146292448043823\n",
            "model 1020: nodes_first= 4, nodes_second=12, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.509018063545227\n",
            "model 1021: nodes_first= 4, nodes_second=12, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5078156590461731\n",
            "model 1022: nodes_first= 4, nodes_second=12, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5178356766700745\n",
            "model 1023: nodes_first= 4, nodes_second=12, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.49979960918426514\n",
            "model 1024: nodes_first= 4, nodes_second=16, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.503406822681427\n",
            "model 1025: nodes_first= 4, nodes_second=16, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.499398797750473\n",
            "model 1026: nodes_first= 4, nodes_second=16, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5194388628005981\n",
            "model 1027: nodes_first= 4, nodes_second=16, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.509018063545227\n",
            "model 1028: nodes_first= 4, nodes_second=24, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.496593177318573\n",
            "model 1029: nodes_first= 4, nodes_second=24, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5026051998138428\n",
            "model 1030: nodes_first= 4, nodes_second=24, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5002003908157349\n",
            "model 1031: nodes_first= 4, nodes_second=24, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.502204418182373\n",
            "model 1032: nodes_first= 4, nodes_second=32, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.49979960918426514\n",
            "model 1033: nodes_first= 4, nodes_second=32, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.4985972046852112\n",
            "model 1034: nodes_first= 4, nodes_second=32, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5126252770423889\n",
            "model 1035: nodes_first= 4, nodes_second=32, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.511422872543335\n",
            "model 1036: nodes_first= 8, nodes_second=2, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5274549126625061\n",
            "model 1037: nodes_first= 8, nodes_second=2, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 1038: nodes_first= 8, nodes_second=2, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5182364583015442\n",
            "model 1039: nodes_first= 8, nodes_second=2, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5038076043128967\n",
            "model 1040: nodes_first= 8, nodes_second=4, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.4917835593223572\n",
            "model 1041: nodes_first= 8, nodes_second=4, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.4989979863166809\n",
            "model 1042: nodes_first= 8, nodes_second=4, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5074148178100586\n",
            "model 1043: nodes_first= 8, nodes_second=4, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.48296594619750977\n",
            "model 1044: nodes_first= 8, nodes_second=8, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.4941883683204651\n",
            "model 1045: nodes_first= 8, nodes_second=8, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5018036365509033\n",
            "model 1046: nodes_first= 8, nodes_second=8, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.49579158425331116\n",
            "model 1047: nodes_first= 8, nodes_second=8, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5118236541748047\n",
            "model 1048: nodes_first= 8, nodes_second=12, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5174348950386047\n",
            "model 1049: nodes_first= 8, nodes_second=12, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5082164406776428\n",
            "model 1050: nodes_first= 8, nodes_second=12, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.49378758668899536\n",
            "model 1051: nodes_first= 8, nodes_second=12, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5006012320518494\n",
            "model 1052: nodes_first= 8, nodes_second=16, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5358717441558838\n",
            "model 1053: nodes_first= 8, nodes_second=16, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5146292448043823\n",
            "model 1054: nodes_first= 8, nodes_second=16, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5314629077911377\n",
            "model 1055: nodes_first= 8, nodes_second=16, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5174348950386047\n",
            "model 1056: nodes_first= 8, nodes_second=24, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5486974120140076\n",
            "model 1057: nodes_first= 8, nodes_second=24, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5226452946662903\n",
            "model 1058: nodes_first= 8, nodes_second=24, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5214428901672363\n",
            "model 1059: nodes_first= 8, nodes_second=24, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5158316493034363\n",
            "model 1060: nodes_first= 8, nodes_second=32, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5070140361785889\n",
            "model 1061: nodes_first= 8, nodes_second=32, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.49819639325141907\n",
            "model 1062: nodes_first= 8, nodes_second=32, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.49819639325141907\n",
            "model 1063: nodes_first= 8, nodes_second=32, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4881763458251953\n",
            "model 1064: nodes_first= 12, nodes_second=2, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5238476991653442\n",
            "model 1065: nodes_first= 12, nodes_second=2, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.52304607629776\n",
            "model 1066: nodes_first= 12, nodes_second=2, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.499398797750473\n",
            "model 1067: nodes_first= 12, nodes_second=2, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4921843707561493\n",
            "model 1068: nodes_first= 12, nodes_second=4, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5158316493034363\n",
            "model 1069: nodes_first= 12, nodes_second=4, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.511422872543335\n",
            "model 1070: nodes_first= 12, nodes_second=4, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5038076043128967\n",
            "model 1071: nodes_first= 12, nodes_second=4, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5070140361785889\n",
            "model 1072: nodes_first= 12, nodes_second=8, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5082164406776428\n",
            "model 1073: nodes_first= 12, nodes_second=8, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.4985972046852112\n",
            "model 1074: nodes_first= 12, nodes_second=8, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5038076043128967\n",
            "model 1075: nodes_first= 12, nodes_second=8, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.49338677525520325\n",
            "model 1076: nodes_first= 12, nodes_second=12, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.4853707551956177\n",
            "model 1077: nodes_first= 12, nodes_second=12, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.47374749183654785\n",
            "model 1078: nodes_first= 12, nodes_second=12, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.4837675392627716\n",
            "model 1079: nodes_first= 12, nodes_second=12, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4969939887523651\n",
            "model 1080: nodes_first= 12, nodes_second=16, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5406813621520996\n",
            "model 1081: nodes_first= 12, nodes_second=16, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5270541310310364\n",
            "model 1082: nodes_first= 12, nodes_second=16, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5254508852958679\n",
            "model 1083: nodes_first= 12, nodes_second=16, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5194388628005981\n",
            "model 1084: nodes_first= 12, nodes_second=24, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.49979960918426514\n",
            "model 1085: nodes_first= 12, nodes_second=24, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5110220313072205\n",
            "model 1086: nodes_first= 12, nodes_second=24, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.503406822681427\n",
            "model 1087: nodes_first= 12, nodes_second=24, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5074148178100586\n",
            "model 1088: nodes_first= 12, nodes_second=32, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5146292448043823\n",
            "model 1089: nodes_first= 12, nodes_second=32, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.503406822681427\n",
            "model 1090: nodes_first= 12, nodes_second=32, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5002003908157349\n",
            "model 1091: nodes_first= 12, nodes_second=32, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4985972046852112\n",
            "model 1092: nodes_first= 16, nodes_second=2, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5266532897949219\n",
            "model 1093: nodes_first= 16, nodes_second=2, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5110220313072205\n",
            "model 1094: nodes_first= 16, nodes_second=2, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5194388628005981\n",
            "model 1095: nodes_first= 16, nodes_second=2, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5158316493034363\n",
            "model 1096: nodes_first= 16, nodes_second=4, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5014027953147888\n",
            "model 1097: nodes_first= 16, nodes_second=4, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.49098196625709534\n",
            "model 1098: nodes_first= 16, nodes_second=4, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.496593177318573\n",
            "model 1099: nodes_first= 16, nodes_second=4, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4921843707561493\n",
            "model 1100: nodes_first= 16, nodes_second=8, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.49979960918426514\n",
            "model 1101: nodes_first= 16, nodes_second=8, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5082164406776428\n",
            "model 1102: nodes_first= 16, nodes_second=8, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.49579158425331116\n",
            "model 1103: nodes_first= 16, nodes_second=8, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4833667278289795\n",
            "model 1104: nodes_first= 16, nodes_second=12, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5030060410499573\n",
            "model 1105: nodes_first= 16, nodes_second=12, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.49579158425331116\n",
            "model 1106: nodes_first= 16, nodes_second=12, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.499398797750473\n",
            "model 1107: nodes_first= 16, nodes_second=12, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5030060410499573\n",
            "model 1108: nodes_first= 16, nodes_second=16, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.509018063545227\n",
            "model 1109: nodes_first= 16, nodes_second=16, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5038076043128967\n",
            "model 1110: nodes_first= 16, nodes_second=16, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.4841683506965637\n",
            "model 1111: nodes_first= 16, nodes_second=16, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4973948001861572\n",
            "model 1112: nodes_first= 16, nodes_second=24, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5338677167892456\n",
            "model 1113: nodes_first= 16, nodes_second=24, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5146292448043823\n",
            "model 1114: nodes_first= 16, nodes_second=24, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5050100088119507\n",
            "model 1115: nodes_first= 16, nodes_second=24, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.499398797750473\n",
            "model 1116: nodes_first= 16, nodes_second=32, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5118236541748047\n",
            "model 1117: nodes_first= 16, nodes_second=32, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5054108500480652\n",
            "model 1118: nodes_first= 16, nodes_second=32, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.496593177318573\n",
            "model 1119: nodes_first= 16, nodes_second=32, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5106212496757507\n",
            "model 1120: nodes_first= 24, nodes_second=2, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5222445130348206\n",
            "model 1121: nodes_first= 24, nodes_second=2, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5142284631729126\n",
            "model 1122: nodes_first= 24, nodes_second=2, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5162324905395508\n",
            "model 1123: nodes_first= 24, nodes_second=2, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5118236541748047\n",
            "model 1124: nodes_first= 24, nodes_second=4, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5138276815414429\n",
            "model 1125: nodes_first= 24, nodes_second=4, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.49298596382141113\n",
            "model 1126: nodes_first= 24, nodes_second=4, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.48456913232803345\n",
            "model 1127: nodes_first= 24, nodes_second=4, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.48737475275993347\n",
            "model 1128: nodes_first= 24, nodes_second=8, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5234469175338745\n",
            "model 1129: nodes_first= 24, nodes_second=8, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5182364583015442\n",
            "model 1130: nodes_first= 24, nodes_second=8, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.4917835593223572\n",
            "model 1131: nodes_first= 24, nodes_second=8, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4837675392627716\n",
            "model 1132: nodes_first= 24, nodes_second=12, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5122244358062744\n",
            "model 1133: nodes_first= 24, nodes_second=12, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.499398797750473\n",
            "model 1134: nodes_first= 24, nodes_second=12, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.521843671798706\n",
            "model 1135: nodes_first= 24, nodes_second=12, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5262525081634521\n",
            "model 1136: nodes_first= 24, nodes_second=16, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5182364583015442\n",
            "model 1137: nodes_first= 24, nodes_second=16, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5178356766700745\n",
            "model 1138: nodes_first= 24, nodes_second=16, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5074148178100586\n",
            "model 1139: nodes_first= 24, nodes_second=16, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5254508852958679\n",
            "model 1140: nodes_first= 24, nodes_second=24, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.537875771522522\n",
            "model 1141: nodes_first= 24, nodes_second=24, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5226452946662903\n",
            "model 1142: nodes_first= 24, nodes_second=24, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5142284631729126\n",
            "model 1143: nodes_first= 24, nodes_second=24, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5106212496757507\n",
            "model 1144: nodes_first= 24, nodes_second=32, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.511422872543335\n",
            "model 1145: nodes_first= 24, nodes_second=32, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5134268403053284\n",
            "model 1146: nodes_first= 24, nodes_second=32, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5098196268081665\n",
            "model 1147: nodes_first= 24, nodes_second=32, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5118236541748047\n",
            "model 1148: nodes_first= 32, nodes_second=2, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5154308676719666\n",
            "model 1149: nodes_first= 32, nodes_second=2, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5134268403053284\n",
            "model 1150: nodes_first= 32, nodes_second=2, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5082164406776428\n",
            "model 1151: nodes_first= 32, nodes_second=2, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.504609227180481\n",
            "model 1152: nodes_first= 32, nodes_second=4, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5050100088119507\n",
            "model 1153: nodes_first= 32, nodes_second=4, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.49779558181762695\n",
            "model 1154: nodes_first= 32, nodes_second=4, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.49298596382141113\n",
            "model 1155: nodes_first= 32, nodes_second=4, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.49338677525520325\n",
            "model 1156: nodes_first= 32, nodes_second=8, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5154308676719666\n",
            "model 1157: nodes_first= 32, nodes_second=8, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5166332721710205\n",
            "model 1158: nodes_first= 32, nodes_second=8, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.4949899911880493\n",
            "model 1159: nodes_first= 32, nodes_second=8, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.4985972046852112\n",
            "model 1160: nodes_first= 32, nodes_second=12, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5442885756492615\n",
            "model 1161: nodes_first= 32, nodes_second=12, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5442885756492615\n",
            "model 1162: nodes_first= 32, nodes_second=12, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5094188451766968\n",
            "model 1163: nodes_first= 32, nodes_second=12, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5086172223091125\n",
            "model 1164: nodes_first= 32, nodes_second=16, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5314629077911377\n",
            "model 1165: nodes_first= 32, nodes_second=16, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5226452946662903\n",
            "model 1166: nodes_first= 32, nodes_second=16, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5146292448043823\n",
            "model 1167: nodes_first= 32, nodes_second=16, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.5058116316795349\n",
            "model 1168: nodes_first= 32, nodes_second=24, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5282565355300903\n",
            "model 1169: nodes_first= 32, nodes_second=24, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.502204418182373\n",
            "model 1170: nodes_first= 32, nodes_second=24, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5106212496757507\n",
            "model 1171: nodes_first= 32, nodes_second=24, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.48456913232803345\n",
            "model 1172: nodes_first= 32, nodes_second=32, batch=1024, dropout_include=True, rate=0.1. Binary accuracy: 0.5130260586738586\n",
            "model 1173: nodes_first= 32, nodes_second=32, batch=1024, dropout_include=True, rate=0.2. Binary accuracy: 0.5078156590461731\n",
            "model 1174: nodes_first= 32, nodes_second=32, batch=1024, dropout_include=True, rate=0.3. Binary accuracy: 0.5082164406776428\n",
            "model 1175: nodes_first= 32, nodes_second=32, batch=1024, dropout_include=True, rate=0.4. Binary accuracy: 0.49138277769088745\n",
            "model 1176: nodes_first= 2, nodes_second=2, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.529859721660614\n",
            "model 1177: nodes_first= 2, nodes_second=4, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5126252770423889\n",
            "model 1178: nodes_first= 2, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.536673367023468\n",
            "model 1179: nodes_first= 2, nodes_second=12, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5434869527816772\n",
            "model 1180: nodes_first= 2, nodes_second=16, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5350701212882996\n",
            "model 1181: nodes_first= 2, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5382765531539917\n",
            "model 1182: nodes_first= 2, nodes_second=32, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5398797392845154\n",
            "model 1183: nodes_first= 4, nodes_second=2, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5326653122901917\n",
            "model 1184: nodes_first= 4, nodes_second=4, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5474950075149536\n",
            "model 1185: nodes_first= 4, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5326653122901917\n",
            "model 1186: nodes_first= 4, nodes_second=12, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5358717441558838\n",
            "model 1187: nodes_first= 4, nodes_second=16, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5322645306587219\n",
            "model 1188: nodes_first= 4, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5390781760215759\n",
            "model 1189: nodes_first= 4, nodes_second=32, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5334669351577759\n",
            "model 1190: nodes_first= 8, nodes_second=2, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5454909801483154\n",
            "model 1191: nodes_first= 8, nodes_second=4, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5523046255111694\n",
            "model 1192: nodes_first= 8, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5374749302864075\n",
            "model 1193: nodes_first= 8, nodes_second=12, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5579158067703247\n",
            "model 1194: nodes_first= 8, nodes_second=16, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5587174296379089\n",
            "model 1195: nodes_first= 8, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5551102161407471\n",
            "model 1196: nodes_first= 8, nodes_second=32, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5470941662788391\n",
            "model 1197: nodes_first= 12, nodes_second=2, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5462926030158997\n",
            "model 1198: nodes_first= 12, nodes_second=4, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5426853895187378\n",
            "model 1199: nodes_first= 12, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5679358839988708\n",
            "model 1200: nodes_first= 12, nodes_second=12, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5334669351577759\n",
            "model 1201: nodes_first= 12, nodes_second=16, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5623246431350708\n",
            "model 1202: nodes_first= 12, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5547094345092773\n",
            "model 1203: nodes_first= 12, nodes_second=32, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5559118390083313\n",
            "model 1204: nodes_first= 16, nodes_second=2, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5266532897949219\n",
            "model 1205: nodes_first= 16, nodes_second=4, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5410821437835693\n",
            "model 1206: nodes_first= 16, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5519037842750549\n",
            "model 1207: nodes_first= 16, nodes_second=12, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.549498975276947\n",
            "model 1208: nodes_first= 16, nodes_second=16, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5434869527816772\n",
            "model 1209: nodes_first= 16, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.550701379776001\n",
            "model 1210: nodes_first= 16, nodes_second=32, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5675350427627563\n",
            "model 1211: nodes_first= 24, nodes_second=2, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5579158067703247\n",
            "model 1212: nodes_first= 24, nodes_second=4, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5482965707778931\n",
            "model 1213: nodes_first= 24, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5811623334884644\n",
            "model 1214: nodes_first= 24, nodes_second=12, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5639278292655945\n",
            "model 1215: nodes_first= 24, nodes_second=16, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5659318566322327\n",
            "model 1216: nodes_first= 24, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5663326382637024\n",
            "model 1217: nodes_first= 24, nodes_second=32, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5587174296379089\n",
            "model 1218: nodes_first= 32, nodes_second=2, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5258517265319824\n",
            "model 1219: nodes_first= 32, nodes_second=4, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5462926030158997\n",
            "model 1220: nodes_first= 32, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5767534971237183\n",
            "model 1221: nodes_first= 32, nodes_second=12, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5623246431350708\n",
            "model 1222: nodes_first= 32, nodes_second=16, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5583166480064392\n",
            "model 1223: nodes_first= 32, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5719438791275024\n",
            "model 1224: nodes_first= 32, nodes_second=32, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5711422562599182\n",
            "model 1225: nodes_first= 2, nodes_second=2, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5254508852958679\n",
            "model 1226: nodes_first= 2, nodes_second=4, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5110220313072205\n",
            "model 1227: nodes_first= 2, nodes_second=8, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5174348950386047\n",
            "model 1228: nodes_first= 2, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5386773347854614\n",
            "model 1229: nodes_first= 2, nodes_second=16, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5282565355300903\n",
            "model 1230: nodes_first= 2, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5434869527816772\n",
            "model 1231: nodes_first= 2, nodes_second=32, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5370741486549377\n",
            "model 1232: nodes_first= 4, nodes_second=2, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5322645306587219\n",
            "model 1233: nodes_first= 4, nodes_second=4, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5426853895187378\n",
            "model 1234: nodes_first= 4, nodes_second=8, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5282565355300903\n",
            "model 1235: nodes_first= 4, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5322645306587219\n",
            "model 1236: nodes_first= 4, nodes_second=16, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.531062126159668\n",
            "model 1237: nodes_first= 4, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5338677167892456\n",
            "model 1238: nodes_first= 4, nodes_second=32, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5262525081634521\n",
            "model 1239: nodes_first= 8, nodes_second=2, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5523046255111694\n",
            "model 1240: nodes_first= 8, nodes_second=4, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5551102161407471\n",
            "model 1241: nodes_first= 8, nodes_second=8, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5290580987930298\n",
            "model 1242: nodes_first= 8, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5591182112693787\n",
            "model 1243: nodes_first= 8, nodes_second=16, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5543085932731628\n",
            "model 1244: nodes_first= 8, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5583166480064392\n",
            "model 1245: nodes_first= 8, nodes_second=32, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5519037842750549\n",
            "model 1246: nodes_first= 12, nodes_second=2, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5390781760215759\n",
            "model 1247: nodes_first= 12, nodes_second=4, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5306613445281982\n",
            "model 1248: nodes_first= 12, nodes_second=8, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5579158067703247\n",
            "model 1249: nodes_first= 12, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5254508852958679\n",
            "model 1250: nodes_first= 12, nodes_second=16, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5595190525054932\n",
            "model 1251: nodes_first= 12, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5434869527816772\n",
            "model 1252: nodes_first= 12, nodes_second=32, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5599198341369629\n",
            "model 1253: nodes_first= 16, nodes_second=2, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5270541310310364\n",
            "model 1254: nodes_first= 16, nodes_second=4, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5370741486549377\n",
            "model 1255: nodes_first= 16, nodes_second=8, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5434869527816772\n",
            "model 1256: nodes_first= 16, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5474950075149536\n",
            "model 1257: nodes_first= 16, nodes_second=16, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5410821437835693\n",
            "model 1258: nodes_first= 16, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5490981936454773\n",
            "model 1259: nodes_first= 16, nodes_second=32, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5587174296379089\n",
            "model 1260: nodes_first= 24, nodes_second=2, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5270541310310364\n",
            "model 1261: nodes_first= 24, nodes_second=4, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5414829850196838\n",
            "model 1262: nodes_first= 24, nodes_second=8, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5695390701293945\n",
            "model 1263: nodes_first= 24, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5623246431350708\n",
            "model 1264: nodes_first= 24, nodes_second=16, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5567134022712708\n",
            "model 1265: nodes_first= 24, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5703406929969788\n",
            "model 1266: nodes_first= 24, nodes_second=32, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5571142435073853\n",
            "model 1267: nodes_first= 32, nodes_second=2, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5394789576530457\n",
            "model 1268: nodes_first= 32, nodes_second=4, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5430861711502075\n",
            "model 1269: nodes_first= 32, nodes_second=8, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5607214570045471\n",
            "model 1270: nodes_first= 32, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.575951874256134\n",
            "model 1271: nodes_first= 32, nodes_second=16, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5543085932731628\n",
            "model 1272: nodes_first= 32, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5715430974960327\n",
            "model 1273: nodes_first= 32, nodes_second=32, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5655310750007629\n",
            "model 1274: nodes_first= 2, nodes_second=2, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5270541310310364\n",
            "model 1275: nodes_first= 2, nodes_second=4, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.49378758668899536\n",
            "model 1276: nodes_first= 2, nodes_second=8, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5138276815414429\n",
            "model 1277: nodes_first= 2, nodes_second=12, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5358717441558838\n",
            "model 1278: nodes_first= 2, nodes_second=16, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5186372995376587\n",
            "model 1279: nodes_first= 2, nodes_second=24, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5386773347854614\n",
            "model 1280: nodes_first= 2, nodes_second=32, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5358717441558838\n",
            "model 1281: nodes_first= 4, nodes_second=2, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5234469175338745\n",
            "model 1282: nodes_first= 4, nodes_second=4, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5402805805206299\n",
            "model 1283: nodes_first= 4, nodes_second=8, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5314629077911377\n",
            "model 1284: nodes_first= 4, nodes_second=12, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5278556942939758\n",
            "model 1285: nodes_first= 4, nodes_second=16, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5258517265319824\n",
            "model 1286: nodes_first= 4, nodes_second=24, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5250501036643982\n",
            "model 1287: nodes_first= 4, nodes_second=32, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5238476991653442\n",
            "model 1288: nodes_first= 8, nodes_second=2, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5414829850196838\n",
            "model 1289: nodes_first= 8, nodes_second=4, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5426853895187378\n",
            "model 1290: nodes_first= 8, nodes_second=8, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5030060410499573\n",
            "model 1291: nodes_first= 8, nodes_second=12, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5426853895187378\n",
            "model 1292: nodes_first= 8, nodes_second=16, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5470941662788391\n",
            "model 1293: nodes_first= 8, nodes_second=24, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5559118390083313\n",
            "model 1294: nodes_first= 8, nodes_second=32, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5486974120140076\n",
            "model 1295: nodes_first= 12, nodes_second=2, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5390781760215759\n",
            "model 1296: nodes_first= 12, nodes_second=4, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5226452946662903\n",
            "model 1297: nodes_first= 12, nodes_second=8, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5370741486549377\n",
            "model 1298: nodes_first= 12, nodes_second=12, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5146292448043823\n",
            "model 1299: nodes_first= 12, nodes_second=16, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5579158067703247\n",
            "model 1300: nodes_first= 12, nodes_second=24, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5426853895187378\n",
            "model 1301: nodes_first= 12, nodes_second=32, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.557515025138855\n",
            "model 1302: nodes_first= 16, nodes_second=2, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5270541310310364\n",
            "model 1303: nodes_first= 16, nodes_second=4, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.529859721660614\n",
            "model 1304: nodes_first= 16, nodes_second=8, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5410821437835693\n",
            "model 1305: nodes_first= 16, nodes_second=12, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5386773347854614\n",
            "model 1306: nodes_first= 16, nodes_second=16, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5346693396568298\n",
            "model 1307: nodes_first= 16, nodes_second=24, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5470941662788391\n",
            "model 1308: nodes_first= 16, nodes_second=32, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.550701379776001\n",
            "model 1309: nodes_first= 24, nodes_second=2, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5346693396568298\n",
            "model 1310: nodes_first= 24, nodes_second=4, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5398797392845154\n",
            "model 1311: nodes_first= 24, nodes_second=8, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5635270476341248\n",
            "model 1312: nodes_first= 24, nodes_second=12, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5647294521331787\n",
            "model 1313: nodes_first= 24, nodes_second=16, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5707414746284485\n",
            "model 1314: nodes_first= 24, nodes_second=24, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5663326382637024\n",
            "model 1315: nodes_first= 24, nodes_second=32, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5559118390083313\n",
            "model 1316: nodes_first= 32, nodes_second=2, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.529859721660614\n",
            "model 1317: nodes_first= 32, nodes_second=4, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5210421085357666\n",
            "model 1318: nodes_first= 32, nodes_second=8, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5454909801483154\n",
            "model 1319: nodes_first= 32, nodes_second=12, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5651302337646484\n",
            "model 1320: nodes_first= 32, nodes_second=16, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.556312620639801\n",
            "model 1321: nodes_first= 32, nodes_second=24, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5687374472618103\n",
            "model 1322: nodes_first= 32, nodes_second=32, batch=128, dropout_include=False, rate=None. Binary accuracy: 0.5683366656303406\n",
            "model 1323: nodes_first= 2, nodes_second=2, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.510220468044281\n",
            "model 1324: nodes_first= 2, nodes_second=4, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.48697394132614136\n",
            "model 1325: nodes_first= 2, nodes_second=8, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5030060410499573\n",
            "model 1326: nodes_first= 2, nodes_second=12, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5254508852958679\n",
            "model 1327: nodes_first= 2, nodes_second=16, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.510220468044281\n",
            "model 1328: nodes_first= 2, nodes_second=24, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5342685580253601\n",
            "model 1329: nodes_first= 2, nodes_second=32, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5306613445281982\n",
            "model 1330: nodes_first= 4, nodes_second=2, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5146292448043823\n",
            "model 1331: nodes_first= 4, nodes_second=4, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5186372995376587\n",
            "model 1332: nodes_first= 4, nodes_second=8, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5270541310310364\n",
            "model 1333: nodes_first= 4, nodes_second=12, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5250501036643982\n",
            "model 1334: nodes_first= 4, nodes_second=16, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5270541310310364\n",
            "model 1335: nodes_first= 4, nodes_second=24, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.521843671798706\n",
            "model 1336: nodes_first= 4, nodes_second=32, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5234469175338745\n",
            "model 1337: nodes_first= 8, nodes_second=2, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5470941662788391\n",
            "model 1338: nodes_first= 8, nodes_second=4, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5038076043128967\n",
            "model 1339: nodes_first= 8, nodes_second=8, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.4989979863166809\n",
            "model 1340: nodes_first= 8, nodes_second=12, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5354709625244141\n",
            "model 1341: nodes_first= 8, nodes_second=16, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5478957891464233\n",
            "model 1342: nodes_first= 8, nodes_second=24, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5599198341369629\n",
            "model 1343: nodes_first= 8, nodes_second=32, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5322645306587219\n",
            "model 1344: nodes_first= 12, nodes_second=2, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5294589400291443\n",
            "model 1345: nodes_first= 12, nodes_second=4, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5206412672996521\n",
            "model 1346: nodes_first= 12, nodes_second=8, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5162324905395508\n",
            "model 1347: nodes_first= 12, nodes_second=12, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5026051998138428\n",
            "model 1348: nodes_first= 12, nodes_second=16, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5555109977722168\n",
            "model 1349: nodes_first= 12, nodes_second=24, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5434869527816772\n",
            "model 1350: nodes_first= 12, nodes_second=32, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5490981936454773\n",
            "model 1351: nodes_first= 16, nodes_second=2, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5294589400291443\n",
            "model 1352: nodes_first= 16, nodes_second=4, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5134268403053284\n",
            "model 1353: nodes_first= 16, nodes_second=8, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5206412672996521\n",
            "model 1354: nodes_first= 16, nodes_second=12, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5398797392845154\n",
            "model 1355: nodes_first= 16, nodes_second=16, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.529859721660614\n",
            "model 1356: nodes_first= 16, nodes_second=24, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5410821437835693\n",
            "model 1357: nodes_first= 16, nodes_second=32, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5519037842750549\n",
            "model 1358: nodes_first= 24, nodes_second=2, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5294589400291443\n",
            "model 1359: nodes_first= 24, nodes_second=4, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5162324905395508\n",
            "model 1360: nodes_first= 24, nodes_second=8, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5663326382637024\n",
            "model 1361: nodes_first= 24, nodes_second=12, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5571142435073853\n",
            "model 1362: nodes_first= 24, nodes_second=16, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5539078116416931\n",
            "model 1363: nodes_first= 24, nodes_second=24, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5591182112693787\n",
            "model 1364: nodes_first= 24, nodes_second=32, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5442885756492615\n",
            "model 1365: nodes_first= 32, nodes_second=2, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5286573171615601\n",
            "model 1366: nodes_first= 32, nodes_second=4, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5070140361785889\n",
            "model 1367: nodes_first= 32, nodes_second=8, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5350701212882996\n",
            "model 1368: nodes_first= 32, nodes_second=12, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.564328670501709\n",
            "model 1369: nodes_first= 32, nodes_second=16, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.5486974120140076\n",
            "model 1370: nodes_first= 32, nodes_second=24, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.564328670501709\n",
            "model 1371: nodes_first= 32, nodes_second=32, batch=256, dropout_include=False, rate=None. Binary accuracy: 0.564328670501709\n",
            "model 1372: nodes_first= 2, nodes_second=2, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.49298596382141113\n",
            "model 1373: nodes_first= 2, nodes_second=4, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.47374749183654785\n",
            "model 1374: nodes_first= 2, nodes_second=8, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.49979960918426514\n",
            "model 1375: nodes_first= 2, nodes_second=12, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5142284631729126\n",
            "model 1376: nodes_first= 2, nodes_second=16, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5030060410499573\n",
            "model 1377: nodes_first= 2, nodes_second=24, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5346693396568298\n",
            "model 1378: nodes_first= 2, nodes_second=32, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5274549126625061\n",
            "model 1379: nodes_first= 4, nodes_second=2, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5066132545471191\n",
            "model 1380: nodes_first= 4, nodes_second=4, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.509018063545227\n",
            "model 1381: nodes_first= 4, nodes_second=8, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5214428901672363\n",
            "model 1382: nodes_first= 4, nodes_second=12, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5202404856681824\n",
            "model 1383: nodes_first= 4, nodes_second=16, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5166332721710205\n",
            "model 1384: nodes_first= 4, nodes_second=24, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.509018063545227\n",
            "model 1385: nodes_first= 4, nodes_second=32, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5122244358062744\n",
            "model 1386: nodes_first= 8, nodes_second=2, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5402805805206299\n",
            "model 1387: nodes_first= 8, nodes_second=4, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.4925851821899414\n",
            "model 1388: nodes_first= 8, nodes_second=8, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.4941883683204651\n",
            "model 1389: nodes_first= 8, nodes_second=12, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5318637490272522\n",
            "model 1390: nodes_first= 8, nodes_second=16, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5454909801483154\n",
            "model 1391: nodes_first= 8, nodes_second=24, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5555109977722168\n",
            "model 1392: nodes_first= 8, nodes_second=32, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5170340538024902\n",
            "model 1393: nodes_first= 12, nodes_second=2, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5226452946662903\n",
            "model 1394: nodes_first= 12, nodes_second=4, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.511422872543335\n",
            "model 1395: nodes_first= 12, nodes_second=8, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5050100088119507\n",
            "model 1396: nodes_first= 12, nodes_second=12, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.48657315969467163\n",
            "model 1397: nodes_first= 12, nodes_second=16, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5571142435073853\n",
            "model 1398: nodes_first= 12, nodes_second=24, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5454909801483154\n",
            "model 1399: nodes_first= 12, nodes_second=32, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5454909801483154\n",
            "model 1400: nodes_first= 16, nodes_second=2, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5266532897949219\n",
            "model 1401: nodes_first= 16, nodes_second=4, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5066132545471191\n",
            "model 1402: nodes_first= 16, nodes_second=8, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.504609227180481\n",
            "model 1403: nodes_first= 16, nodes_second=12, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.531062126159668\n",
            "model 1404: nodes_first= 16, nodes_second=16, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5266532897949219\n",
            "model 1405: nodes_first= 16, nodes_second=24, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5478957891464233\n",
            "model 1406: nodes_first= 16, nodes_second=32, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5198397040367126\n",
            "model 1407: nodes_first= 24, nodes_second=2, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5306613445281982\n",
            "model 1408: nodes_first= 24, nodes_second=4, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.4989979863166809\n",
            "model 1409: nodes_first= 24, nodes_second=8, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5623246431350708\n",
            "model 1410: nodes_first= 24, nodes_second=12, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5278556942939758\n",
            "model 1411: nodes_first= 24, nodes_second=16, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5515030026435852\n",
            "model 1412: nodes_first= 24, nodes_second=24, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5567134022712708\n",
            "model 1413: nodes_first= 24, nodes_second=32, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5262525081634521\n",
            "model 1414: nodes_first= 32, nodes_second=2, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5234469175338745\n",
            "model 1415: nodes_first= 32, nodes_second=4, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5134268403053284\n",
            "model 1416: nodes_first= 32, nodes_second=8, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5158316493034363\n",
            "model 1417: nodes_first= 32, nodes_second=12, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5659318566322327\n",
            "model 1418: nodes_first= 32, nodes_second=16, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5386773347854614\n",
            "model 1419: nodes_first= 32, nodes_second=24, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5454909801483154\n",
            "model 1420: nodes_first= 32, nodes_second=32, batch=512, dropout_include=False, rate=None. Binary accuracy: 0.5607214570045471\n",
            "model 1421: nodes_first= 2, nodes_second=2, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.48937875032424927\n",
            "model 1422: nodes_first= 2, nodes_second=4, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4665330648422241\n",
            "model 1423: nodes_first= 2, nodes_second=8, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5002003908157349\n",
            "model 1424: nodes_first= 2, nodes_second=12, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4973948001861572\n",
            "model 1425: nodes_first= 2, nodes_second=16, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4925851821899414\n",
            "model 1426: nodes_first= 2, nodes_second=24, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5354709625244141\n",
            "model 1427: nodes_first= 2, nodes_second=32, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5278556942939758\n",
            "model 1428: nodes_first= 4, nodes_second=2, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4949899911880493\n",
            "model 1429: nodes_first= 4, nodes_second=4, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5078156590461731\n",
            "model 1430: nodes_first= 4, nodes_second=8, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.52304607629776\n",
            "model 1431: nodes_first= 4, nodes_second=12, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.504609227180481\n",
            "model 1432: nodes_first= 4, nodes_second=16, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5130260586738586\n",
            "model 1433: nodes_first= 4, nodes_second=24, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.49298596382141113\n",
            "model 1434: nodes_first= 4, nodes_second=32, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5074148178100586\n",
            "model 1435: nodes_first= 8, nodes_second=2, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5394789576530457\n",
            "model 1436: nodes_first= 8, nodes_second=4, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4853707551956177\n",
            "model 1437: nodes_first= 8, nodes_second=8, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.49779558181762695\n",
            "model 1438: nodes_first= 8, nodes_second=12, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5182364583015442\n",
            "model 1439: nodes_first= 8, nodes_second=16, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5458917617797852\n",
            "model 1440: nodes_first= 8, nodes_second=24, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5470941662788391\n",
            "model 1441: nodes_first= 8, nodes_second=32, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5126252770423889\n",
            "model 1442: nodes_first= 12, nodes_second=2, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5198397040367126\n",
            "model 1443: nodes_first= 12, nodes_second=4, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5118236541748047\n",
            "model 1444: nodes_first= 12, nodes_second=8, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5082164406776428\n",
            "model 1445: nodes_first= 12, nodes_second=12, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4745490849018097\n",
            "model 1446: nodes_first= 12, nodes_second=16, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5482965707778931\n",
            "model 1447: nodes_first= 12, nodes_second=24, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5350701212882996\n",
            "model 1448: nodes_first= 12, nodes_second=32, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5450901985168457\n",
            "model 1449: nodes_first= 16, nodes_second=2, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5238476991653442\n",
            "model 1450: nodes_first= 16, nodes_second=4, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5038076043128967\n",
            "model 1451: nodes_first= 16, nodes_second=8, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4985972046852112\n",
            "model 1452: nodes_first= 16, nodes_second=12, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5134268403053284\n",
            "model 1453: nodes_first= 16, nodes_second=16, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5314629077911377\n",
            "model 1454: nodes_first= 16, nodes_second=24, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5446893572807312\n",
            "model 1455: nodes_first= 16, nodes_second=32, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.510220468044281\n",
            "model 1456: nodes_first= 24, nodes_second=2, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5254508852958679\n",
            "model 1457: nodes_first= 24, nodes_second=4, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.4969939887523651\n",
            "model 1458: nodes_first= 24, nodes_second=8, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5326653122901917\n",
            "model 1459: nodes_first= 24, nodes_second=12, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5166332721710205\n",
            "model 1460: nodes_first= 24, nodes_second=16, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5394789576530457\n",
            "model 1461: nodes_first= 24, nodes_second=24, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5543085932731628\n",
            "model 1462: nodes_first= 24, nodes_second=32, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5274549126625061\n",
            "model 1463: nodes_first= 32, nodes_second=2, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5250501036643982\n",
            "model 1464: nodes_first= 32, nodes_second=4, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5110220313072205\n",
            "model 1465: nodes_first= 32, nodes_second=8, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5130260586738586\n",
            "model 1466: nodes_first= 32, nodes_second=12, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5559118390083313\n",
            "model 1467: nodes_first= 32, nodes_second=16, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5418837666511536\n",
            "model 1468: nodes_first= 32, nodes_second=24, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5406813621520996\n",
            "model 1469: nodes_first= 32, nodes_second=32, batch=1024, dropout_include=False, rate=None. Binary accuracy: 0.5278556942939758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(range(len(accuracy_list)), key=lambda x: accuracy_list[x])[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRdpcMxbQwlS",
        "outputId": "6912eb6b-f73b-4144-f6e4-ee5f7d63e7a7"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1272, 1223, 1270, 1220, 1213]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Top 5 models**"
      ],
      "metadata": {
        "id": "uraff3kqjHDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 1272: nodes_first= 32, nodes_second=24, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.5715430974960327\n",
        "\n",
        "model 1223: nodes_first= 32, nodes_second=24, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5719438791275024\n",
        "\n",
        "model 1270: nodes_first= 32, nodes_second=12, batch=64, dropout_include=False, rate=None. Binary accuracy: 0.575951874256134\n",
        "\n",
        "model 1220: nodes_first= 32, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5767534971237183\n",
        "\n",
        "model 1213: nodes_first= 24, nodes_second=8, batch=32, dropout_include=False, rate=None. Binary accuracy: 0.5811623334884644"
      ],
      "metadata": {
        "id": "UVvmlbvmipxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network(nodes_first, nodes_second, batch, dropout_include, SEED, X_train, y_train, X_valid, y_valid, rate_=None):\n",
        "\n",
        "  from tensorflow.python.framework import ops\n",
        "  ops.reset_default_graph()\n",
        "\n",
        "  seed(SEED)\n",
        "  tensorflow.random.set_seed(SEED)\n",
        "  random.seed(SEED)\n",
        "  numpy.random.seed(SEED)\n",
        "\n",
        "  if dropout_include==False:\n",
        "      model = keras.Sequential([\n",
        "          layers.Dense(nodes_first, activation='relu'),\n",
        "          layers.Dense(nodes_second, activation='relu'),  \n",
        "          layers.Dense(1, activation='sigmoid')\n",
        "      ])\n",
        "  else:\n",
        "      model = keras.Sequential([\n",
        "          layers.Dense(nodes_first, activation='relu'),\n",
        "          layers.Dropout(rate=rate_),\n",
        "          layers.Dense(nodes_second, activation='relu'),\n",
        "          layers.Dropout(rate=rate_),    \n",
        "          layers.Dense(1, activation='sigmoid')\n",
        "      ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['binary_accuracy'])\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(\n",
        "      patience=3,\n",
        "      min_delta=0.001,\n",
        "      restore_best_weights=False,\n",
        "  )\n",
        "\n",
        "  history = model.fit(\n",
        "      X_train, y_train,\n",
        "      validation_data=(X_valid, y_valid),\n",
        "      batch_size=batch,\n",
        "      epochs=20,\n",
        "      verbose=0,\n",
        "      callbacks=[early_stopping]\n",
        "  )\n",
        "\n",
        "  return pd.DataFrame(model.predict(X_valid, verbose=1)), str(history.history['binary_accuracy'][-1])"
      ],
      "metadata": {
        "id": "Azs9a3_tP5n-"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_5, bin_acc = neural_network(nodes_first= 32, nodes_second=24, batch=64, dropout_include=False, rate_=None, SEED = SEED, X_train = X_train_transformed, y_train = y_train, X_valid = X_test_transformed, y_valid = y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnq69IyRPcgP",
        "outputId": "8b86b0e7-41d8-4a48-bcb7-7f822ebbf8c5"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QZDNkABuPeE2",
        "outputId": "6ad5460f-e64a-4539-8d90-c76058724eb1"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0\n",
              "0    0.391584\n",
              "1    0.322723\n",
              "2    0.366349\n",
              "3    0.362144\n",
              "4    0.377586\n",
              "..        ...\n",
              "632  0.508823\n",
              "633  0.552950\n",
              "634  0.589796\n",
              "635  0.598485\n",
              "636  0.396026\n",
              "\n",
              "[637 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83e8d00d-265f-4ba9-bf72-9ecd4fd0944b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.391584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.322723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.366349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.362144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.377586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>0.508823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>0.552950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>0.589796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>0.598485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0.396026</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83e8d00d-265f-4ba9-bf72-9ecd4fd0944b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83e8d00d-265f-4ba9-bf72-9ecd4fd0944b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83e8d00d-265f-4ba9-bf72-9ecd4fd0944b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bin_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TvTQo2AmR296",
        "outputId": "e09ad179-7fe6-432d-8c09-be11d7333bab"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.5715430974960327'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_4, bin_acc = neural_network(nodes_first= 32, nodes_second=24, batch=32, dropout_include=False, rate_=None, SEED = SEED, X_train = X_train_transformed, y_train = y_train, X_valid = X_test_transformed, y_valid = y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiVzIUUefuN",
        "outputId": "56329146-88f2-4449-9ef6-0860348dc736"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SoBXmdQfehl5",
        "outputId": "3fcd7e6d-d17e-4bdf-de1e-1f9c47126269"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0\n",
              "0    0.415483\n",
              "1    0.325158\n",
              "2    0.368344\n",
              "3    0.366286\n",
              "4    0.383946\n",
              "..        ...\n",
              "632  0.519569\n",
              "633  0.557580\n",
              "634  0.614020\n",
              "635  0.627056\n",
              "636  0.403316\n",
              "\n",
              "[637 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c70b983-ea9b-4dac-961c-c7888d25500f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.415483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.325158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.368344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.366286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.383946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>0.519569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>0.557580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>0.614020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>0.627056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0.403316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c70b983-ea9b-4dac-961c-c7888d25500f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c70b983-ea9b-4dac-961c-c7888d25500f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c70b983-ea9b-4dac-961c-c7888d25500f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bin_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "loR_eShXeh3F",
        "outputId": "5f129e2f-2c36-426d-b9fa-179415393d05"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.5719438791275024'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_3, bin_acc = neural_network(nodes_first= 32, nodes_second=12, batch=64, dropout_include=False, rate_=None, SEED = SEED, X_train = X_train_transformed, y_train = y_train, X_valid = X_test_transformed, y_valid = y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_j1bOJ6e4NP",
        "outputId": "857113e1-9404-4e1e-a301-6757bfab582d"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IPZA2tYqe51N",
        "outputId": "4701e466-868d-4bf6-f87f-ef5b1398df07"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0\n",
              "0    0.556008\n",
              "1    0.388831\n",
              "2    0.361675\n",
              "3    0.354577\n",
              "4    0.415219\n",
              "..        ...\n",
              "632  0.588578\n",
              "633  0.502847\n",
              "634  0.603909\n",
              "635  0.595757\n",
              "636  0.460573\n",
              "\n",
              "[637 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae29bebf-b259-492d-870e-ccb7c27e52ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.556008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.388831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.361675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.354577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.415219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>0.588578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>0.502847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>0.603909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>0.595757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0.460573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae29bebf-b259-492d-870e-ccb7c27e52ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae29bebf-b259-492d-870e-ccb7c27e52ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae29bebf-b259-492d-870e-ccb7c27e52ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bin_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NuojFbFKe61J",
        "outputId": "8dc0f685-5309-40cf-f4b0-9368ba6e247c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.575951874256134'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_2, bin_acc = neural_network( nodes_first= 32, nodes_second=8, batch=32, dropout_include=False, rate_=None, SEED = SEED, X_train = X_train_transformed, y_train = y_train, X_valid = X_test_transformed, y_valid = y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMrqWyI4fLX0",
        "outputId": "04765457-7eb8-4510-e9ab-888cec6ac69b"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fTfNJBpQfMnF",
        "outputId": "b2d574e2-be36-4f73-c27a-2bbfe5980a9c"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0\n",
              "0    0.507302\n",
              "1    0.397984\n",
              "2    0.354286\n",
              "3    0.375178\n",
              "4    0.387085\n",
              "..        ...\n",
              "632  0.626407\n",
              "633  0.558763\n",
              "634  0.550930\n",
              "635  0.568097\n",
              "636  0.472149\n",
              "\n",
              "[637 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5591276e-1b7c-4fdd-8ebd-cd3238968ac4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.507302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.397984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.354286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.375178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.387085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>0.626407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>0.558763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>0.550930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>0.568097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0.472149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5591276e-1b7c-4fdd-8ebd-cd3238968ac4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5591276e-1b7c-4fdd-8ebd-cd3238968ac4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5591276e-1b7c-4fdd-8ebd-cd3238968ac4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bin_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dNHNhEyUfNlJ",
        "outputId": "7379bbc0-9971-4e70-878d-6333e7a874d0"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.5767534971237183'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_1, bin_acc = neural_network( nodes_first= 24, nodes_second=8, batch=32, dropout_include=False, rate_=None, SEED = SEED, X_train = X_train_transformed, y_train = y_train, X_valid = X_test_transformed, y_valid = y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtuMEsDWfczG",
        "outputId": "40b20e5e-e5ee-4dec-f87a-e346e2a63ea6"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "31JheJpXfeY3",
        "outputId": "31f7fc53-2ace-4723-a1a5-1c14f8571c13"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0\n",
              "0    0.469068\n",
              "1    0.340286\n",
              "2    0.367041\n",
              "3    0.365146\n",
              "4    0.480576\n",
              "..        ...\n",
              "632  0.497561\n",
              "633  0.509327\n",
              "634  0.578830\n",
              "635  0.576412\n",
              "636  0.439048\n",
              "\n",
              "[637 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0219a697-eaa9-443e-ab72-2550887d861e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.469068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.340286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.367041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.365146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.480576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>0.497561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>0.509327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>0.578830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>0.576412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0.439048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0219a697-eaa9-443e-ab72-2550887d861e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0219a697-eaa9-443e-ab72-2550887d861e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0219a697-eaa9-443e-ab72-2550887d861e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bin_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K720gC7TffbM",
        "outputId": "1b9f51b1-490d-403b-e0db-f4c6da8e8f81"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.5811623334884644'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = X_valid[['Close', 'Open']].copy()"
      ],
      "metadata": {
        "id": "wT8B-kAVR3TL"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results['NN 5'] = df_result_5[0].values\n",
        "df_results['NN 4'] = df_result_4[0].values\n",
        "df_results['NN 3'] = df_result_3[0].values\n",
        "df_results['NN 2'] = df_result_2[0].values\n",
        "df_results['NN 1'] = df_result_1[0].values\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "F_WldZzJdgvL",
        "outputId": "9a8426a8-ca23-4f4e-a604-2e0c28dd3fb3"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Close     Open      NN 5      NN 4      NN 3      NN 2      NN 1\n",
              "Date                                                                          \n",
              "2019-07-29  1614.96  1587.52  0.391584  0.415483  0.556008  0.507302  0.469068\n",
              "2019-07-30  1603.24  1614.96  0.322723  0.325158  0.388831  0.397984  0.340286\n",
              "2019-07-31  1601.91  1603.24  0.366349  0.368344  0.361675  0.354286  0.367041\n",
              "2019-08-01  1601.91  1601.91  0.362144  0.366286  0.354577  0.375178  0.365146\n",
              "2019-08-02  1583.93  1601.91  0.377586  0.383946  0.415219  0.387085  0.480576\n",
              "...             ...      ...       ...       ...       ...       ...       ...\n",
              "2022-02-17  1785.48  1717.35  0.508823  0.519569  0.588578  0.626407  0.497561\n",
              "2022-02-18  1774.84  1785.48  0.552950  0.557580  0.502847  0.558763  0.509327\n",
              "2022-02-21  1766.02  1774.84  0.589796  0.614020  0.603909  0.550930  0.578830\n",
              "2022-02-22  1759.73  1766.02  0.598485  0.627056  0.595757  0.568097  0.576412\n",
              "2022-02-23  1718.50  1759.73  0.396026  0.403316  0.460573  0.472149  0.439048\n",
              "\n",
              "[637 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9eee4b00-1224-4771-8961-9a516c95cdf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Open</th>\n",
              "      <th>NN 5</th>\n",
              "      <th>NN 4</th>\n",
              "      <th>NN 3</th>\n",
              "      <th>NN 2</th>\n",
              "      <th>NN 1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>1614.96</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>0.391584</td>\n",
              "      <td>0.415483</td>\n",
              "      <td>0.556008</td>\n",
              "      <td>0.507302</td>\n",
              "      <td>0.469068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-30</th>\n",
              "      <td>1603.24</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>0.322723</td>\n",
              "      <td>0.325158</td>\n",
              "      <td>0.388831</td>\n",
              "      <td>0.397984</td>\n",
              "      <td>0.340286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-31</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.368344</td>\n",
              "      <td>0.361675</td>\n",
              "      <td>0.354286</td>\n",
              "      <td>0.367041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.362144</td>\n",
              "      <td>0.366286</td>\n",
              "      <td>0.354577</td>\n",
              "      <td>0.375178</td>\n",
              "      <td>0.365146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-02</th>\n",
              "      <td>1583.93</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.377586</td>\n",
              "      <td>0.383946</td>\n",
              "      <td>0.415219</td>\n",
              "      <td>0.387085</td>\n",
              "      <td>0.480576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-17</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1717.35</td>\n",
              "      <td>0.508823</td>\n",
              "      <td>0.519569</td>\n",
              "      <td>0.588578</td>\n",
              "      <td>0.626407</td>\n",
              "      <td>0.497561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1785.48</td>\n",
              "      <td>0.552950</td>\n",
              "      <td>0.557580</td>\n",
              "      <td>0.502847</td>\n",
              "      <td>0.558763</td>\n",
              "      <td>0.509327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>0.589796</td>\n",
              "      <td>0.614020</td>\n",
              "      <td>0.603909</td>\n",
              "      <td>0.550930</td>\n",
              "      <td>0.578830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>0.598485</td>\n",
              "      <td>0.627056</td>\n",
              "      <td>0.595757</td>\n",
              "      <td>0.568097</td>\n",
              "      <td>0.576412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>0.396026</td>\n",
              "      <td>0.403316</td>\n",
              "      <td>0.460573</td>\n",
              "      <td>0.472149</td>\n",
              "      <td>0.439048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eee4b00-1224-4771-8961-9a516c95cdf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9eee4b00-1224-4771-8961-9a516c95cdf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9eee4b00-1224-4771-8961-9a516c95cdf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "signal = []\n",
        "for i in range(len(df_results[\"Close\"])):\n",
        "    if df_results[\"NN 1\"][i] > 0.5:\n",
        "        signal.append(1)\n",
        "    else:\n",
        "        signal.append(0)\n",
        "df_results[\"Signal 1\"] = signal\n",
        "\n",
        "signal = []\n",
        "for i in range(len(df_results[\"Close\"])):\n",
        "    if df_results[\"NN 2\"][i] > 0.5:\n",
        "        signal.append(1)\n",
        "    else:\n",
        "        signal.append(0)\n",
        "df_results[\"Signal 2\"] = signal\n",
        "\n",
        "signal = []\n",
        "for i in range(len(df_results[\"Close\"])):\n",
        "    if df_results[\"NN 3\"][i] > 0.5:\n",
        "        signal.append(1)\n",
        "    else:\n",
        "        signal.append(0)\n",
        "df_results[\"Signal 3\"] = signal\n",
        "\n",
        "signal = []\n",
        "for i in range(len(df_results[\"Close\"])):\n",
        "    if df_results[\"NN 4\"][i] > 0.5:\n",
        "        signal.append(1)\n",
        "    else:\n",
        "        signal.append(0)\n",
        "df_results[\"Signal 4\"] = signal\n",
        "\n",
        "signal = []\n",
        "for i in range(len(df_results[\"Close\"])):\n",
        "    if df_results[\"NN 5\"][i] > 0.5:\n",
        "        signal.append(1)\n",
        "    else:\n",
        "        signal.append(0)\n",
        "df_results[\"Signal 5\"] = signal\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "n-BjqNrfeMzk",
        "outputId": "647dea85-1f17-4211-b4d6-706e2071790b"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Close     Open      NN 5      NN 4      NN 3      NN 2  \\\n",
              "Date                                                                   \n",
              "2019-07-29  1614.96  1587.52  0.391584  0.415483  0.556008  0.507302   \n",
              "2019-07-30  1603.24  1614.96  0.322723  0.325158  0.388831  0.397984   \n",
              "2019-07-31  1601.91  1603.24  0.366349  0.368344  0.361675  0.354286   \n",
              "2019-08-01  1601.91  1601.91  0.362144  0.366286  0.354577  0.375178   \n",
              "2019-08-02  1583.93  1601.91  0.377586  0.383946  0.415219  0.387085   \n",
              "...             ...      ...       ...       ...       ...       ...   \n",
              "2022-02-17  1785.48  1717.35  0.508823  0.519569  0.588578  0.626407   \n",
              "2022-02-18  1774.84  1785.48  0.552950  0.557580  0.502847  0.558763   \n",
              "2022-02-21  1766.02  1774.84  0.589796  0.614020  0.603909  0.550930   \n",
              "2022-02-22  1759.73  1766.02  0.598485  0.627056  0.595757  0.568097   \n",
              "2022-02-23  1718.50  1759.73  0.396026  0.403316  0.460573  0.472149   \n",
              "\n",
              "                NN 1  Signal 1  Signal 2  Signal 3  Signal 4  Signal 5  \n",
              "Date                                                                    \n",
              "2019-07-29  0.469068         0         1         1         0         0  \n",
              "2019-07-30  0.340286         0         0         0         0         0  \n",
              "2019-07-31  0.367041         0         0         0         0         0  \n",
              "2019-08-01  0.365146         0         0         0         0         0  \n",
              "2019-08-02  0.480576         0         0         0         0         0  \n",
              "...              ...       ...       ...       ...       ...       ...  \n",
              "2022-02-17  0.497561         0         1         1         1         1  \n",
              "2022-02-18  0.509327         1         1         1         1         1  \n",
              "2022-02-21  0.578830         1         1         1         1         1  \n",
              "2022-02-22  0.576412         1         1         1         1         1  \n",
              "2022-02-23  0.439048         0         0         0         0         0  \n",
              "\n",
              "[637 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-123cd33a-c44d-441c-827e-9cafc96da70d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Open</th>\n",
              "      <th>NN 5</th>\n",
              "      <th>NN 4</th>\n",
              "      <th>NN 3</th>\n",
              "      <th>NN 2</th>\n",
              "      <th>NN 1</th>\n",
              "      <th>Signal 1</th>\n",
              "      <th>Signal 2</th>\n",
              "      <th>Signal 3</th>\n",
              "      <th>Signal 4</th>\n",
              "      <th>Signal 5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>1614.96</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>0.391584</td>\n",
              "      <td>0.415483</td>\n",
              "      <td>0.556008</td>\n",
              "      <td>0.507302</td>\n",
              "      <td>0.469068</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-30</th>\n",
              "      <td>1603.24</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>0.322723</td>\n",
              "      <td>0.325158</td>\n",
              "      <td>0.388831</td>\n",
              "      <td>0.397984</td>\n",
              "      <td>0.340286</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-31</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.368344</td>\n",
              "      <td>0.361675</td>\n",
              "      <td>0.354286</td>\n",
              "      <td>0.367041</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.362144</td>\n",
              "      <td>0.366286</td>\n",
              "      <td>0.354577</td>\n",
              "      <td>0.375178</td>\n",
              "      <td>0.365146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-02</th>\n",
              "      <td>1583.93</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.377586</td>\n",
              "      <td>0.383946</td>\n",
              "      <td>0.415219</td>\n",
              "      <td>0.387085</td>\n",
              "      <td>0.480576</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-17</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1717.35</td>\n",
              "      <td>0.508823</td>\n",
              "      <td>0.519569</td>\n",
              "      <td>0.588578</td>\n",
              "      <td>0.626407</td>\n",
              "      <td>0.497561</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1785.48</td>\n",
              "      <td>0.552950</td>\n",
              "      <td>0.557580</td>\n",
              "      <td>0.502847</td>\n",
              "      <td>0.558763</td>\n",
              "      <td>0.509327</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>0.589796</td>\n",
              "      <td>0.614020</td>\n",
              "      <td>0.603909</td>\n",
              "      <td>0.550930</td>\n",
              "      <td>0.578830</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>0.598485</td>\n",
              "      <td>0.627056</td>\n",
              "      <td>0.595757</td>\n",
              "      <td>0.568097</td>\n",
              "      <td>0.576412</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>0.396026</td>\n",
              "      <td>0.403316</td>\n",
              "      <td>0.460573</td>\n",
              "      <td>0.472149</td>\n",
              "      <td>0.439048</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-123cd33a-c44d-441c-827e-9cafc96da70d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-123cd33a-c44d-441c-827e-9cafc96da70d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-123cd33a-c44d-441c-827e-9cafc96da70d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trading_results(df_results[\"Close\"], df_results[\"Signal 1\"])\n",
        "\n",
        "for i in range(len(results)):\n",
        "    if results[i] != 'n/a':\n",
        "        results[i] = results[i]*100\n",
        "        \n",
        "amount = []\n",
        "amount_ = 100\n",
        "for element in results:\n",
        "    if element != 'n/a':\n",
        "        amount_ = amount_*(1+element/100)\n",
        "        amount.append(amount_)\n",
        "    else:\n",
        "        amount.append(element)\n",
        "amount[0] = 100\n",
        "\n",
        "for i in range(len(amount)):\n",
        "  if amount[i] != 'n/a':\n",
        "      remember = amount[i]\n",
        "  else:\n",
        "      amount[i] = remember \n",
        "\n",
        "df_results[\"Results 1\"] = amount"
      ],
      "metadata": {
        "id": "0duQXQ0jggjz"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "eeTGfPiDg6ZN",
        "outputId": "5e25773d-e964-45bc-b9e9-8ef42273568e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Close     Open      NN 5      NN 4      NN 3      NN 2  \\\n",
              "Date                                                                   \n",
              "2019-07-29  1614.96  1587.52  0.391584  0.415483  0.556008  0.507302   \n",
              "2019-07-30  1603.24  1614.96  0.322723  0.325158  0.388831  0.397984   \n",
              "2019-07-31  1601.91  1603.24  0.366349  0.368344  0.361675  0.354286   \n",
              "2019-08-01  1601.91  1601.91  0.362144  0.366286  0.354577  0.375178   \n",
              "2019-08-02  1583.93  1601.91  0.377586  0.383946  0.415219  0.387085   \n",
              "...             ...      ...       ...       ...       ...       ...   \n",
              "2022-02-17  1785.48  1717.35  0.508823  0.519569  0.588578  0.626407   \n",
              "2022-02-18  1774.84  1785.48  0.552950  0.557580  0.502847  0.558763   \n",
              "2022-02-21  1766.02  1774.84  0.589796  0.614020  0.603909  0.550930   \n",
              "2022-02-22  1759.73  1766.02  0.598485  0.627056  0.595757  0.568097   \n",
              "2022-02-23  1718.50  1759.73  0.396026  0.403316  0.460573  0.472149   \n",
              "\n",
              "                NN 1  Signal 1  Signal 2  Signal 3  Signal 4  Signal 5  \\\n",
              "Date                                                                     \n",
              "2019-07-29  0.469068         0         1         1         0         0   \n",
              "2019-07-30  0.340286         0         0         0         0         0   \n",
              "2019-07-31  0.367041         0         0         0         0         0   \n",
              "2019-08-01  0.365146         0         0         0         0         0   \n",
              "2019-08-02  0.480576         0         0         0         0         0   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-02-17  0.497561         0         1         1         1         1   \n",
              "2022-02-18  0.509327         1         1         1         1         1   \n",
              "2022-02-21  0.578830         1         1         1         1         1   \n",
              "2022-02-22  0.576412         1         1         1         1         1   \n",
              "2022-02-23  0.439048         0         0         0         0         0   \n",
              "\n",
              "             Results 1  \n",
              "Date                    \n",
              "2019-07-29  100.000000  \n",
              "2019-07-30  100.000000  \n",
              "2019-07-31  100.000000  \n",
              "2019-08-01  100.000000  \n",
              "2019-08-02  100.000000  \n",
              "...                ...  \n",
              "2022-02-17   59.809291  \n",
              "2022-02-18   57.926074  \n",
              "2022-02-21   57.926074  \n",
              "2022-02-22   57.926074  \n",
              "2022-02-23   55.855582  \n",
              "\n",
              "[637 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-065afb32-0c0c-4c99-8895-2a43e45c0c71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Open</th>\n",
              "      <th>NN 5</th>\n",
              "      <th>NN 4</th>\n",
              "      <th>NN 3</th>\n",
              "      <th>NN 2</th>\n",
              "      <th>NN 1</th>\n",
              "      <th>Signal 1</th>\n",
              "      <th>Signal 2</th>\n",
              "      <th>Signal 3</th>\n",
              "      <th>Signal 4</th>\n",
              "      <th>Signal 5</th>\n",
              "      <th>Results 1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>1614.96</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>0.391584</td>\n",
              "      <td>0.415483</td>\n",
              "      <td>0.556008</td>\n",
              "      <td>0.507302</td>\n",
              "      <td>0.469068</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-30</th>\n",
              "      <td>1603.24</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>0.322723</td>\n",
              "      <td>0.325158</td>\n",
              "      <td>0.388831</td>\n",
              "      <td>0.397984</td>\n",
              "      <td>0.340286</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-31</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.368344</td>\n",
              "      <td>0.361675</td>\n",
              "      <td>0.354286</td>\n",
              "      <td>0.367041</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.362144</td>\n",
              "      <td>0.366286</td>\n",
              "      <td>0.354577</td>\n",
              "      <td>0.375178</td>\n",
              "      <td>0.365146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-02</th>\n",
              "      <td>1583.93</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.377586</td>\n",
              "      <td>0.383946</td>\n",
              "      <td>0.415219</td>\n",
              "      <td>0.387085</td>\n",
              "      <td>0.480576</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-17</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1717.35</td>\n",
              "      <td>0.508823</td>\n",
              "      <td>0.519569</td>\n",
              "      <td>0.588578</td>\n",
              "      <td>0.626407</td>\n",
              "      <td>0.497561</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>59.809291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1785.48</td>\n",
              "      <td>0.552950</td>\n",
              "      <td>0.557580</td>\n",
              "      <td>0.502847</td>\n",
              "      <td>0.558763</td>\n",
              "      <td>0.509327</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57.926074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>0.589796</td>\n",
              "      <td>0.614020</td>\n",
              "      <td>0.603909</td>\n",
              "      <td>0.550930</td>\n",
              "      <td>0.578830</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57.926074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>0.598485</td>\n",
              "      <td>0.627056</td>\n",
              "      <td>0.595757</td>\n",
              "      <td>0.568097</td>\n",
              "      <td>0.576412</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57.926074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>0.396026</td>\n",
              "      <td>0.403316</td>\n",
              "      <td>0.460573</td>\n",
              "      <td>0.472149</td>\n",
              "      <td>0.439048</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55.855582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-065afb32-0c0c-4c99-8895-2a43e45c0c71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-065afb32-0c0c-4c99-8895-2a43e45c0c71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-065afb32-0c0c-4c99-8895-2a43e45c0c71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trading_results(df_results[\"Close\"], df_results[\"Signal 2\"])\n",
        "\n",
        "for i in range(len(results)):\n",
        "    if results[i] != 'n/a':\n",
        "        results[i] = results[i]*100\n",
        "        \n",
        "amount = []\n",
        "amount_ = 100\n",
        "for element in results:\n",
        "    if element != 'n/a':\n",
        "        amount_ = amount_*(1+element/100)\n",
        "        amount.append(amount_)\n",
        "    else:\n",
        "        amount.append(element)\n",
        "amount[0] = 100\n",
        "\n",
        "for i in range(len(amount)):\n",
        "  if amount[i] != 'n/a':\n",
        "      remember = amount[i]\n",
        "  else:\n",
        "      amount[i] = remember \n",
        "\n",
        "df_results[\"Results 2\"] = amount"
      ],
      "metadata": {
        "id": "hPxr734yg8re"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = trading_results(df_results[\"Close\"], df_results[\"Signal 3\"])\n",
        "\n",
        "for i in range(len(results)):\n",
        "    if results[i] != 'n/a':\n",
        "        results[i] = results[i]*100\n",
        "        \n",
        "amount = []\n",
        "amount_ = 100\n",
        "for element in results:\n",
        "    if element != 'n/a':\n",
        "        amount_ = amount_*(1+element/100)\n",
        "        amount.append(amount_)\n",
        "    else:\n",
        "        amount.append(element)\n",
        "amount[0] = 100\n",
        "\n",
        "for i in range(len(amount)):\n",
        "  if amount[i] != 'n/a':\n",
        "      remember = amount[i]\n",
        "  else:\n",
        "      amount[i] = remember \n",
        "\n",
        "df_results[\"Results 3\"] = amount"
      ],
      "metadata": {
        "id": "Z7YqjUYdhDKb"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = trading_results(df_results[\"Close\"], df_results[\"Signal 4\"])\n",
        "\n",
        "for i in range(len(results)):\n",
        "    if results[i] != 'n/a':\n",
        "        results[i] = results[i]*100\n",
        "        \n",
        "amount = []\n",
        "amount_ = 100\n",
        "for element in results:\n",
        "    if element != 'n/a':\n",
        "        amount_ = amount_*(1+element/100)\n",
        "        amount.append(amount_)\n",
        "    else:\n",
        "        amount.append(element)\n",
        "amount[0] = 100\n",
        "\n",
        "for i in range(len(amount)):\n",
        "  if amount[i] != 'n/a':\n",
        "      remember = amount[i]\n",
        "  else:\n",
        "      amount[i] = remember \n",
        "\n",
        "df_results[\"Results 4\"] = amount"
      ],
      "metadata": {
        "id": "sqqK6-UOhE7s"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = trading_results(df_results[\"Close\"], df_results[\"Signal 5\"])\n",
        "\n",
        "for i in range(len(results)):\n",
        "    if results[i] != 'n/a':\n",
        "        results[i] = results[i]*100\n",
        "        \n",
        "amount = []\n",
        "amount_ = 100\n",
        "for element in results:\n",
        "    if element != 'n/a':\n",
        "        amount_ = amount_*(1+element/100)\n",
        "        amount.append(amount_)\n",
        "    else:\n",
        "        amount.append(element)\n",
        "amount[0] = 100\n",
        "\n",
        "for i in range(len(amount)):\n",
        "  if amount[i] != 'n/a':\n",
        "      remember = amount[i]\n",
        "  else:\n",
        "      amount[i] = remember \n",
        "\n",
        "df_results[\"Results 5\"] = amount"
      ],
      "metadata": {
        "id": "bc2UtO8lhGr-"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "XJwh3aSfhIc_",
        "outputId": "0ecba3e7-d56a-43b4-e20c-ea0b44cf8a81"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Close     Open      NN 5      NN 4      NN 3      NN 2  \\\n",
              "Date                                                                   \n",
              "2019-07-29  1614.96  1587.52  0.391584  0.415483  0.556008  0.507302   \n",
              "2019-07-30  1603.24  1614.96  0.322723  0.325158  0.388831  0.397984   \n",
              "2019-07-31  1601.91  1603.24  0.366349  0.368344  0.361675  0.354286   \n",
              "2019-08-01  1601.91  1601.91  0.362144  0.366286  0.354577  0.375178   \n",
              "2019-08-02  1583.93  1601.91  0.377586  0.383946  0.415219  0.387085   \n",
              "...             ...      ...       ...       ...       ...       ...   \n",
              "2022-02-17  1785.48  1717.35  0.508823  0.519569  0.588578  0.626407   \n",
              "2022-02-18  1774.84  1785.48  0.552950  0.557580  0.502847  0.558763   \n",
              "2022-02-21  1766.02  1774.84  0.589796  0.614020  0.603909  0.550930   \n",
              "2022-02-22  1759.73  1766.02  0.598485  0.627056  0.595757  0.568097   \n",
              "2022-02-23  1718.50  1759.73  0.396026  0.403316  0.460573  0.472149   \n",
              "\n",
              "                NN 1  Signal 1  Signal 2  Signal 3  Signal 4  Signal 5  \\\n",
              "Date                                                                     \n",
              "2019-07-29  0.469068         0         1         1         0         0   \n",
              "2019-07-30  0.340286         0         0         0         0         0   \n",
              "2019-07-31  0.367041         0         0         0         0         0   \n",
              "2019-08-01  0.365146         0         0         0         0         0   \n",
              "2019-08-02  0.480576         0         0         0         0         0   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-02-17  0.497561         0         1         1         1         1   \n",
              "2022-02-18  0.509327         1         1         1         1         1   \n",
              "2022-02-21  0.578830         1         1         1         1         1   \n",
              "2022-02-22  0.576412         1         1         1         1         1   \n",
              "2022-02-23  0.439048         0         0         0         0         0   \n",
              "\n",
              "             Results 1   Results 2   Results 3   Results 4   Results 5  \n",
              "Date                                                                    \n",
              "2019-07-29  100.000000  100.000000  100.000000  100.000000  100.000000  \n",
              "2019-07-30  100.000000   98.874285   98.874285  100.000000  100.000000  \n",
              "2019-07-31  100.000000   98.874285   98.874285  100.000000  100.000000  \n",
              "2019-08-01  100.000000   98.874285   98.874285  100.000000  100.000000  \n",
              "2019-08-02  100.000000   98.874285   98.874285  100.000000  100.000000  \n",
              "...                ...         ...         ...         ...         ...  \n",
              "2022-02-17   59.809291   35.248036   37.615049   28.675137   26.386407  \n",
              "2022-02-18   57.926074   35.248036   37.615049   28.675137   26.386407  \n",
              "2022-02-21   57.926074   35.248036   37.615049   28.675137   26.386407  \n",
              "2022-02-22   57.926074   35.248036   37.615049   28.675137   26.386407  \n",
              "2022-02-23   55.855582   33.784759   36.053508   27.484726   25.291009  \n",
              "\n",
              "[637 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7981b58-c5d1-4ee6-ad6e-92c47d19421c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Open</th>\n",
              "      <th>NN 5</th>\n",
              "      <th>NN 4</th>\n",
              "      <th>NN 3</th>\n",
              "      <th>NN 2</th>\n",
              "      <th>NN 1</th>\n",
              "      <th>Signal 1</th>\n",
              "      <th>Signal 2</th>\n",
              "      <th>Signal 3</th>\n",
              "      <th>Signal 4</th>\n",
              "      <th>Signal 5</th>\n",
              "      <th>Results 1</th>\n",
              "      <th>Results 2</th>\n",
              "      <th>Results 3</th>\n",
              "      <th>Results 4</th>\n",
              "      <th>Results 5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>1614.96</td>\n",
              "      <td>1587.52</td>\n",
              "      <td>0.391584</td>\n",
              "      <td>0.415483</td>\n",
              "      <td>0.556008</td>\n",
              "      <td>0.507302</td>\n",
              "      <td>0.469068</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-30</th>\n",
              "      <td>1603.24</td>\n",
              "      <td>1614.96</td>\n",
              "      <td>0.322723</td>\n",
              "      <td>0.325158</td>\n",
              "      <td>0.388831</td>\n",
              "      <td>0.397984</td>\n",
              "      <td>0.340286</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-31</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1603.24</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.368344</td>\n",
              "      <td>0.361675</td>\n",
              "      <td>0.354286</td>\n",
              "      <td>0.367041</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>1601.91</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.362144</td>\n",
              "      <td>0.366286</td>\n",
              "      <td>0.354577</td>\n",
              "      <td>0.375178</td>\n",
              "      <td>0.365146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-02</th>\n",
              "      <td>1583.93</td>\n",
              "      <td>1601.91</td>\n",
              "      <td>0.377586</td>\n",
              "      <td>0.383946</td>\n",
              "      <td>0.415219</td>\n",
              "      <td>0.387085</td>\n",
              "      <td>0.480576</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>98.874285</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-17</th>\n",
              "      <td>1785.48</td>\n",
              "      <td>1717.35</td>\n",
              "      <td>0.508823</td>\n",
              "      <td>0.519569</td>\n",
              "      <td>0.588578</td>\n",
              "      <td>0.626407</td>\n",
              "      <td>0.497561</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>59.809291</td>\n",
              "      <td>35.248036</td>\n",
              "      <td>37.615049</td>\n",
              "      <td>28.675137</td>\n",
              "      <td>26.386407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-18</th>\n",
              "      <td>1774.84</td>\n",
              "      <td>1785.48</td>\n",
              "      <td>0.552950</td>\n",
              "      <td>0.557580</td>\n",
              "      <td>0.502847</td>\n",
              "      <td>0.558763</td>\n",
              "      <td>0.509327</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57.926074</td>\n",
              "      <td>35.248036</td>\n",
              "      <td>37.615049</td>\n",
              "      <td>28.675137</td>\n",
              "      <td>26.386407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-21</th>\n",
              "      <td>1766.02</td>\n",
              "      <td>1774.84</td>\n",
              "      <td>0.589796</td>\n",
              "      <td>0.614020</td>\n",
              "      <td>0.603909</td>\n",
              "      <td>0.550930</td>\n",
              "      <td>0.578830</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57.926074</td>\n",
              "      <td>35.248036</td>\n",
              "      <td>37.615049</td>\n",
              "      <td>28.675137</td>\n",
              "      <td>26.386407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-22</th>\n",
              "      <td>1759.73</td>\n",
              "      <td>1766.02</td>\n",
              "      <td>0.598485</td>\n",
              "      <td>0.627056</td>\n",
              "      <td>0.595757</td>\n",
              "      <td>0.568097</td>\n",
              "      <td>0.576412</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57.926074</td>\n",
              "      <td>35.248036</td>\n",
              "      <td>37.615049</td>\n",
              "      <td>28.675137</td>\n",
              "      <td>26.386407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-23</th>\n",
              "      <td>1718.50</td>\n",
              "      <td>1759.73</td>\n",
              "      <td>0.396026</td>\n",
              "      <td>0.403316</td>\n",
              "      <td>0.460573</td>\n",
              "      <td>0.472149</td>\n",
              "      <td>0.439048</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55.855582</td>\n",
              "      <td>33.784759</td>\n",
              "      <td>36.053508</td>\n",
              "      <td>27.484726</td>\n",
              "      <td>25.291009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>637 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7981b58-c5d1-4ee6-ad6e-92c47d19421c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7981b58-c5d1-4ee6-ad6e-92c47d19421c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7981b58-c5d1-4ee6-ad6e-92c47d19421c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.to_excel('NN_results.xlsx')"
      ],
      "metadata": {
        "id": "-Mmh3TawhJTY"
      },
      "execution_count": 151,
      "outputs": []
    }
  ]
}